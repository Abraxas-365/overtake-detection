#[doc(hidden)]
pub mod __private228 {
    #[doc(hidden)]
    pub use crate::private::*;
}
use serde_core::__private228 as serde_core_private;
#[doc(hidden)]
pub mod __private228 {
    #[doc(hidden)]
    pub use crate::private::*;
}
// src/smoother.rs

use crate::types::VehiclePosition;
use std::collections::{HashMap, VecDeque};

/// Temporal smoother for vehicle position using a sliding window
pub struct LanePositionSmoother {
    history: VecDeque<VehiclePosition>,
    window_size: usize,
}

impl LanePositionSmoother {
    /// Create a new smoother with specified window size
    ///
    /// # Arguments
    /// * `window_size` - Number of frames to use for smoothing (e.g., 10 frames)
    pub fn new(window_size: usize) -> Self {
        Self {
            history: VecDeque::with_capacity(window_size),
            window_size,
        }
    }

    /// Smooth the current position using temporal window
    ///
    /// Uses different strategies for different components:
    /// - Lane index: Mode (most common value)
    /// - Lateral offset: Median (resistant to outliers)
    /// - Confidence: Average
    pub fn smooth(&mut self, position: VehiclePosition) -> VehiclePosition {
        self.history.push_back(position);

        // Maintain window size
        if self.history.len() > self.window_size {
            self.history.pop_front();
        }

        // Need at least 3 frames for meaningful smoothing
        if self.history.len() < 3 {
            return position;
        }

        VehiclePosition {
            lane_index: self.smooth_lane_index(),
            lateral_offset: self.smooth_lateral_offset(),
            confidence: self.smooth_confidence(),
            timestamp: position.timestamp, // Keep current timestamp
        }
    }

    /// Get the most common lane index (mode)
    fn smooth_lane_index(&self) -> i32 {
        let mut counts: HashMap<i32, usize> = HashMap::new();

        for pos in &self.history {
            *counts.entry(pos.lane_index).or_insert(0) += 1;
        }

        counts
            .into_iter()
            .max_by_key(|(_, count)| *count)
            .map(|(lane, _)| lane)
            .unwrap_or(-1)
    }

    /// Get median lateral offset (resistant to outliers)
    fn smooth_lateral_offset(&self) -> f32 {
        let mut offsets: Vec<f32> = self.history.iter().map(|p| p.lateral_offset).collect();
        offsets.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
        offsets[offsets.len() / 2]
    }

    /// Get average confidence
    fn smooth_confidence(&self) -> f32 {
        let sum: f32 = self.history.iter().map(|p| p.confidence).sum();
        sum / self.history.len() as f32
    }

    /// Reset the smoother (e.g., when video changes)
    pub fn reset(&mut self) {
        self.history.clear();
    }

    /// Get the number of frames currently in the history
    pub fn history_size(&self) -> usize {
        self.history.len()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_smoother_mode_for_lane_index() {
        let mut smoother = LanePositionSmoother::new(5);

        // Feed noisy lane detections: [1, 1, 2, 1, 1]
        let positions = vec![
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.0,
            },
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.033,
            },
            VehiclePosition {
                lane_index: 2, // noise
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.066,
            },
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.099,
            },
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.132,
            },
        ];

        for pos in positions {
            smoother.smooth(pos);
        }

        // Last smoothed position should have lane_index = 1 (mode)
        let last_pos = positions.last().unwrap();
        let smoothed = smoother.smooth(*last_pos);
        assert_eq!(smoothed.lane_index, 1);
    }

    #[test]
    fn test_smoother_median_for_offset() {
        let mut smoother = LanePositionSmoother::new(5);

        // Feed offsets with outlier: [-0.1, -0.05, 0.0, 0.05, 2.0 (outlier)]
        let offsets = vec![-0.1, -0.05, 0.0, 0.05, 2.0];

        for (i, offset) in offsets.iter().enumerate() {
            let pos = VehiclePosition {
                lane_index: 1,
                lateral_offset: *offset,
                confidence: 0.8,
                timestamp: i as f64 * 0.033,
            };
            smoother.smooth(pos);
        }

        let last_pos = VehiclePosition {
            lane_index: 1,
            lateral_offset: 2.0,
            confidence: 0.8,
            timestamp: 0.165,
        };
        let smoothed = smoother.smooth(last_pos);

        // Median should be 0.0 (middle value), not affected by 2.0 outlier
        assert_eq!(smoothed.lateral_offset, 0.0);
    }
}
// src/types.rs

use serde::{Deserialize, Serialize};
use std::collections::HashMap;

// ============================================================================
// Configuration Structs
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Config {
    pub model: ModelConfig,
    pub inference: InferenceConfig,
    pub detection: DetectionConfig,
    pub video: VideoConfig,
    pub logging: LoggingConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelConfig {
    pub path: String,
    pub input_width: usize,
    pub input_height: usize,
    pub num_anchors: usize,
    pub num_lanes: usize,
    pub griding_num: usize,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct InferenceConfig {
    pub use_tensorrt: bool,
    pub use_fp16: bool,
    pub enable_engine_cache: bool,
    pub engine_cache_path: String,
    pub num_threads: usize,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DetectionConfig {
    pub confidence_threshold: f32,
    pub min_points_per_lane: usize,
    pub smoother_window_size: usize,
    pub calibration_frames: usize,
    pub debounce_frames: u32,
    pub confirm_frames: u32,
    pub min_lane_confidence: f32,
    pub min_position_confidence: f32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VideoConfig {
    pub input_dir: String,
    pub output_dir: String,
    pub source_width: usize,
    pub source_height: usize,
    pub target_fps: u32,
    pub save_annotated: bool,
    pub save_events_only: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LoggingConfig {
    pub level: String,
}

impl Config {
    pub fn load(path: &str) -> anyhow::Result<Self> {
        let contents = std::fs::read_to_string(path)?;
        let config: Config = serde_yaml::from_str(&contents)?;
        Ok(config)
    }
}

// ============================================================================
// Frame Type
// ============================================================================

#[derive(Debug, Clone)]
pub struct Frame {
    pub data: Vec<u8>,
    pub width: usize,
    pub height: usize,
    pub timestamp_ms: f64,
}

// ============================================================================
// Lane Detection Types (for inference output)
// ============================================================================

/// Lane from detection (uses tuple points for compatibility)
#[derive(Debug, Clone)]
pub struct DetectedLane {
    pub points: Vec<(f32, f32)>,
    pub confidence: f32,
}

// ============================================================================
// Analysis Types (Python-compatible)
// ============================================================================

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub enum LaneChangeState {
    Centered,
    Drifting,
    Crossing,
    Completed,
}

impl LaneChangeState {
    pub fn as_str(&self) -> &'static str {
        match self {
            LaneChangeState::Centered => "CENTERED",
            LaneChangeState::Drifting => "DRIFTING",
            LaneChangeState::Crossing => "CROSSING",
            LaneChangeState::Completed => "COMPLETED",
        }
    }
}

impl std::fmt::Display for LaneChangeState {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", self.as_str())
    }
}

#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub struct Point {
    pub x: f32,
    pub y: f32,
}

impl Point {
    pub fn new(x: f32, y: f32) -> Self {
        Self { x, y }
    }

    pub fn distance_to(&self, other: &Point) -> f32 {
        ((self.x - other.x).powi(2) + (self.y - other.y).powi(2)).sqrt()
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum LanePosition {
    LeftFar,
    LeftNear,
    RightNear,
    RightFar,
}

/// Lane for analysis (uses Point struct)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Lane {
    pub lane_id: usize,
    pub points: Vec<Point>,
    pub confidence: f32,
    pub position: Option<LanePosition>,
}

impl Lane {
    /// Create from detected lane (tuple points)
    pub fn from_detected(lane_id: usize, detected: &DetectedLane) -> Self {
        Self {
            lane_id,
            points: detected
                .points
                .iter()
                .map(|p| Point::new(p.0, p.1))
                .collect(),
            confidence: detected.confidence,
            position: None,
        }
    }

    pub fn get_x_at_y(&self, target_y: f32) -> Option<f32> {
        if self.points.len() < 2 {
            return None;
        }

        let mut sorted_points = self.points.clone();
        sorted_points.sort_by(|a, b| a.y.partial_cmp(&b.y).unwrap_or(std::cmp::Ordering::Equal));

        for i in 0..sorted_points.len() - 1 {
            let p1 = &sorted_points[i];
            let p2 = &sorted_points[i + 1];

            if p1.y <= target_y && target_y <= p2.y {
                if (p2.y - p1.y).abs() < 1e-6 {
                    return Some(p1.x);
                }
                let ratio = (target_y - p1.y) / (p2.y - p1.y);
                return Some(p1.x + ratio * (p2.x - p1.x));
            }
        }
        None
    }

    pub fn avg_x(&self) -> f32 {
        if self.points.is_empty() {
            return 0.0;
        }
        self.points.iter().map(|p| p.x).sum::<f32>() / self.points.len() as f32
    }
}

// ============================================================================
// Vehicle State
// ============================================================================

#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub struct VehicleState {
    pub lateral_offset: f32,
    pub lane_width: Option<f32>,
    pub heading_offset: f32,
    pub frame_id: u64,
    pub timestamp_ms: f64,
}

impl VehicleState {
    pub fn invalid() -> Self {
        Self {
            lateral_offset: 0.0,
            lane_width: None,
            heading_offset: 0.0,
            frame_id: 0,
            timestamp_ms: 0.0,
        }
    }

    pub fn normalized_offset(&self) -> Option<f32> {
        match self.lane_width {
            Some(width) if width > 1.0 => Some(self.lateral_offset / width),
            _ => None,
        }
    }

    pub fn is_valid(&self) -> bool {
        self.lane_width.map_or(false, |w| w > 0.0)
    }
}

// ============================================================================
// Direction
// ============================================================================

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum Direction {
    Left = -1,
    Unknown = 0,
    Right = 1,
}

impl Direction {
    pub fn from_offset(offset: f32) -> Self {
        if offset > 0.0 {
            Direction::Right
        } else if offset < 0.0 {
            Direction::Left
        } else {
            Direction::Unknown
        }
    }

    pub fn as_str(&self) -> &'static str {
        match self {
            Direction::Left => "LEFT",
            Direction::Right => "RIGHT",
            Direction::Unknown => "UNKNOWN",
        }
    }

    pub fn as_i32(&self) -> i32 {
        match self {
            Direction::Left => -1,
            Direction::Right => 1,
            Direction::Unknown => 0,
        }
    }
}

impl std::fmt::Display for Direction {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", self.as_str())
    }
}

// ============================================================================
// Lane Change Event
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LaneChangeEvent {
    pub event_id: String,
    pub timestamp: String,
    pub video_timestamp_ms: f64,
    pub frame_id: u64,
    pub direction: Direction,
    pub confidence: f32,
    pub duration_ms: Option<f64>,
    pub source_id: String,
    pub metadata: HashMap<String, serde_json::Value>,
}

impl LaneChangeEvent {
    pub fn new(
        video_timestamp_ms: f64,
        frame_id: u64,
        direction: Direction,
        confidence: f32,
    ) -> Self {
        Self {
            event_id: uuid::Uuid::new_v4().to_string(),
            timestamp: chrono::Utc::now().to_rfc3339(),
            video_timestamp_ms,
            frame_id,
            direction,
            confidence,
            duration_ms: None,
            source_id: String::new(),
            metadata: HashMap::new(),
        }
    }

    pub fn direction_name(&self) -> &'static str {
        self.direction.as_str()
    }

    pub fn to_json(&self) -> serde_json::Value {
        serde_json::json!({
            "event_id": self.event_id,
            "event_type": "lane_change",
            "timestamp": self.timestamp,
            "video_timestamp_ms": self.video_timestamp_ms,
            "frame_id": self.frame_id,
            "direction": self.direction_name(),
            "confidence": self.confidence,
            "duration_ms": self.duration_ms,
            "source_id": self.source_id,
            "metadata": self.metadata,
        })
    }
}

// ============================================================================
// Lane Change Config
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LaneChangeConfig {
    pub drift_threshold: f32,
    pub crossing_threshold: f32,
    pub min_frames_confirm: u32,
    pub cooldown_frames: u32,
    pub smoothing_alpha: f32,
    pub reference_y_ratio: f32,
}

impl Default for LaneChangeConfig {
    fn default() -> Self {
        Self {
            drift_threshold: 0.2,
            crossing_threshold: 0.4,
            min_frames_confirm: 5,
            cooldown_frames: 30,
            smoothing_alpha: 0.3,
            reference_y_ratio: 0.8,
        }
    }
}
// src/video_processor.rs

use crate::types::{Config, DetectedLane, VehicleState};
use anyhow::Result;
use opencv::{
    core::{self, Mat},
    imgproc,
    prelude::*,
    videoio::{self, VideoCapture, VideoCaptureTraitConst, VideoWriter},
};
use std::path::{Path, PathBuf};
use tracing::info;
use walkdir::WalkDir;

pub struct VideoProcessor {
    config: Config,
}

impl VideoProcessor {
    pub fn new(config: Config) -> Self {
        Self { config }
    }

    pub fn find_video_files(&self) -> Result<Vec<PathBuf>> {
        let mut videos = Vec::new();

        let video_extensions = vec!["mp4", "avi", "mov", "mkv", "MP4", "AVI", "MOV", "MKV"];

        for entry in WalkDir::new(&self.config.video.input_dir)
            .follow_links(true)
            .into_iter()
            .filter_map(|e| e.ok())
        {
            let path = entry.path();
            if let Some(ext) = path.extension() {
                if video_extensions.contains(&ext.to_str().unwrap_or("")) {
                    videos.push(path.to_path_buf());
                }
            }
        }

        info!("Found {} video files", videos.len());
        Ok(videos)
    }

    pub fn open_video(&self, path: &Path) -> Result<VideoReader> {
        info!("Opening video: {}", path.display());

        let cap = VideoCapture::from_file(path.to_str().unwrap(), videoio::CAP_ANY)?;

        if !cap.is_opened()? {
            anyhow::bail!("Failed to open video file");
        }

        let fps = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FPS)?;
        let total_frames = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FRAME_COUNT)? as i32;
        let width = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FRAME_WIDTH)? as i32;
        let height = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FRAME_HEIGHT)? as i32;

        info!(
            "Video properties: {}x{} @ {:.1} FPS, {} frames",
            width, height, fps, total_frames
        );

        Ok(VideoReader {
            cap,
            fps,
            total_frames,
            current_frame: 0,
            width,
            height,
        })
    }

    pub fn create_writer(
        &self,
        input_path: &Path,
        width: i32,
        height: i32,
        fps: f64,
    ) -> Result<Option<VideoWriter>> {
        if !self.config.video.save_annotated {
            return Ok(None);
        }

        std::fs::create_dir_all(&self.config.video.output_dir)?;

        let input_name = input_path.file_stem().unwrap().to_str().unwrap();
        let output_path = PathBuf::from(&self.config.video.output_dir)
            .join(format!("{}_annotated.mp4", input_name));

        info!("Output video: {}", output_path.display());

        let fourcc = VideoWriter::fourcc('m', 'p', '4', 'v')?;
        let writer = VideoWriter::new(
            output_path.to_str().unwrap(),
            fourcc,
            fps,
            core::Size::new(width, height),
            true,
        )?;

        Ok(Some(writer))
    }
}

pub struct VideoReader {
    pub cap: VideoCapture,
    pub fps: f64,
    pub total_frames: i32,
    pub current_frame: i32,
    pub width: i32,
    pub height: i32,
}

impl VideoReader {
    pub fn read_frame(&mut self) -> Result<Option<crate::types::Frame>> {
        use opencv::videoio::VideoCaptureTrait;

        let mut mat = Mat::default();

        if !VideoCaptureTrait::read(&mut self.cap, &mut mat)? || mat.empty() {
            return Ok(None);
        }

        self.current_frame += 1;
        let timestamp_ms = (self.current_frame as f64 / self.fps) * 1000.0;

        let mut rgb_mat = Mat::default();
        imgproc::cvt_color(&mat, &mut rgb_mat, imgproc::COLOR_BGR2RGB, 0)?;

        let data = rgb_mat.data_bytes()?.to_vec();

        Ok(Some(crate::types::Frame {
            data,
            width: self.width as usize,
            height: self.height as usize,
            timestamp_ms,
        }))
    }

    pub fn progress(&self) -> f32 {
        if self.total_frames == 0 {
            return 0.0;
        }
        (self.current_frame as f32 / self.total_frames as f32) * 100.0
    }
}

/// Draw lanes with Python-style state machine info overlay
pub fn draw_lanes_with_state(
    frame: &[u8],
    width: i32,
    height: i32,
    lanes: &[DetectedLane],
    state: &str,
    vehicle_state: Option<&VehicleState>,
) -> Result<Mat> {
    let mat = Mat::from_slice(frame)?;
    let mat = mat.reshape(3, height)?;

    let mut bgr_mat = Mat::default();
    imgproc::cvt_color(&mat, &mut bgr_mat, imgproc::COLOR_RGB2BGR, 0)?;
    let mut output = bgr_mat.try_clone()?;

    // Lane colors
    let colors = vec![
        core::Scalar::new(0.0, 0.0, 255.0, 0.0),   // Red
        core::Scalar::new(0.0, 255.0, 0.0, 0.0),   // Green
        core::Scalar::new(255.0, 0.0, 0.0, 0.0),   // Blue
        core::Scalar::new(0.0, 255.0, 255.0, 0.0), // Yellow
    ];

    // Draw lanes
    for (i, lane) in lanes.iter().enumerate() {
        let color = colors[i % colors.len()];

        // Draw lane points
        for point in &lane.points {
            let pt = core::Point::new(point.0 as i32, point.1 as i32);
            imgproc::circle(&mut output, pt, 3, color, -1, imgproc::LINE_8, 0)?;
        }

        // Draw lane lines
        for window in lane.points.windows(2) {
            let pt1 = core::Point::new(window[0].0 as i32, window[0].1 as i32);
            let pt2 = core::Point::new(window[1].0 as i32, window[1].1 as i32);
            imgproc::line(&mut output, pt1, pt2, color, 2, imgproc::LINE_AA, 0)?;
        }
    }

    // Draw vehicle position marker
    let vehicle_x = width / 2;
    let vehicle_y = (height as f32 * 0.85) as i32;

    imgproc::circle(
        &mut output,
        core::Point::new(vehicle_x, vehicle_y),
        10,
        core::Scalar::new(0.0, 255.0, 255.0, 0.0),
        -1,
        imgproc::LINE_8,
        0,
    )?;

    // State color based on state machine state
    let state_color = match state {
        "CENTERED" => core::Scalar::new(0.0, 255.0, 0.0, 0.0),
        "DRIFTING" => core::Scalar::new(0.0, 255.0, 255.0, 0.0),
        "CROSSING" => core::Scalar::new(0.0, 165.0, 255.0, 0.0),
        "COMPLETED" => core::Scalar::new(0.0, 0.0, 255.0, 0.0),
        _ => core::Scalar::new(255.0, 255.0, 255.0, 0.0),
    };

    // Draw info overlay background
    imgproc::rectangle(
        &mut output,
        core::Rect::new(5, 5, 550, 70),
        core::Scalar::new(40.0, 40.0, 40.0, 0.0),
        -1,
        imgproc::LINE_8,
        0,
    )?;

    // Draw state text
    imgproc::put_text(
        &mut output,
        &format!("State: {}", state),
        core::Point::new(15, 32),
        imgproc::FONT_HERSHEY_SIMPLEX,
        0.8,
        state_color,
        2,
        imgproc::LINE_8,
        false,
    )?;

    // Draw vehicle state info if available
    if let Some(vs) = vehicle_state {
        if vs.is_valid() {
            let normalized = vs.normalized_offset().unwrap_or(0.0);
            let info = format!(
                "Offset: {:.1}px ({:+.1}%) | Width: {:.0}px",
                vs.lateral_offset,
                normalized * 100.0,
                vs.lane_width.unwrap_or(0.0)
            );
            imgproc::put_text(
                &mut output,
                &info,
                core::Point::new(200, 32),
                imgproc::FONT_HERSHEY_SIMPLEX,
                0.5,
                core::Scalar::new(255.0, 255.0, 255.0, 0.0),
                1,
                imgproc::LINE_8,
                false,
            )?;
        }
    }

    // Draw lanes count
    let lanes_info = format!("Lanes: {}", lanes.len());
    imgproc::put_text(
        &mut output,
        &lanes_info,
        core::Point::new(15, 60),
        imgproc::FONT_HERSHEY_SIMPLEX,
        0.5,
        core::Scalar::new(200.0, 200.0, 200.0, 0.0),
        1,
        imgproc::LINE_8,
        false,
    )?;

    Ok(output)
}
// src/analysis/state_machine.rs

use crate::types::{Direction, LaneChangeConfig, LaneChangeEvent, LaneChangeState, VehicleState};
use std::collections::HashMap;
use tracing::{debug, info};

/// State machine for lane change detection (matching Python implementation)
pub struct LaneChangeStateMachine {
    config: LaneChangeConfig,
    source_id: String,

    // Current state
    state: LaneChangeState,
    frames_in_state: u32,

    // Pending state transition
    pending_state: Option<LaneChangeState>,
    pending_frames: u32,

    // Lane change tracking
    change_direction: Direction,
    change_start_frame: Option<u64>,
    change_start_time: Option<f64>,

    // Cooldown tracking
    cooldown_remaining: u32,
}

impl LaneChangeStateMachine {
    pub fn new(config: LaneChangeConfig) -> Self {
        Self {
            config,
            source_id: String::new(),
            state: LaneChangeState::Centered,
            frames_in_state: 0,
            pending_state: None,
            pending_frames: 0,
            change_direction: Direction::Unknown,
            change_start_frame: None,
            change_start_time: None,
            cooldown_remaining: 0,
        }
    }

    pub fn with_source_id(mut self, source_id: String) -> Self {
        self.source_id = source_id;
        self
    }

    /// Get current state name
    pub fn current_state(&self) -> &str {
        self.state.as_str()
    }

    /// Update state machine with new vehicle state
    pub fn update(
        &mut self,
        vehicle_state: &VehicleState,
        frame_id: u64,
        timestamp_ms: f64,
    ) -> Option<LaneChangeEvent> {
        // Handle cooldown period
        if self.cooldown_remaining > 0 {
            self.cooldown_remaining -= 1;
            if self.cooldown_remaining == 0 {
                // Reset to CENTERED after cooldown
                self.state = LaneChangeState::Centered;
                self.frames_in_state = 0;
            }
            return None;
        }

        // Check if we have valid lane information
        if !vehicle_state.is_valid() {
            return None;
        }

        // Calculate normalized offset (as fraction of lane width)
        let lane_width = vehicle_state.lane_width.unwrap(); // Safe due to is_valid check
        let normalized_offset = (vehicle_state.lateral_offset / lane_width).abs();
        let direction = Direction::from_offset(vehicle_state.lateral_offset);

        // Determine target state based on offset magnitude
        let target_state = self.determine_target_state(normalized_offset);

        // Check for state transition
        self.check_transition(target_state, direction, frame_id, timestamp_ms)
    }

    /// Determine target state based on lateral offset magnitude
    fn determine_target_state(&self, normalized_offset: f32) -> LaneChangeState {
        if normalized_offset >= self.config.crossing_threshold {
            LaneChangeState::Crossing
        } else if normalized_offset >= self.config.drift_threshold {
            LaneChangeState::Drifting
        } else {
            // Vehicle is centered
            if self.state == LaneChangeState::Crossing {
                // Was crossing, now centered = completed
                LaneChangeState::Completed
            } else {
                LaneChangeState::Centered
            }
        }
    }

    /// Check if state transition should occur
    fn check_transition(
        &mut self,
        target_state: LaneChangeState,
        direction: Direction,
        frame_id: u64,
        timestamp_ms: f64,
    ) -> Option<LaneChangeEvent> {
        // Same state as current - reset pending and increment counter
        if target_state == self.state {
            self.pending_state = None;
            self.pending_frames = 0;
            self.frames_in_state += 1;
            return None;
        }

        // Different target state - accumulate confirmation frames
        if self.pending_state == Some(target_state) {
            self.pending_frames += 1;
        } else {
            self.pending_state = Some(target_state);
            self.pending_frames = 1;
        }

        // Check if we have enough confirmation frames
        if self.pending_frames < self.config.min_frames_confirm {
            return None;
        }

        // Transition confirmed - execute and potentially emit event
        self.execute_transition(target_state, direction, frame_id, timestamp_ms)
    }

    /// Execute state transition and create event if applicable
    fn execute_transition(
        &mut self,
        target_state: LaneChangeState,
        direction: Direction,
        frame_id: u64,
        timestamp_ms: f64,
    ) -> Option<LaneChangeEvent> {
        let from_state = self.state;

        // Track lane change start
        if target_state == LaneChangeState::Drifting && from_state == LaneChangeState::Centered {
            self.change_direction = direction;
            self.change_start_frame = Some(frame_id);
            self.change_start_time = Some(timestamp_ms);
            debug!(
                "Lane change started: {} at frame {}",
                direction.as_str(),
                frame_id
            );
        }

        // Calculate duration for completed lane changes
        let duration_ms = if target_state == LaneChangeState::Completed {
            self.change_start_time.map(|start| timestamp_ms - start)
        } else {
            None
        };

        // Update state
        self.state = target_state;
        self.frames_in_state = 0;
        self.pending_state = None;
        self.pending_frames = 0;

        // Handle completed state - start cooldown and emit event
        if target_state == LaneChangeState::Completed {
            self.cooldown_remaining = self.config.cooldown_frames;

            let mut event = LaneChangeEvent::new(
                timestamp_ms,
                frame_id,
                self.change_direction,
                0.9, // Could be calculated from detection confidences
            );
            event.duration_ms = duration_ms;
            event.source_id = self.source_id.clone();
            event.metadata.insert(
                "start_frame".to_string(),
                serde_json::json!(self.change_start_frame),
            );
            event
                .metadata
                .insert("end_frame".to_string(), serde_json::json!(frame_id));

            info!(
                "Lane change completed: {} (duration: {:.0}ms) at frame {}",
                event.direction_name(),
                duration_ms.unwrap_or(0.0),
                frame_id
            );

            // Reset lane change tracking
            self.change_direction = Direction::Unknown;
            self.change_start_frame = None;
            self.change_start_time = None;

            return Some(event);
        }

        None
    }

    /// Reset state machine to initial state
    pub fn reset(&mut self) {
        self.state = LaneChangeState::Centered;
        self.frames_in_state = 0;
        self.pending_state = None;
        self.pending_frames = 0;
        self.change_direction = Direction::Unknown;
        self.change_start_frame = None;
        self.change_start_time = None;
        self.cooldown_remaining = 0;
    }

    /// Set source ID for events
    pub fn set_source_id(&mut self, source_id: String) {
        self.source_id = source_id;
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    fn create_config() -> LaneChangeConfig {
        LaneChangeConfig {
            drift_threshold: 0.2,
            crossing_threshold: 0.4,
            min_frames_confirm: 3,
            cooldown_frames: 10,
            smoothing_alpha: 0.3,
            reference_y_ratio: 0.8,
        }
    }

    fn create_vehicle_state(lateral_offset: f32, lane_width: f32) -> VehicleState {
        VehicleState {
            lateral_offset,
            lane_width: Some(lane_width),
            heading_offset: 0.0,
            frame_id: 0,
            timestamp_ms: 0.0,
        }
    }

    #[test]
    fn test_initial_state_is_centered() {
        let fsm = LaneChangeStateMachine::new(create_config());
        assert_eq!(fsm.current_state(), "CENTERED");
    }

    #[test]
    fn test_no_event_when_centered() {
        let mut fsm = LaneChangeStateMachine::new(create_config());
        let centered = create_vehicle_state(0.0, 400.0);

        let event = fsm.update(&centered, 0, 0.0);

        assert!(event.is_none());
        assert_eq!(fsm.current_state(), "CENTERED");
    }

    #[test]
    fn test_drift_detection_requires_multiple_frames() {
        let mut fsm = LaneChangeStateMachine::new(create_config());

        // 25% offset = drifting
        let drifting = create_vehicle_state(100.0, 400.0);

        // First two frames shouldn't trigger transition
        let event1 = fsm.update(&drifting, 0, 0.0);
        let event2 = fsm.update(&drifting, 1, 33.3);

        assert!(event1.is_none());
        assert!(event2.is_none());
        assert_eq!(fsm.current_state(), "CENTERED");

        // Third frame should trigger transition to DRIFTING
        let event3 = fsm.update(&drifting, 2, 66.6);

        assert!(event3.is_none()); // No event for DRIFTING
        assert_eq!(fsm.current_state(), "DRIFTING");
    }

    #[test]
    fn test_complete_lane_change_emits_event() {
        let config = LaneChangeConfig {
            drift_threshold: 0.2,
            crossing_threshold: 0.4,
            min_frames_confirm: 2,
            cooldown_frames: 0,
            ..Default::default()
        };
        let mut fsm = LaneChangeStateMachine::new(config);

        let mut events = Vec::new();
        let mut frame_id = 0u64;

        // Phase 1: Start drifting (25% offset)
        let drifting = create_vehicle_state(100.0, 400.0);
        for _ in 0..3 {
            if let Some(e) = fsm.update(&drifting, frame_id, frame_id as f64 * 33.3) {
                events.push(e);
            }
            frame_id += 1;
        }
        assert_eq!(fsm.current_state(), "DRIFTING");

        // Phase 2: Cross boundary (50% offset)
        let crossing = create_vehicle_state(200.0, 400.0);
        for _ in 0..3 {
            if let Some(e) = fsm.update(&crossing, frame_id, frame_id as f64 * 33.3) {
                events.push(e);
            }
            frame_id += 1;
        }
        assert_eq!(fsm.current_state(), "CROSSING");

        // Phase 3: Re-center in new lane
        let centered = create_vehicle_state(10.0, 400.0);
        for _ in 0..3 {
            if let Some(e) = fsm.update(&centered, frame_id, frame_id as f64 * 33.3) {
                events.push(e);
            }
            frame_id += 1;
        }

        // Should have emitted a COMPLETED event
        assert_eq!(events.len(), 1);
        assert_eq!(events[0].direction, Direction::Right);
        assert!(events[0].duration_ms.is_some());
        assert!(events[0].duration_ms.unwrap() > 0.0);
    }

    #[test]
    fn test_direction_tracking_left() {
        let config = LaneChangeConfig {
            drift_threshold: 0.2,
            crossing_threshold: 0.4,
            min_frames_confirm: 2,
            cooldown_frames: 0,
            ..Default::default()
        };
        let mut fsm = LaneChangeStateMachine::new(config);

        let mut event: Option<LaneChangeEvent> = None;
        let mut frame_id = 0u64;

        // Negative offset = drifting left
        let drifting_left = create_vehicle_state(-100.0, 400.0);
        for _ in 0..3 {
            if let Some(e) = fsm.update(&drifting_left, frame_id, frame_id as f64 * 33.3) {
                event = Some(e);
            }
            frame_id += 1;
        }

        let crossing_left = create_vehicle_state(-200.0, 400.0);
        for _ in 0..3 {
            if let Some(e) = fsm.update(&crossing_left, frame_id, frame_id as f64 * 33.3) {
                event = Some(e);
            }
            frame_id += 1;
        }

        let centered = create_vehicle_state(-10.0, 400.0);
        for _ in 0..3 {
            if let Some(e) = fsm.update(&centered, frame_id, frame_id as f64 * 33.3) {
                event = Some(e);
            }
            frame_id += 1;
        }

        assert!(event.is_some());
        let e = event.unwrap();
        assert_eq!(e.direction, Direction::Left);
        assert_eq!(e.direction_name(), "LEFT");
    }

    #[test]
    fn test_reset_clears_state() {
        let mut fsm = LaneChangeStateMachine::new(create_config());

        // Get into DRIFTING state
        let drifting = create_vehicle_state(100.0, 400.0);
        for i in 0..5 {
            fsm.update(&drifting, i, i as f64 * 33.3);
        }
        assert_eq!(fsm.current_state(), "DRIFTING");

        // Reset
        fsm.reset();
        assert_eq!(fsm.current_state(), "CENTERED");
    }
}
// src/analysis/position_estimator.rs

use crate::types::{Lane, LanePosition, VehicleState};
use tracing::debug;

/// Estimates vehicle lateral position from lane detections
pub struct PositionEstimator {
    /// Vertical position for measurement (0=top, 1=bottom)
    pub reference_y_ratio: f32,
    /// Minimum acceptable lane width in pixels
    pub min_lane_width: f32,
    /// Maximum acceptable lane width in pixels
    pub max_lane_width: f32,
}

impl PositionEstimator {
    pub fn new(reference_y_ratio: f32) -> Self {
        Self {
            reference_y_ratio,
            min_lane_width: 100.0,
            max_lane_width: 1000.0,
        }
    }

    /// Estimate vehicle position from detected lanes
    pub fn estimate(&self, lanes: &[Lane], frame_width: u32, frame_height: u32) -> VehicleState {
        let vehicle_x = frame_width as f32 / 2.0;
        let reference_y = frame_height as f32 * self.reference_y_ratio;

        // Find ego lane boundaries (lanes closest to center on each side)
        let left_lane = self.find_ego_lane(lanes, vehicle_x, true);
        let right_lane = self.find_ego_lane(lanes, vehicle_x, false);

        // Calculate positions at reference Y
        let left_x = left_lane.and_then(|l| l.get_x_at_y(reference_y));
        let right_x = right_lane.and_then(|l| l.get_x_at_y(reference_y));

        // Calculate lane width and offset
        let mut lane_width: Option<f32> = None;
        let mut lateral_offset = 0.0f32;

        match (left_x, right_x) {
            (Some(lx), Some(rx)) => {
                let width = rx - lx;

                // Validate lane width
                if width >= self.min_lane_width && width <= self.max_lane_width {
                    lane_width = Some(width);
                    let lane_center = (lx + rx) / 2.0;
                    // Offset: positive = right of center, negative = left of center
                    lateral_offset = vehicle_x - lane_center;
                } else {
                    debug!(
                        "Invalid lane width: {:.1} (min: {:.1}, max: {:.1})",
                        width, self.min_lane_width, self.max_lane_width
                    );
                }
            }
            (Some(lx), None) => {
                // Only left lane visible
                lateral_offset = vehicle_x - lx;
            }
            (None, Some(rx)) => {
                // Only right lane visible
                lateral_offset = vehicle_x - rx;
            }
            (None, None) => {}
        }

        VehicleState {
            lateral_offset,
            lane_width,
            heading_offset: 0.0,
            frame_id: 0,
            timestamp_ms: 0.0,
        }
    }

    /// Find the ego lane boundary on one side
    fn find_ego_lane<'a>(
        &self,
        lanes: &'a [Lane],
        vehicle_x: f32,
        is_left: bool,
    ) -> Option<&'a Lane> {
        let mut candidates: Vec<(&Lane, f32)> = Vec::new();

        for lane in lanes {
            if lane.points.is_empty() {
                continue;
            }

            let avg_x = lane.avg_x();

            if is_left {
                // Left boundary should be to the left of vehicle
                if avg_x < vehicle_x {
                    let distance = vehicle_x - avg_x;
                    candidates.push((lane, distance));
                }
            } else {
                // Right boundary should be to the right of vehicle
                if avg_x > vehicle_x {
                    let distance = avg_x - vehicle_x;
                    candidates.push((lane, distance));
                }
            }
        }

        // Return closest lane
        candidates.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap_or(std::cmp::Ordering::Equal));
        candidates.first().map(|(lane, _)| *lane)
    }
}

/// Temporal smoothing for position estimates using EMA
pub struct PositionSmoother {
    alpha: f32,
    smoothed_offset: Option<f32>,
    smoothed_width: Option<f32>,
}

impl PositionSmoother {
    pub fn new(alpha: f32) -> Self {
        Self {
            alpha,
            smoothed_offset: None,
            smoothed_width: None,
        }
    }

    /// Apply temporal smoothing to vehicle state
    pub fn smooth(&mut self, state: VehicleState) -> VehicleState {
        // Smooth lateral offset
        let smoothed_offset = match self.smoothed_offset {
            None => {
                self.smoothed_offset = Some(state.lateral_offset);
                state.lateral_offset
            }
            Some(prev) => {
                let new_val = self.alpha * state.lateral_offset + (1.0 - self.alpha) * prev;
                self.smoothed_offset = Some(new_val);
                new_val
            }
        };

        // Smooth lane width
        let smoothed_width = if let Some(width) = state.lane_width {
            match self.smoothed_width {
                None => {
                    self.smoothed_width = Some(width);
                    Some(width)
                }
                Some(prev) => {
                    let new_val = self.alpha * width + (1.0 - self.alpha) * prev;
                    self.smoothed_width = Some(new_val);
                    Some(new_val)
                }
            }
        } else {
            self.smoothed_width
        };

        VehicleState {
            lateral_offset: smoothed_offset,
            lane_width: smoothed_width,
            heading_offset: state.heading_offset,
            frame_id: state.frame_id,
            timestamp_ms: state.timestamp_ms,
        }
    }

    /// Reset smoother state
    pub fn reset(&mut self) {
        self.smoothed_offset = None;
        self.smoothed_width = None;
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::types::Point;

    fn create_test_lane(lane_id: usize, x_positions: &[f32], y_start: f32, y_step: f32) -> Lane {
        let points: Vec<Point> = x_positions
            .iter()
            .enumerate()
            .map(|(i, &x)| Point::new(x, y_start + i as f32 * y_step))
            .collect();

        Lane {
            lane_id,
            points,
            confidence: 0.9,
            position: None,
        }
    }

    #[test]
    fn test_position_estimator_centered() {
        let estimator = PositionEstimator::new(0.8);

        // Create left and right lanes centered around frame center
        let left_lane = create_test_lane(0, &[400.0, 410.0, 420.0], 200.0, 50.0);
        let right_lane = create_test_lane(1, &[880.0, 870.0, 860.0], 200.0, 50.0);

        let lanes = vec![left_lane, right_lane];
        let state = estimator.estimate(&lanes, 1280, 720);

        assert!(state.is_valid());
        assert!(state.lateral_offset.abs() < 50.0); // Roughly centered
    }

    #[test]
    fn test_smoother_reduces_jitter() {
        let mut smoother = PositionSmoother::new(0.3);

        let states = vec![
            VehicleState {
                lateral_offset: 10.0,
                lane_width: Some(400.0),
                heading_offset: 0.0,
                frame_id: 0,
                timestamp_ms: 0.0,
            },
            VehicleState {
                lateral_offset: 50.0,
                lane_width: Some(400.0),
                heading_offset: 0.0,
                frame_id: 1,
                timestamp_ms: 33.3,
            }, // spike
            VehicleState {
                lateral_offset: 12.0,
                lane_width: Some(400.0),
                heading_offset: 0.0,
                frame_id: 2,
                timestamp_ms: 66.6,
            },
        ];

        let mut smoothed_values = Vec::new();
        for state in states {
            let smoothed = smoother.smooth(state);
            smoothed_values.push(smoothed.lateral_offset);
        }

        // The spike at 50.0 should be dampened
        assert!(smoothed_values[1] < 50.0);
        assert!(smoothed_values[1] > 10.0);
    }
}
// src/analysis/mod.rs

mod lane_analyzer;
mod position_estimator;
mod state_machine;

pub use lane_analyzer::LaneChangeAnalyzer;
// src/analysis/lane_analyzer.rs

use crate::analysis::position_estimator::{PositionEstimator, PositionSmoother};
use crate::analysis::state_machine::LaneChangeStateMachine;
use crate::types::{Lane, LaneChangeConfig, LaneChangeEvent, VehicleState};
use tracing::debug;

/// High-level analyzer for lane change detection (matching Python's LaneChangeAnalyzer)
pub struct LaneChangeAnalyzer {
    position_estimator: PositionEstimator,
    smoother: PositionSmoother,
    state_machine: LaneChangeStateMachine,
    config: LaneChangeConfig,
    last_state: Option<VehicleState>,
}

impl LaneChangeAnalyzer {
    pub fn new(config: LaneChangeConfig) -> Self {
        let position_estimator = PositionEstimator::new(config.reference_y_ratio);
        let smoother = PositionSmoother::new(config.smoothing_alpha);
        let state_machine = LaneChangeStateMachine::new(config.clone());

        Self {
            position_estimator,
            smoother,
            state_machine,
            config,
            last_state: None,
        }
    }

    /// Analyze lanes for lane change events
    ///
    /// Performs the full analysis pipeline:
    /// 1. Estimate vehicle position from lanes
    /// 2. Apply temporal smoothing
    /// 3. Update state machine
    /// 4. Return event if lane change detected
    pub fn analyze(
        &mut self,
        lanes: &[Lane],
        frame_width: u32,
        frame_height: u32,
        frame_id: u64,
        timestamp_ms: f64,
    ) -> Option<LaneChangeEvent> {
        // Estimate raw vehicle position
        let mut raw_state = self
            .position_estimator
            .estimate(lanes, frame_width, frame_height);
        raw_state.frame_id = frame_id;
        raw_state.timestamp_ms = timestamp_ms;

        // Apply temporal smoothing
        let smoothed_state = self.smoother.smooth(raw_state);
        self.last_state = Some(smoothed_state);

        // Update state machine and check for lane change
        self.state_machine
            .update(&smoothed_state, frame_id, timestamp_ms)
    }

    /// Analyze pre-computed vehicle state for lane change
    pub fn analyze_with_state(
        &mut self,
        vehicle_state: &VehicleState,
        frame_id: u64,
        timestamp_ms: f64,
    ) -> Option<LaneChangeEvent> {
        self.state_machine
            .update(vehicle_state, frame_id, timestamp_ms)
    }

    /// Get current state machine state name
    pub fn current_state(&self) -> &str {
        self.state_machine.current_state()
    }

    /// Get last computed vehicle state
    pub fn last_vehicle_state(&self) -> Option<&VehicleState> {
        self.last_state.as_ref()
    }

    /// Reset analyzer for new video processing
    pub fn reset(&mut self) {
        self.state_machine.reset();
        self.smoother.reset();
        self.last_state = None;
    }

    /// Update source ID for new video
    pub fn set_source_id(&mut self, source_id: String) {
        self.state_machine.set_source_id(source_id);
    }

    /// Get the config
    pub fn config(&self) -> &LaneChangeConfig {
        &self.config
    }
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::types::Point;

    fn create_test_lanes(left_x: f32, right_x: f32) -> Vec<Lane> {
        vec![
            Lane {
                lane_id: 0,
                points: vec![
                    Point::new(left_x, 100.0),
                    Point::new(left_x + 10.0, 200.0),
                    Point::new(left_x + 20.0, 300.0),
                    Point::new(left_x + 30.0, 400.0),
                    Point::new(left_x + 40.0, 500.0),
                ],
                confidence: 0.9,
                position: None,
            },
            Lane {
                lane_id: 1,
                points: vec![
                    Point::new(right_x, 100.0),
                    Point::new(right_x - 10.0, 200.0),
                    Point::new(right_x - 20.0, 300.0),
                    Point::new(right_x - 30.0, 400.0),
                    Point::new(right_x - 40.0, 500.0),
                ],
                confidence: 0.9,
                position: None,
            },
        ]
    }

    #[test]
    fn test_analyzer_integration() {
        let config = LaneChangeConfig {
            min_frames_confirm: 2,
            cooldown_frames: 0,
            ..Default::default()
        };
        let mut analyzer = LaneChangeAnalyzer::new(config);

        let frame_width = 1280u32;
        let frame_height = 720u32;

        // Centered lanes (vehicle at x=640, lanes at 400 and 880)
        let centered_lanes = create_test_lanes(400.0, 880.0);

        // Process several centered frames
        for i in 0..5 {
            let event = analyzer.analyze(
                &centered_lanes,
                frame_width,
                frame_height,
                i,
                i as f64 * 33.3,
            );
            assert!(event.is_none());
        }

        assert_eq!(analyzer.current_state(), "CENTERED");

        // Check that we have a valid last state
        let last_state = analyzer.last_vehicle_state();
        assert!(last_state.is_some());
        assert!(last_state.unwrap().is_valid());
    }

    #[test]
    fn test_analyzer_reset() {
        let config = LaneChangeConfig::default();
        let mut analyzer = LaneChangeAnalyzer::new(config);

        // Do some processing
        let lanes = create_test_lanes(200.0, 680.0); // Off-center
        for i in 0..10 {
            analyzer.analyze(&lanes, 1280, 720, i, i as f64 * 33.3);
        }

        // Reset
        analyzer.reset();

        assert_eq!(analyzer.current_state(), "CENTERED");
        assert!(analyzer.last_vehicle_state().is_none());
    }
}
use crate::types::Config;
use anyhow::Result;
use std::fs;

impl Config {
    pub fn load(path: &str) -> Result<Self> {
        let contents = fs::read_to_string(path)?;
        let config: Config = serde_yaml::from_str(&contents)?;
        Ok(config)
    }
}
use crate::types::{Config, Lane};
use anyhow::Result;
use tracing::info;

pub struct LaneDetectionResult {
    pub lanes: Vec<Lane>,
    pub timestamp: f64,
}

// CULane row anchors (normalized to 320 height)
const ROW_ANCHORS: [f32; 72] = [
    121.0, 131.0, 141.0, 150.0, 160.0, 170.0, 180.0, 189.0, 199.0, 209.0, 219.0, 228.0, 238.0,
    248.0, 258.0, 267.0, 277.0, 287.0, 297.0, 306.0, 316.0, 326.0, 336.0, 345.0, 355.0, 365.0,
    375.0, 384.0, 394.0, 404.0, 414.0, 423.0, 433.0, 443.0, 453.0, 462.0, 472.0, 482.0, 492.0,
    501.0, 511.0, 521.0, 531.0, 540.0, 550.0, 560.0, 570.0, 579.0, 589.0, 599.0, 609.0, 618.0,
    628.0, 638.0, 648.0, 657.0, 667.0, 677.0, 687.0, 696.0, 706.0, 716.0, 726.0, 735.0, 745.0,
    755.0, 765.0, 774.0, 784.0, 794.0, 804.0, 813.0,
];

pub fn parse_lanes(
    output: &[f32],
    frame_width: f32,
    frame_height: f32,
    config: &Config,
    timestamp: f64,
) -> Result<LaneDetectionResult> {
    // DEBUG: Check output values
    let max_val = output.iter().copied().fold(f32::NEG_INFINITY, f32::max);
    let min_val = output.iter().copied().fold(f32::INFINITY, f32::min);
    let avg_val = output.iter().sum::<f32>() / output.len() as f32;

    info!(
        "Output stats - min: {:.4}, max: {:.4}, avg: {:.4}",
        min_val, max_val, avg_val
    );

    // Model output shape: [1, griding_num, num_anchors, num_lanes]
    // = [1, 200, 72, 4]

    let griding_num = config.model.griding_num;
    let num_anchors = config.model.num_anchors;
    let num_lanes = config.model.num_lanes;

    info!(
        "Config - griding: {}, anchors: {}, lanes: {}",
        griding_num, num_anchors, num_lanes
    );

    let mut lanes = Vec::new();

    // Process each lane
    for lane_idx in 0..num_lanes {
        let mut points = Vec::new();
        let mut total_confidence = 0.0;
        let mut point_count = 0;

        // Process each anchor (row)
        for anchor_idx in 0..num_anchors {
            // Find the grid position with max probability
            let mut max_prob = f32::NEG_INFINITY;
            let mut max_grid_idx = 0;

            // Check each grid position
            for grid_idx in 0..griding_num {
                // Index calculation for shape [1, 200, 72, 4]
                // Skip batch dimension (0), so: [grid, anchor, lane]
                let idx = grid_idx * (num_anchors * num_lanes) + anchor_idx * num_lanes + lane_idx;

                let prob = output[idx];
                if prob > max_prob {
                    max_prob = prob;
                    max_grid_idx = grid_idx;
                }
            }

            // Use sigmoid for confidence (simpler than softmax)
            let confidence = 1.0 / (1.0 + (-max_prob).exp());

            // LOWERED THRESHOLD for debugging
            if confidence >= 0.1 && max_grid_idx < griding_num {
                // Convert grid position to pixel coordinates
                let x = (max_grid_idx as f32 / griding_num as f32) * frame_width;

                // Y coordinate from row anchor (scaled to frame height)
                let y = (ROW_ANCHORS[anchor_idx] / config.model.input_height as f32) * frame_height;

                points.push((x, y));
                total_confidence += confidence;
                point_count += 1;
            }
        }

        // LOWERED THRESHOLD: Only need 3+ points
        if points.len() >= 3 {
            let avg_confidence = if point_count > 0 {
                total_confidence / point_count as f32
            } else {
                0.0
            };

            info!(
                "Lane {} detected with {} points, confidence: {:.4}",
                lane_idx,
                points.len(),
                avg_confidence
            );

            lanes.push(Lane {
                points,
                confidence: avg_confidence,
            });
        }
    }

    info!("Total lanes detected: {}", lanes.len());

    Ok(LaneDetectionResult { lanes, timestamp })
}

pub fn find_vehicle_lane_with_confidence(
    lanes: &[Lane],
    frame_width: f32,
) -> Option<(usize, f32, f32)> {
    if lanes.len() < 2 {
        return None;
    }

    let vehicle_x = frame_width / 2.0;

    let mut lane_positions: Vec<(usize, f32, f32)> = lanes
        .iter()
        .enumerate()
        .filter_map(|(idx, lane)| lane.points.last().map(|p| (idx, p.0, lane.confidence)))
        .collect();

    lane_positions.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap());

    for i in 0..lane_positions.len() - 1 {
        let (_, left_x, left_conf) = lane_positions[i];
        let (_, right_x, right_conf) = lane_positions[i + 1];

        if left_x <= vehicle_x && vehicle_x <= right_x {
            let lane_width = right_x - left_x;
            let offset_from_left = vehicle_x - left_x;
            let normalized_offset = (offset_from_left / lane_width - 0.5) * 2.0;
            let confidence = left_conf.min(right_conf);

            return Some((i, normalized_offset, confidence));
        }
    }

    None
}
// src/overtake_detector.rs

use crate::types::{Config, Direction, LaneChangeEvent, OvertakeEvent, VehiclePosition};
use std::collections::VecDeque;
use tracing::info;

pub struct DetectorResult {
    pub lane_change: Option<LaneChangeEvent>,
    pub overtake: Option<OvertakeEvent>,
}

pub struct OvertakeDetector {
    config: Config,
    lane_history: VecDeque<(i32, f64)>,
    last_stable_lane: Option<i32>,
    last_change_time: Option<f64>,
    recent_changes: Vec<LaneChangeEvent>,
    calibration_frames: Vec<i32>,
    baseline_lane: Option<i32>,
    is_calibrated: bool,
}

impl OvertakeDetector {
    pub fn new(config: Config) -> Self {
        Self {
            config,
            lane_history: VecDeque::with_capacity(30),
            last_stable_lane: None,
            last_change_time: None,
            recent_changes: Vec::new(),
            calibration_frames: Vec::new(),
            baseline_lane: None,
            is_calibrated: false,
        }
    }

    /// Update with VehiclePosition (smoothed position)
    pub fn update_with_position(&mut self, position: VehiclePosition) -> DetectorResult {
        // Handle calibration phase
        if !self.is_calibrated {
            self.calibration_frames.push(position.lane_index);

            if self.calibration_frames.len() >= self.config.detection.calibration_frames {
                self.baseline_lane = Some(self.compute_baseline_lane());
                self.last_stable_lane = self.baseline_lane;
                self.is_calibrated = true;
                info!(
                    " Calibration complete! Baseline lane: {}",
                    self.baseline_lane.unwrap()
                );
            }

            return DetectorResult {
                lane_change: None,
                overtake: None,
            };
        }

        // After calibration, detect lane changes and overtakes
        let overtake = self.update(
            position.lane_index,
            position.lateral_offset,
            position.timestamp,
        );

        // Extract the lane change event if one occurred
        let lane_change = if overtake.is_some() {
            self.recent_changes.last().cloned()
        } else {
            None
        };

        DetectorResult {
            lane_change,
            overtake,
        }
    }

    /// Check if calibration is complete
    pub fn is_calibrated(&self) -> bool {
        self.is_calibrated
    }

    /// Get the baseline lane from calibration
    pub fn get_baseline_lane(&self) -> Option<i32> {
        self.baseline_lane
    }

    /// Original update method (used internally)
    pub fn update(
        &mut self,
        current_lane: i32,
        _lateral_offset: f32,
        timestamp: f64,
    ) -> Option<OvertakeEvent> {
        // Add to history
        self.lane_history.push_back((current_lane, timestamp));
        if self.lane_history.len() > 30 {
            self.lane_history.pop_front();
        }

        // Get stable lane (mode of last 10 frames)
        let stable_lane = self.get_stable_lane();

        // Detect lane change
        if let Some(prev_stable) = self.last_stable_lane {
            if stable_lane != prev_stable {
                let event = LaneChangeEvent {
                    timestamp,
                    direction: if stable_lane > prev_stable {
                        Direction::Right
                    } else {
                        Direction::Left
                    },
                    from_lane: prev_stable,
                    to_lane: stable_lane,
                    confidence: 0.8, // You can calculate actual confidence
                };

                info!(
                    "Lane change detected: {:?} from {} to {}",
                    event.direction, event.from_lane, event.to_lane
                );

                // Check for overtake
                let overtake = self.check_overtake(&event);

                self.last_stable_lane = Some(stable_lane);
                self.last_change_time = Some(timestamp);

                return overtake;
            }
        } else {
            self.last_stable_lane = Some(stable_lane);
        }

        None
    }

    fn get_stable_lane(&self) -> i32 {
        if self.lane_history.is_empty() {
            return -1;
        }

        // Get mode of last 10 frames
        let recent: Vec<i32> = self
            .lane_history
            .iter()
            .rev()
            .take(10)
            .map(|(lane, _)| *lane)
            .collect();

        let mut counts = std::collections::HashMap::new();
        for &lane in &recent {
            *counts.entry(lane).or_insert(0) += 1;
        }

        counts
            .into_iter()
            .max_by_key(|(_, count)| *count)
            .map(|(lane, _)| lane)
            .unwrap_or(-1)
    }

    fn check_overtake(&mut self, current_event: &LaneChangeEvent) -> Option<OvertakeEvent> {
        self.recent_changes.push(current_event.clone());

        self.recent_changes.retain(|e| {
            current_event.timestamp - e.timestamp < self.config.overtake.max_window_seconds
        });

        if self.recent_changes.len() < 2 {
            return None;
        }

        let prev = &self.recent_changes[self.recent_changes.len() - 2];
        let curr = current_event;
        let delta = curr.timestamp - prev.timestamp;

        // Check timing constraints
        if delta < self.config.overtake.min_interval_seconds
            || delta > self.config.overtake.max_window_seconds
        {
            return None;
        }

        //  NEW: Only process opposite directions
        let is_complete = (prev.direction == Direction::Left && curr.direction == Direction::Right)
            || (prev.direction == Direction::Right && curr.direction == Direction::Left);

        //  NEW: Don't return anything for same-direction pairs
        if !is_complete {
            return None; // Changed from creating incomplete event
        }

        if is_complete {
            info!(" OVERTAKE DETECTED!");
        }

        Some(OvertakeEvent {
            start_timestamp: prev.timestamp,
            end_timestamp: curr.timestamp,
            first_direction: prev.direction,
            second_direction: curr.direction,
            start_lane: prev.from_lane,
            end_lane: curr.to_lane,
            is_complete,
            confidence: (prev.confidence + curr.confidence) / 2.0,
        })
    }

    /// Compute the baseline lane from calibration frames (mode)
    fn compute_baseline_lane(&self) -> i32 {
        let mut counts = std::collections::HashMap::new();
        for &lane in &self.calibration_frames {
            *counts.entry(lane).or_insert(0) += 1;
        }

        *counts
            .iter()
            .max_by_key(|(_, count)| *count)
            .map(|(lane, _)| lane)
            .unwrap_or(&1) // Default to lane 1 if no data
    }

    /// Reset the detector (useful for new video or scene changes)
    pub fn reset(&mut self) {
        self.lane_history.clear();
        self.last_stable_lane = None;
        self.last_change_time = None;
        self.recent_changes.clear();
        self.calibration_frames.clear();
        self.baseline_lane = None;
        self.is_calibrated = false;
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    fn create_test_config() -> Config {
        // You'll need to create a minimal valid config for testing
        // This is just a placeholder structure
        Config {
            model: crate::types::ModelConfig {
                path: "test.onnx".to_string(),
                input_width: 1600,
                input_height: 320,
                num_anchors: 72,
                num_lanes: 4,
                griding_num: 200,
            },
            inference: crate::types::InferenceConfig {
                use_tensorrt: false,
                use_fp16: false,
                enable_engine_cache: false,
                engine_cache_path: "".to_string(),
                num_threads: 4,
            },
            detection: crate::types::DetectionConfig {
                confidence_threshold: 0.5,
                min_points_per_lane: 5,
                smoother_window_size: 10,
                calibration_frames: 90,
                debounce_frames: 15,
                confirm_frames: 20,
                min_lane_confidence: 0.6,
                min_position_confidence: 0.5,
            },
            overtake: crate::types::OvertakeConfig {
                lane_change_offset_threshold: 0.7,
                debounce_frames: 15,
                confirm_frames: 20,
                max_window_seconds: 10.0,
                min_interval_seconds: 1.0,
            },
            video: crate::types::VideoConfig {
                input_dir: "".to_string(),
                output_dir: "".to_string(),
                source_width: 1920,
                source_height: 1080,
                target_fps: 30,
                save_annotated: true,
                save_events_only: false,
            },
            logging: crate::types::LoggingConfig {
                level: "info".to_string(),
            },
        }
    }

    #[test]
    fn test_calibration() {
        let config = create_test_config();
        let mut detector = OvertakeDetector::new(config);

        assert!(!detector.is_calibrated());
        assert_eq!(detector.get_baseline_lane(), None);

        // Simulate calibration with 90 frames in lane 1
        for i in 0..90 {
            let position = VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: i as f64 * 0.033,
            };
            detector.update_with_position(position);
        }

        assert!(detector.is_calibrated());
        assert_eq!(detector.get_baseline_lane(), Some(1));
    }

    #[test]
    fn test_lane_change_detection() {
        let config = create_test_config();
        let mut detector = OvertakeDetector::new(config);

        // Complete calibration
        for i in 0..90 {
            let position = VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: i as f64 * 0.033,
            };
            detector.update_with_position(position);
        }

        // Stay in lane 1 for a bit
        for i in 90..120 {
            let position = VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: i as f64 * 0.033,
            };
            let result = detector.update_with_position(position);
            assert!(result.lane_change.is_none());
        }

        // Change to lane 2
        for i in 120..150 {
            let position = VehiclePosition {
                lane_index: 2,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: i as f64 * 0.033,
            };
            let result = detector.update_with_position(position);

            // Should detect lane change at some point
            if result.lane_change.is_some() {
                let event = result.lane_change.unwrap();
                assert_eq!(event.from_lane, 1);
                assert_eq!(event.to_lane, 2);
                assert_eq!(event.direction, Direction::Right);
                return; // Test passed
            }
        }
    }
}
// src/main.rs

mod analysis;
mod inference;
mod lane_detection;
mod preprocessing;
mod types;
mod video_processor;

use analysis::LaneChangeAnalyzer;
use anyhow::Result;
use std::path::Path;
use tracing::{debug, error, info};
use types::{DetectedLane, Lane, LaneChangeConfig, LaneChangeEvent};

#[tokio::main]
async fn main() -> Result<()> {
    tracing_subscriber::fmt()
        .with_env_filter("overtake_detection=info,ort=warn")
        .init();

    info!(" Lane Change Detection System Starting");

    let config = types::Config::load("config.yaml")?;
    info!(" Configuration loaded");

    let mut inference_engine = inference::InferenceEngine::new(config.clone())?;
    info!(" Inference engine ready");

    let video_processor = video_processor::VideoProcessor::new(config.clone());

    let video_files = video_processor.find_video_files()?;

    if video_files.is_empty() {
        error!("No video files found in {}", config.video.input_dir);
        return Ok(());
    }

    info!("Found {} video file(s) to process", video_files.len());

    for (idx, video_path) in video_files.iter().enumerate() {
        info!("\n========================================");
        info!(
            "Processing video {}/{}: {}",
            idx + 1,
            video_files.len(),
            video_path.display()
        );
        info!("========================================\n");

        match process_video(
            &video_path,
            &mut inference_engine,
            &video_processor,
            &config,
        )
        .await
        {
            Ok(stats) => {
                info!("\n Video processed successfully!");
                info!("  Total frames: {}", stats.total_frames);
                info!(
                    "  Frames with valid position: {} ({:.1}%)",
                    stats.frames_with_position,
                    (stats.frames_with_position as f32 / stats.total_frames as f32) * 100.0
                );
                info!("  Lane changes detected: {}", stats.lane_changes_detected);
                info!("  Processing time: {:.2}s", stats.duration_secs);
                info!("  Average FPS: {:.2}", stats.avg_fps);
            }
            Err(e) => {
                error!("Failed to process video: {}", e);
            }
        }
    }

    info!("\n All videos processed!");
    Ok(())
}

struct ProcessingStats {
    total_frames: u64,
    frames_with_position: u64,
    lane_changes_detected: usize,
    duration_secs: f64,
    avg_fps: f64,
}

async fn process_video(
    video_path: &Path,
    inference_engine: &mut inference::InferenceEngine,
    video_processor: &video_processor::VideoProcessor,
    config: &types::Config,
) -> Result<ProcessingStats> {
    use std::time::Instant;

    let start_time = Instant::now();

    let mut reader = video_processor.open_video(video_path)?;

    let mut writer =
        video_processor.create_writer(video_path, reader.width, reader.height, reader.fps)?;

    let lane_change_config = LaneChangeConfig {
        drift_threshold: 0.2,
        crossing_threshold: 0.4,
        min_frames_confirm: config.detection.confirm_frames,
        cooldown_frames: 30,
        smoothing_alpha: 0.3,
        reference_y_ratio: 0.8,
    };

    let mut analyzer = LaneChangeAnalyzer::new(lane_change_config);
    analyzer.set_source_id(video_path.to_string_lossy().to_string());

    info!(" Lane Change Analyzer Configuration:");
    info!(
        "   Drift threshold: {:.0}% of lane width",
        analyzer.config().drift_threshold * 100.0
    );
    info!(
        "   Crossing threshold: {:.0}% of lane width",
        analyzer.config().crossing_threshold * 100.0
    );
    info!(
        "   Min frames to confirm: {}",
        analyzer.config().min_frames_confirm
    );
    info!("   Cooldown frames: {}", analyzer.config().cooldown_frames);

    let mut lane_changes: Vec<LaneChangeEvent> = Vec::new();
    let mut frame_count: u64 = 0;
    let mut frames_with_valid_position: u64 = 0;

    while let Some(frame) = reader.read_frame()? {
        frame_count += 1;
        let timestamp_ms = frame.timestamp_ms;

        if frame_count % 30 == 0 {
            info!(
                "Progress: {:.1}% ({}/{}) | State: {} | Lane changes: {}",
                reader.progress(),
                reader.current_frame,
                reader.total_frames,
                analyzer.current_state(),
                lane_changes.len()
            );
        }

        match process_frame(&frame, inference_engine, config).await {
            Ok(detected_lanes) => {
                // Convert DetectedLane to Lane for analysis
                let analysis_lanes: Vec<Lane> = detected_lanes
                    .iter()
                    .enumerate()
                    .map(|(i, dl)| Lane::from_detected(i, dl))
                    .collect();

                // Run lane change analysis
                if let Some(event) = analyzer.analyze(
                    &analysis_lanes,
                    frame.width as u32,
                    frame.height as u32,
                    frame_count,
                    timestamp_ms,
                ) {
                    lane_changes.push(event.clone());
                    info!(
                        " LANE CHANGE #{}: {} at {:.2}s (frame {}) - Duration: {:.0}ms",
                        lane_changes.len(),
                        event.direction_name(),
                        event.video_timestamp_ms / 1000.0,
                        event.frame_id,
                        event.duration_ms.unwrap_or(0.0)
                    );
                }

                // Track valid positions
                if analyzer
                    .last_vehicle_state()
                    .map_or(false, |s| s.is_valid())
                {
                    frames_with_valid_position += 1;
                }

                // Debug logging
                if frame_count % 30 == 0 {
                    if let Some(vs) = analyzer.last_vehicle_state() {
                        if vs.is_valid() {
                            let normalized = vs.normalized_offset().unwrap_or(0.0);
                            debug!(
                                "Frame {}: State={}, Offset={:.1}px ({:.1}%), LaneWidth={:.0}px",
                                frame_count,
                                analyzer.current_state(),
                                vs.lateral_offset,
                                normalized * 100.0,
                                vs.lane_width.unwrap_or(0.0)
                            );
                        }
                    }
                }

                // Write annotated frame
                if let Some(ref mut w) = writer {
                    if let Ok(annotated) = video_processor::draw_lanes_with_state(
                        &frame.data,
                        reader.width,
                        reader.height,
                        &detected_lanes,
                        analyzer.current_state(),
                        analyzer.last_vehicle_state(),
                    ) {
                        use opencv::videoio::VideoWriterTrait;
                        w.write(&annotated)?;
                    }
                }
            }
            Err(e) => {
                error!("Frame {} processing failed: {}", frame_count, e);
            }
        }
    }

    let duration = start_time.elapsed();
    let avg_fps = frame_count as f64 / duration.as_secs_f64();

    info!("\n Processing Summary:");
    info!(
        "  Frames with valid position: {}/{} ({:.1}%)",
        frames_with_valid_position,
        frame_count,
        (frames_with_valid_position as f32 / frame_count as f32) * 100.0
    );
    info!("  Lane changes detected: {}", lane_changes.len());

    if !lane_changes.is_empty() {
        info!("\n   Lane change events:");
        for (i, event) in lane_changes.iter().enumerate() {
            info!(
                "    {}. {} at {:.2}s (frame {}) - duration: {:.0}ms",
                i + 1,
                event.direction_name(),
                event.video_timestamp_ms / 1000.0,
                event.frame_id,
                event.duration_ms.unwrap_or(0.0)
            );
        }
    }

    save_results(video_path, &lane_changes, config)?;

    Ok(ProcessingStats {
        total_frames: frame_count,
        frames_with_position: frames_with_valid_position,
        lane_changes_detected: lane_changes.len(),
        duration_secs: duration.as_secs_f64(),
        avg_fps,
    })
}

async fn process_frame(
    frame: &types::Frame,
    inference_engine: &mut inference::InferenceEngine,
    config: &types::Config,
) -> Result<Vec<DetectedLane>> {
    let preprocessed = preprocessing::preprocess(
        &frame.data,
        frame.width,
        frame.height,
        config.model.input_width,
        config.model.input_height,
    )?;

    let output = inference_engine.infer(&preprocessed)?;

    let lane_detection = lane_detection::parse_lanes(
        &output,
        frame.width as f32,
        frame.height as f32,
        config,
        frame.timestamp_ms,
    )?;

    let high_confidence_lanes: Vec<DetectedLane> = lane_detection
        .lanes
        .into_iter()
        .filter(|lane| lane.confidence > config.detection.min_lane_confidence)
        .collect();

    Ok(high_confidence_lanes)
}

fn save_results(
    video_path: &Path,
    lane_changes: &[LaneChangeEvent],
    config: &types::Config,
) -> Result<()> {
    use std::fs::File;
    use std::io::Write;

    std::fs::create_dir_all(&config.video.output_dir)?;

    let video_name = video_path.file_stem().unwrap().to_str().unwrap();

    // Save as JSON Lines
    let jsonl_path =
        Path::new(&config.video.output_dir).join(format!("{}_lane_changes.jsonl", video_name));
    let mut file = File::create(&jsonl_path)?;
    for event in lane_changes {
        let json_line = serde_json::to_string(&event.to_json())?;
        writeln!(file, "{}", json_line)?;
    }
    info!(" Lane changes saved to: {}", jsonl_path.display());

    // Save as pretty JSON
    let json_path =
        Path::new(&config.video.output_dir).join(format!("{}_lane_changes.json", video_name));
    let events_json: Vec<serde_json::Value> = lane_changes.iter().map(|e| e.to_json()).collect();
    let json = serde_json::to_string_pretty(&events_json)?;
    let mut file = File::create(&json_path)?;
    file.write_all(json.as_bytes())?;

    // Save summary
    let summary = serde_json::json!({
        "video": video_name,
        "total_lane_changes": lane_changes.len(),
        "events": lane_changes.iter().map(|e| e.to_json()).collect::<Vec<_>>(),
    });

    let summary_path =
        Path::new(&config.video.output_dir).join(format!("{}_summary.json", video_name));
    let json = serde_json::to_string_pretty(&summary)?;
    let mut file = File::create(&summary_path)?;
    file.write_all(json.as_bytes())?;
    info!(" Summary saved to: {}", summary_path.display());

    Ok(())
}
// src/preprocessing.rs

use anyhow::Result;

/// Preprocess raw RGB image for model input
pub fn preprocess(
    src: &[u8],
    src_width: usize,
    src_height: usize,
    dst_width: usize,
    dst_height: usize,
) -> Result<Vec<f32>> {
    // Resize
    let resized = resize_bilinear(src, src_width, src_height, dst_width, dst_height);

    // Normalize and convert HWC -> CHW
    const MEAN: [f32; 3] = [0.485, 0.456, 0.406];
    const STD: [f32; 3] = [0.229, 0.224, 0.225];

    let mut output = vec![0.0f32; 3 * dst_height * dst_width];

    for c in 0..3 {
        for h in 0..dst_height {
            for w in 0..dst_width {
                let hwc_idx = (h * dst_width + w) * 3 + c;
                let chw_idx = c * dst_height * dst_width + h * dst_width + w;

                let pixel = resized[hwc_idx] as f32 / 255.0;
                output[chw_idx] = (pixel - MEAN[c]) / STD[c];
            }
        }
    }

    Ok(output)
}

/// Bilinear image resize
fn resize_bilinear(src: &[u8], src_w: usize, src_h: usize, dst_w: usize, dst_h: usize) -> Vec<u8> {
    let mut dst = vec![0u8; dst_h * dst_w * 3];

    let x_ratio = src_w as f32 / dst_w as f32;
    let y_ratio = src_h as f32 / dst_h as f32;

    for dy in 0..dst_h {
        for dx in 0..dst_w {
            let sx = dx as f32 * x_ratio;
            let sy = dy as f32 * y_ratio;

            let sx0 = sx.floor() as usize;
            let sy0 = sy.floor() as usize;
            let sx1 = (sx0 + 1).min(src_w - 1);
            let sy1 = (sy0 + 1).min(src_h - 1);

            let fx = sx - sx0 as f32;
            let fy = sy - sy0 as f32;

            for c in 0..3 {
                let p00 = src[(sy0 * src_w + sx0) * 3 + c] as f32;
                let p10 = src[(sy0 * src_w + sx1) * 3 + c] as f32;
                let p01 = src[(sy1 * src_w + sx0) * 3 + c] as f32;
                let p11 = src[(sy1 * src_w + sx1) * 3 + c] as f32;

                let val = p00 * (1.0 - fx) * (1.0 - fy)
                    + p10 * fx * (1.0 - fy)
                    + p01 * (1.0 - fx) * fy
                    + p11 * fx * fy;

                dst[(dy * dst_w + dx) * 3 + c] = val.round() as u8;
            }
        }
    }

    dst
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_preprocess() {
        let src = vec![128u8; 640 * 480 * 3];
        let result = preprocess(&src, 640, 480, 1600, 320);
        assert!(result.is_ok());
        assert_eq!(result.unwrap().len(), 3 * 320 * 1600);
    }

    #[test]
    fn test_resize() {
        let src = vec![255u8; 100 * 100 * 3];
        let dst = resize_bilinear(&src, 100, 100, 50, 50);
        assert_eq!(dst.len(), 50 * 50 * 3);
    }
}
use opencv::{core, imgproc, prelude::*};

pub fn visualize_lanes(frame: &Mat, lanes: &[Lane], position: &VehiclePosition) -> Result<Mat> {
    let mut debug_frame = frame.clone();

    // Draw detected lanes with different colors
    let colors = [
        core::Scalar::new(255.0, 0.0, 0.0, 0.0),   // Blue - Lane 0
        core::Scalar::new(0.0, 255.0, 0.0, 0.0),   // Green - Lane 1
        core::Scalar::new(0.0, 0.0, 255.0, 0.0),   // Red - Lane 2
        core::Scalar::new(255.0, 255.0, 0.0, 0.0), // Cyan - Lane 3
    ];

    for (i, lane) in lanes.iter().enumerate() {
        // Draw lane points
        for window in lane.points.windows(2) {
            let p1 = core::Point::new(window[0].x as i32, window[0].y as i32);
            let p2 = core::Point::new(window[1].x as i32, window[1].y as i32);
            imgproc::line(
                &mut debug_frame,
                p1,
                p2,
                colors[i % 4],
                3,
                imgproc::LINE_8,
                0,
            )?;
        }

        // Draw lane ID
        if let Some(first_point) = lane.points.first() {
            imgproc::put_text(
                &mut debug_frame,
                &format!("L{} ({:.2})", i, lane.confidence),
                core::Point::new(first_point.x as i32, first_point.y as i32 - 10),
                imgproc::FONT_HERSHEY_SIMPLEX,
                0.6,
                colors[i % 4],
                2,
                imgproc::LINE_8,
                false,
            )?;
        }
    }

    // Draw vehicle position indicator
    let vehicle_x = frame.cols() / 2;
    let vehicle_y = (frame.rows() as f32 * 0.85) as i32;

    imgproc::circle(
        &mut debug_frame,
        core::Point::new(vehicle_x, vehicle_y),
        10,
        core::Scalar::new(0.0, 255.0, 255.0, 0.0), // Yellow
        -1,
        imgproc::LINE_8,
        0,
    )?;

    // Draw current lane info
    let info = format!(
        "Lane: {} | Offset: {:.2} | Conf: {:.2}",
        position.lane_index, position.lateral_offset, position.confidence
    );
    imgproc::put_text(
        &mut debug_frame,
        &info,
        core::Point::new(10, 30),
        imgproc::FONT_HERSHEY_SIMPLEX,
        0.8,
        core::Scalar::new(0.0, 255.0, 0.0, 0.0),
        2,
        imgproc::LINE_8,
        false,
    )?;

    Ok(debug_frame)
}
// src/inference.rs

use crate::types::Config;
use anyhow::{Context, Result};
use ort::{
    execution_providers::CUDAExecutionProvider,
    session::{builder::GraphOptimizationLevel, Session},
};
use tracing::{debug, info};

pub struct InferenceEngine {
    session: Session,
    config: Config,
}

impl InferenceEngine {
    pub fn new(config: Config) -> Result<Self> {
        info!("Initializing inference engine");
        info!("Model path: {}", config.model.path);

        let mut session_builder = Session::builder()?;

        // CUDA execution provider
        info!("Enabling CUDA execution provider");
        session_builder =
            session_builder.with_execution_providers([CUDAExecutionProvider::default()
                .with_device_id(0)
                .build()])?;

        info!("Building ONNX Runtime session...");
        let session = session_builder
            .with_optimization_level(GraphOptimizationLevel::Level3)?
            .with_intra_threads(config.inference.num_threads)?
            .with_inter_threads(1)?
            .commit_from_file(&config.model.path)
            .context("Failed to load model")?;

        info!(" Inference engine initialized successfully");

        Ok(Self { session, config })
    }

    pub fn infer(&mut self, input: &[f32]) -> Result<Vec<f32>> {
        debug!("Running inference");

        // Create shape tuple
        let shape = [
            1,
            3,
            self.config.model.input_height,
            self.config.model.input_width,
        ];

        // Create input value from tuple (shape, data)
        let input_value =
            ort::value::Value::from_array((shape.as_slice(), input.to_vec().into_boxed_slice()))?;

        // Run inference
        let outputs = self.session.run(ort::inputs!["input" => input_value])?;

        // Extract output
        let output = &outputs[0];
        let (output_shape, data_slice) = output.try_extract_tensor::<f32>()?;

        // DEBUG: Print actual output shape
        info!("Model output shape: {:?}", output_shape);
        info!("Model output size: {}", data_slice.len());

        // Convert slice to Vec
        let output_data: Vec<f32> = data_slice.to_vec();

        Ok(output_data)
    }
}
// src/detection/smoother.rs
use super::types::VehiclePosition;
use std::collections::{HashMap, VecDeque};

pub struct LanePositionSmoother {
    history: VecDeque<VehiclePosition>,
    window_size: usize,
}

impl LanePositionSmoother {
    pub fn new(window_size: usize) -> Self {
        Self {
            history: VecDeque::with_capacity(window_size),
            window_size,
        }
    }

    /// Smooth the position using temporal window
    pub fn smooth(&mut self, position: VehiclePosition) -> VehiclePosition {
        self.history.push_back(position);
        if self.history.len() > self.window_size {
            self.history.pop_front();
        }

        // Need at least 3 frames for smoothing
        if self.history.len() < 3 {
            return position;
        }

        VehiclePosition {
            lane_index: self.smooth_lane_index(),
            lateral_offset: self.smooth_lateral_offset(),
            confidence: self.smooth_confidence(),
            left_boundary: self.smooth_boundary(|p| p.left_boundary),
            right_boundary: self.smooth_boundary(|p| p.right_boundary),
            timestamp: position.timestamp, // Keep current timestamp
        }
    }

    /// Use mode (most common) for discrete lane index
    fn smooth_lane_index(&self) -> i32 {
        let mut counts: HashMap<i32, usize> = HashMap::new();
        for pos in &self.history {
            *counts.entry(pos.lane_index).or_insert(0) += 1;
        }

        counts
            .into_iter()
            .max_by_key(|(_, count)| *count)
            .map(|(lane, _)| lane)
            .unwrap_or(-1)
    }

    /// Use median for lateral offset (resistant to outliers)
    fn smooth_lateral_offset(&self) -> f32 {
        let mut offsets: Vec<f32> = self.history.iter().map(|p| p.lateral_offset).collect();
        offsets.sort_by(|a, b| a.partial_cmp(b).unwrap());
        offsets[offsets.len() / 2]
    }

    /// Average confidence
    fn smooth_confidence(&self) -> f32 {
        self.history.iter().map(|p| p.confidence).sum::<f32>() / self.history.len() as f32
    }

    /// Median for boundaries
    fn smooth_boundary<F>(&self, getter: F) -> f32
    where
        F: Fn(&VehiclePosition) -> f32,
    {
        let mut values: Vec<f32> = self.history.iter().map(&getter).collect();
        values.sort_by(|a, b| a.partial_cmp(b).unwrap());
        values[values.len() / 2]
    }

    /// Reset the smoother (e.g., after scene change)
    pub fn reset(&mut self) {
        self.history.clear();
    }
}
// src/detection/state_machine.rs
use super::types::{Direction, LaneChangeEvent, VehiclePosition};
use std::time::{Duration, Instant};

#[derive(Debug, Clone, Copy, PartialEq)]
pub enum PipelineState {
    Calibrating,
    StableInLane,
    ChangingLane,
    LaneChanged,
}

pub struct StateMachine {
    config: Config,
    state: PipelineState,
    current_position: VehiclePosition,
    previous_position: VehiclePosition,

    // Calibration
    calibration_frames: Vec<i32>,
    baseline_lane: Option<i32>,

    // Lane change tracking
    frames_above_threshold: u32,
    frames_in_new_lane: u32,
    lane_change_start_time: Option<Instant>,
    pending_direction: Direction,
}

#[derive(Debug, Clone)]
pub struct Config {
    pub offset_threshold: f32,
    pub debounce_frames: u32,
    pub confirm_frames: u32,
    pub timeout_ms: u64,
    pub calibration_frames: usize,
}

impl Default for Config {
    fn default() -> Self {
        Self {
            offset_threshold: 0.85, // Stricter than 0.7
            debounce_frames: 15,    // More than 5
            confirm_frames: 20,     // More than 10
            timeout_ms: 8000,
            calibration_frames: 90, // 3 seconds @ 30fps
        }
    }
}

impl StateMachine {
    pub fn new(config: Config) -> Self {
        Self {
            config,
            state: PipelineState::Calibrating,
            current_position: VehiclePosition::invalid(),
            previous_position: VehiclePosition::invalid(),
            calibration_frames: Vec::new(),
            baseline_lane: None,
            frames_above_threshold: 0,
            frames_in_new_lane: 0,
            lane_change_start_time: None,
            pending_direction: Direction::None,
        }
    }

    pub fn update(&mut self, position: VehiclePosition) -> Option<LaneChangeEvent> {
        self.previous_position = self.current_position;
        self.current_position = position;

        // Skip invalid positions
        if !position.is_valid() {
            return None;
        }

        match self.state {
            PipelineState::Calibrating => {
                self.calibration_frames.push(position.lane_index);

                if self.calibration_frames.len() >= self.config.calibration_frames {
                    self.baseline_lane = Some(self.compute_baseline_lane());
                    self.state = PipelineState::StableInLane;
                    println!(
                        " Calibration complete. Baseline lane: {}",
                        self.baseline_lane.unwrap()
                    );
                }
                None
            }

            PipelineState::StableInLane => {
                if position.lateral_offset.abs() > self.config.offset_threshold {
                    self.frames_above_threshold += 1;

                    if self.frames_above_threshold >= self.config.debounce_frames {
                        self.state = PipelineState::ChangingLane;
                        self.lane_change_start_time = Some(Instant::now());
                        self.pending_direction = if position.lateral_offset < 0.0 {
                            Direction::Left
                        } else {
                            Direction::Right
                        };
                        println!(" Lane change started: {:?}", self.pending_direction);
                    }
                } else {
                    self.frames_above_threshold = 0;
                }
                None
            }

            PipelineState::ChangingLane => {
                // Check timeout
                if let Some(start_time) = self.lane_change_start_time {
                    if start_time.elapsed() > Duration::from_millis(self.config.timeout_ms) {
                        println!(" Lane change timeout");
                        self.reset_to_stable();
                        return None;
                    }
                }

                // Check if lane index changed
                if position.lane_index != self.previous_position.lane_index
                    && position.lane_index >= 0
                    && self.previous_position.lane_index >= 0
                {
                    self.state = PipelineState::LaneChanged;
                    self.frames_in_new_lane = 1;
                    println!(
                        " Lane index changed: {}  {}",
                        self.previous_position.lane_index, position.lane_index
                    );
                }
                None
            }

            PipelineState::LaneChanged => {
                self.frames_in_new_lane += 1;

                if self.frames_in_new_lane >= self.config.confirm_frames {
                    println!(" Lane change confirmed");

                    let event = LaneChangeEvent {
                        timestamp: Instant::now(),
                        direction: self.pending_direction,
                        from_lane: self.previous_position.lane_index,
                        to_lane: position.lane_index,
                        confidence: position.confidence,
                    };

                    self.reset_to_stable();
                    Some(event)
                } else {
                    None
                }
            }
        }
    }

    fn reset_to_stable(&mut self) {
        self.state = PipelineState::StableInLane;
        self.frames_above_threshold = 0;
        self.frames_in_new_lane = 0;
        self.lane_change_start_time = None;
    }

    fn compute_baseline_lane(&self) -> i32 {
        let mut counts = std::collections::HashMap::new();
        for &lane in &self.calibration_frames {
            *counts.entry(lane).or_insert(0) += 1;
        }
        *counts
            .iter()
            .max_by_key(|(_, count)| *count)
            .map(|(lane, _)| lane)
            .unwrap_or(&1) // Default to lane 1
    }

    pub fn is_calibrated(&self) -> bool {
        self.baseline_lane.is_some()
    }
}
// src/detection/types.rs
use std::time::Instant;

#[derive(Debug, Clone, Copy)]
pub struct VehiclePosition {
    pub lane_index: i32,
    pub lateral_offset: f32,
    pub left_boundary: f32,
    pub right_boundary: f32,
    pub confidence: f32,
    pub timestamp: Instant,
}

impl VehiclePosition {
    pub fn invalid() -> Self {
        Self {
            lane_index: -1,
            lateral_offset: 0.0,
            left_boundary: 0.0,
            right_boundary: 0.0,
            confidence: 0.0,
            timestamp: Instant::now(),
        }
    }

    pub fn is_valid(&self) -> bool {
        self.lane_index >= 0 && self.confidence > 0.5
    }
}

#[derive(Debug, Clone)]
pub struct Lane {
    pub points: Vec<LanePoint>,
    pub lane_id: usize,
    pub confidence: f32,
}

#[derive(Debug, Clone, Copy)]
pub struct LanePoint {
    pub x: f32,
    pub y: f32,
    pub confidence: f32,
}

#[derive(Debug, Clone, Copy, PartialEq)]
pub enum Direction {
    None,
    Left,
    Right,
}

#[derive(Debug, Clone, Copy)]
pub struct LaneChangeEvent {
    pub timestamp: Instant,
    pub direction: Direction,
    pub from_lane: i32,
    pub to_lane: i32,
    pub confidence: f32,
}

#[derive(Debug, Clone)]
pub struct OvertakeEvent {
    pub start_timestamp: Instant,
    pub end_timestamp: Instant,
    pub first_direction: Direction,
    pub second_direction: Direction,
    pub start_lane: i32,
    pub end_lane: i32,
    pub is_complete: bool,
    pub confidence: f32,
}
// src/detection/position_calculator.rs
use super::types::{Lane, VehiclePosition};

const MIN_LANE_CONFIDENCE: f32 = 0.6;
const MIN_POINTS_PER_LANE: usize = 5;

pub fn calculate_vehicle_position(
    lanes: &[Lane],
    image_width: u32,
    image_height: u32,
) -> VehiclePosition {
    let vehicle_center_x = image_width as f32 / 2.0;
    let sample_y = image_height as f32 * 0.85;

    // Filter lanes by confidence and point count
    let valid_lanes: Vec<&Lane> = lanes
        .iter()
        .filter(|lane| {
            lane.confidence > MIN_LANE_CONFIDENCE && lane.points.len() >= MIN_POINTS_PER_LANE
        })
        .collect();

    if valid_lanes.len() < 2 {
        return VehiclePosition::invalid();
    }

    // Get x-coordinates at sample height
    let mut lane_xs: Vec<(usize, f32)> = valid_lanes
        .iter()
        .enumerate()
        .filter_map(|(i, lane)| interpolate_lane_x(lane, sample_y).map(|x| (i, x)))
        .collect();

    // Sort by x-coordinate
    lane_xs.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap());

    // Filter out lanes too far from vehicle center (likely road edges)
    let max_distance = image_width as f32 * 0.6;
    lane_xs.retain(|(_, x)| (x - vehicle_center_x).abs() < max_distance);

    if lane_xs.len() < 2 {
        return VehiclePosition::invalid();
    }

    // Find which lane boundaries the vehicle is between
    for i in 0..lane_xs.len() - 1 {
        let (left_idx, left_x) = lane_xs[i];
        let (right_idx, right_x) = lane_xs[i + 1];

        if left_x <= vehicle_center_x && vehicle_center_x <= right_x {
            let lane_width = right_x - left_x;
            let offset_normalized = ((vehicle_center_x - left_x) / lane_width - 0.5) * 2.0;

            return VehiclePosition {
                lane_index: i as i32,
                lateral_offset: offset_normalized,
                left_boundary: left_x,
                right_boundary: right_x,
                confidence: valid_lanes[left_idx]
                    .confidence
                    .min(valid_lanes[right_idx].confidence),
                timestamp: std::time::Instant::now(),
            };
        }
    }

    VehiclePosition::invalid()
}

fn interpolate_lane_x(lane: &Lane, target_y: f32) -> Option<f32> {
    // Find two points bracketing target_y
    let mut lower: Option<&crate::detection::types::LanePoint> = None;
    let mut upper: Option<&crate::detection::types::LanePoint> = None;

    for point in &lane.points {
        if point.y <= target_y {
            if lower.is_none() || point.y > lower.unwrap().y {
                lower = Some(point);
            }
        }
        if point.y >= target_y {
            if upper.is_none() || point.y < upper.unwrap().y {
                upper = Some(point);
            }
        }
    }

    match (lower, upper) {
        (Some(p1), Some(p2)) if (p2.y - p1.y).abs() > 0.1 => {
            // Linear interpolation
            let t = (target_y - p1.y) / (p2.y - p1.y);
            Some(p1.x + t * (p2.x - p1.x))
        }
        (Some(p), None) | (None, Some(p)) => Some(p.x),
        _ => None,
    }
}
// src/detection/mod.rs

mod overtake_detector;
mod position_calculator;
mod smoother;
mod state_machine;
mod types;

// Re-export public APIs
pub use overtake_detector::OvertakeDetector;
pub use position_calculator::calculate_vehicle_position;
pub use smoother::LanePositionSmoother;
pub use state_machine::StateMachine;
pub use types::*;
use std::collections::VecDeque;

pub struct LanePositionSmoother {
    history: VecDeque<VehiclePosition>,
    window_size: usize,
}

impl LanePositionSmoother {
    pub fn new(window_size: usize) -> Self {
        Self {
            history: VecDeque::with_capacity(window_size),
            window_size,
        }
    }

    pub fn smooth(&mut self, position: VehiclePosition) -> VehiclePosition {
        self.history.push_back(position);
        if self.history.len() > self.window_size {
            self.history.pop_front();
        }

        // Mode for lane_index (most common in window)
        let lane_index = self.most_common_lane();

        // Median for lateral_offset (reduce noise)
        let mut offsets: Vec<f32> = self.history.iter().map(|p| p.lateral_offset).collect();
        offsets.sort_by(|a, b| a.partial_cmp(b).unwrap());
        let lateral_offset = offsets[offsets.len() / 2];

        // Average confidence
        let confidence =
            self.history.iter().map(|p| p.confidence).sum::<f32>() / self.history.len() as f32;

        VehiclePosition {
            lane_index,
            lateral_offset,
            confidence,
            ..position
        }
    }

    fn most_common_lane(&self) -> i32 {
        let mut counts = std::collections::HashMap::new();
        for pos in &self.history {
            *counts.entry(pos.lane_index).or_insert(0) += 1;
        }
        *counts
            .iter()
            .max_by_key(|(_, count)| *count)
            .map(|(lane, _)| lane)
            .unwrap_or(&-1)
    }
}
