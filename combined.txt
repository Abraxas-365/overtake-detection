#[doc(hidden)]
pub mod __private228 {
    #[doc(hidden)]
    pub use crate::private::*;
}
use serde_core::__private228 as serde_core_private;
#[doc(hidden)]
pub mod __private228 {
    #[doc(hidden)]
    pub use crate::private::*;
}
// src/smoother.rs

use crate::types::VehiclePosition;
use std::collections::{HashMap, VecDeque};

/// Temporal smoother for vehicle position using a sliding window
pub struct LanePositionSmoother {
    history: VecDeque<VehiclePosition>,
    window_size: usize,
}

impl LanePositionSmoother {
    /// Create a new smoother with specified window size
    ///
    /// # Arguments
    /// * `window_size` - Number of frames to use for smoothing (e.g., 10 frames)
    pub fn new(window_size: usize) -> Self {
        Self {
            history: VecDeque::with_capacity(window_size),
            window_size,
        }
    }

    /// Smooth the current position using temporal window
    ///
    /// Uses different strategies for different components:
    /// - Lane index: Mode (most common value)
    /// - Lateral offset: Median (resistant to outliers)
    /// - Confidence: Average
    pub fn smooth(&mut self, position: VehiclePosition) -> VehiclePosition {
        self.history.push_back(position);

        // Maintain window size
        if self.history.len() > self.window_size {
            self.history.pop_front();
        }

        // Need at least 3 frames for meaningful smoothing
        if self.history.len() < 3 {
            return position;
        }

        VehiclePosition {
            lane_index: self.smooth_lane_index(),
            lateral_offset: self.smooth_lateral_offset(),
            confidence: self.smooth_confidence(),
            timestamp: position.timestamp, // Keep current timestamp
        }
    }

    /// Get the most common lane index (mode)
    fn smooth_lane_index(&self) -> i32 {
        let mut counts: HashMap<i32, usize> = HashMap::new();

        for pos in &self.history {
            *counts.entry(pos.lane_index).or_insert(0) += 1;
        }

        counts
            .into_iter()
            .max_by_key(|(_, count)| *count)
            .map(|(lane, _)| lane)
            .unwrap_or(-1)
    }

    /// Get median lateral offset (resistant to outliers)
    fn smooth_lateral_offset(&self) -> f32 {
        let mut offsets: Vec<f32> = self.history.iter().map(|p| p.lateral_offset).collect();
        offsets.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
        offsets[offsets.len() / 2]
    }

    /// Get average confidence
    fn smooth_confidence(&self) -> f32 {
        let sum: f32 = self.history.iter().map(|p| p.confidence).sum();
        sum / self.history.len() as f32
    }

    /// Reset the smoother (e.g., when video changes)
    pub fn reset(&mut self) {
        self.history.clear();
    }

    /// Get the number of frames currently in the history
    pub fn history_size(&self) -> usize {
        self.history.len()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_smoother_mode_for_lane_index() {
        let mut smoother = LanePositionSmoother::new(5);

        // Feed noisy lane detections: [1, 1, 2, 1, 1]
        let positions = vec![
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.0,
            },
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.033,
            },
            VehiclePosition {
                lane_index: 2, // noise
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.066,
            },
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.099,
            },
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.132,
            },
        ];

        for pos in positions {
            smoother.smooth(pos);
        }

        // Last smoothed position should have lane_index = 1 (mode)
        let last_pos = positions.last().unwrap();
        let smoothed = smoother.smooth(*last_pos);
        assert_eq!(smoothed.lane_index, 1);
    }

    #[test]
    fn test_smoother_median_for_offset() {
        let mut smoother = LanePositionSmoother::new(5);

        // Feed offsets with outlier: [-0.1, -0.05, 0.0, 0.05, 2.0 (outlier)]
        let offsets = vec![-0.1, -0.05, 0.0, 0.05, 2.0];

        for (i, offset) in offsets.iter().enumerate() {
            let pos = VehiclePosition {
                lane_index: 1,
                lateral_offset: *offset,
                confidence: 0.8,
                timestamp: i as f64 * 0.033,
            };
            smoother.smooth(pos);
        }

        let last_pos = VehiclePosition {
            lane_index: 1,
            lateral_offset: 2.0,
            confidence: 0.8,
            timestamp: 0.165,
        };
        let smoothed = smoother.smooth(last_pos);

        // Median should be 0.0 (middle value), not affected by 2.0 outlier
        assert_eq!(smoothed.lateral_offset, 0.0);
    }
}
// src/types.rs

use serde::{Deserialize, Serialize};
use std::collections::HashMap;

// ============================================================================
// Configuration Structs
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Config {
    pub model: ModelConfig,
    pub inference: InferenceConfig,
    pub detection: DetectionConfig,
    pub video: VideoConfig,
    pub logging: LoggingConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelConfig {
    pub path: String,
    pub input_width: usize,
    pub input_height: usize,
    pub num_anchors: usize,
    pub num_lanes: usize,
    pub griding_num: usize,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct InferenceConfig {
    pub use_tensorrt: bool,
    pub use_fp16: bool,
    pub enable_engine_cache: bool,
    pub engine_cache_path: String,
    pub num_threads: usize,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DetectionConfig {
    pub confidence_threshold: f32,
    pub min_points_per_lane: usize,
    pub smoother_window_size: usize,
    pub calibration_frames: usize,
    pub debounce_frames: u32,
    pub confirm_frames: u32,
    pub min_lane_confidence: f32,
    pub min_position_confidence: f32,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VideoConfig {
    pub input_dir: String,
    pub output_dir: String,
    pub source_width: usize,
    pub source_height: usize,
    pub target_fps: u32,
    pub save_annotated: bool,
    pub save_events_only: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LoggingConfig {
    pub level: String,
}

impl Config {
    pub fn load(path: &str) -> anyhow::Result<Self> {
        let contents = std::fs::read_to_string(path)?;
        let config: Config = serde_yaml::from_str(&contents)?;
        Ok(config)
    }
}

// ============================================================================
// Frame Type
// ============================================================================

#[derive(Debug, Clone)]
pub struct Frame {
    pub data: Vec<u8>,
    pub width: usize,
    pub height: usize,
    pub timestamp_ms: f64,
}

// ============================================================================
// Lane Detection Types (for inference output)
// ============================================================================

/// Lane from detection (uses tuple points for compatibility)
#[derive(Debug, Clone)]
pub struct DetectedLane {
    pub points: Vec<(f32, f32)>,
    pub confidence: f32,
}

// ============================================================================
// Analysis Types (Python-compatible)
// ============================================================================

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub enum LaneChangeState {
    Centered,
    Drifting,
    Crossing,
    Completed,
}

impl LaneChangeState {
    pub fn as_str(&self) -> &'static str {
        match self {
            LaneChangeState::Centered => "CENTERED",
            LaneChangeState::Drifting => "DRIFTING",
            LaneChangeState::Crossing => "CROSSING",
            LaneChangeState::Completed => "COMPLETED",
        }
    }
}

impl std::fmt::Display for LaneChangeState {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", self.as_str())
    }
}

#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub struct Point {
    pub x: f32,
    pub y: f32,
}

impl Point {
    pub fn new(x: f32, y: f32) -> Self {
        Self { x, y }
    }

    pub fn distance_to(&self, other: &Point) -> f32 {
        ((self.x - other.x).powi(2) + (self.y - other.y).powi(2)).sqrt()
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum LanePosition {
    LeftFar,
    LeftNear,
    RightNear,
    RightFar,
}

/// Lane for analysis (uses Point struct)
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Lane {
    pub lane_id: usize,
    pub points: Vec<Point>,
    pub confidence: f32,
    pub position: Option<LanePosition>,
}

impl Lane {
    /// Create from detected lane (tuple points)
    pub fn from_detected(lane_id: usize, detected: &DetectedLane) -> Self {
        Self {
            lane_id,
            points: detected
                .points
                .iter()
                .map(|p| Point::new(p.0, p.1))
                .collect(),
            confidence: detected.confidence,
            position: None,
        }
    }

    pub fn get_x_at_y(&self, target_y: f32) -> Option<f32> {
        if self.points.len() < 2 {
            return None;
        }

        let mut sorted_points = self.points.clone();
        sorted_points.sort_by(|a, b| a.y.partial_cmp(&b.y).unwrap_or(std::cmp::Ordering::Equal));

        for i in 0..sorted_points.len() - 1 {
            let p1 = &sorted_points[i];
            let p2 = &sorted_points[i + 1];

            if p1.y <= target_y && target_y <= p2.y {
                if (p2.y - p1.y).abs() < 1e-6 {
                    return Some(p1.x);
                }
                let ratio = (target_y - p1.y) / (p2.y - p1.y);
                return Some(p1.x + ratio * (p2.x - p1.x));
            }
        }
        None
    }

    pub fn avg_x(&self) -> f32 {
        if self.points.is_empty() {
            return 0.0;
        }
        self.points.iter().map(|p| p.x).sum::<f32>() / self.points.len() as f32
    }
}

// ============================================================================
// Vehicle State
// ============================================================================

#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub struct VehicleState {
    pub lateral_offset: f32,
    pub lane_width: Option<f32>,
    pub heading_offset: f32,
    pub frame_id: u64,
    pub timestamp_ms: f64,
}

impl VehicleState {
    pub fn invalid() -> Self {
        Self {
            lateral_offset: 0.0,
            lane_width: None,
            heading_offset: 0.0,
            frame_id: 0,
            timestamp_ms: 0.0,
        }
    }

    pub fn normalized_offset(&self) -> Option<f32> {
        match self.lane_width {
            Some(width) if width > 1.0 => Some(self.lateral_offset / width),
            _ => None,
        }
    }

    pub fn is_valid(&self) -> bool {
        self.lane_width.map_or(false, |w| w > 0.0)
    }
}

// ============================================================================
// Direction
// ============================================================================

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum Direction {
    Left = -1,
    Unknown = 0,
    Right = 1,
}

impl Direction {
    pub fn from_offset(offset: f32) -> Self {
        if offset > 0.0 {
            Direction::Right
        } else if offset < 0.0 {
            Direction::Left
        } else {
            Direction::Unknown
        }
    }

    pub fn as_str(&self) -> &'static str {
        match self {
            Direction::Left => "LEFT",
            Direction::Right => "RIGHT",
            Direction::Unknown => "UNKNOWN",
        }
    }

    pub fn as_i32(&self) -> i32 {
        match self {
            Direction::Left => -1,
            Direction::Right => 1,
            Direction::Unknown => 0,
        }
    }
}

impl std::fmt::Display for Direction {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", self.as_str())
    }
}

// ============================================================================
// Lane Change Event
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LaneChangeEvent {
    pub event_id: String,
    pub timestamp: String,
    pub video_timestamp_ms: f64,
    pub frame_id: u64,
    pub direction: Direction,
    pub confidence: f32,
    pub duration_ms: Option<f64>,
    pub source_id: String,
    pub metadata: HashMap<String, serde_json::Value>,
}

impl LaneChangeEvent {
    pub fn new(
        video_timestamp_ms: f64,
        frame_id: u64,
        direction: Direction,
        confidence: f32,
    ) -> Self {
        Self {
            event_id: uuid::Uuid::new_v4().to_string(),
            timestamp: chrono::Utc::now().to_rfc3339(),
            video_timestamp_ms,
            frame_id,
            direction,
            confidence,
            duration_ms: None,
            source_id: String::new(),
            metadata: HashMap::new(),
        }
    }

    pub fn direction_name(&self) -> &'static str {
        self.direction.as_str()
    }

    pub fn to_json(&self) -> serde_json::Value {
        serde_json::json!({
            "event_id": self.event_id,
            "event_type": "lane_change",
            "timestamp": self.timestamp,
            "video_timestamp_ms": self.video_timestamp_ms,
            "frame_id": self.frame_id,
            "direction": self.direction_name(),
            "confidence": self.confidence,
            "duration_ms": self.duration_ms,
            "source_id": self.source_id,
            "metadata": self.metadata,
        })
    }
}

// ============================================================================
// Lane Change Config
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LaneChangeConfig {
    pub drift_threshold: f32,
    pub crossing_threshold: f32,
    pub min_frames_confirm: u32,
    pub cooldown_frames: u32,
    pub smoothing_alpha: f32,
    pub reference_y_ratio: f32,
}

impl Default for LaneChangeConfig {
    fn default() -> Self {
        Self {
            drift_threshold: 0.2,
            crossing_threshold: 0.4,
            min_frames_confirm: 5,
            cooldown_frames: 30,
            smoothing_alpha: 0.3,
            reference_y_ratio: 0.8,
        }
    }
}
// src/video_processor.rs

use crate::types::{Config, DetectedLane, VehicleState};
use anyhow::Result;
use opencv::{
    core::{self, Mat},
    imgproc,
    prelude::*,
    videoio::{self, VideoCapture, VideoCaptureTraitConst, VideoWriter},
};
use std::path::{Path, PathBuf};
use tracing::info;
use walkdir::WalkDir;

pub struct VideoProcessor {
    config: Config,
}

impl VideoProcessor {
    pub fn new(config: Config) -> Self {
        Self { config }
    }

    pub fn find_video_files(&self) -> Result<Vec<PathBuf>> {
        let mut videos = Vec::new();

        let video_extensions = vec!["mp4", "avi", "mov", "mkv", "MP4", "AVI", "MOV", "MKV"];

        for entry in WalkDir::new(&self.config.video.input_dir)
            .follow_links(true)
            .into_iter()
            .filter_map(|e| e.ok())
        {
            let path = entry.path();
            if let Some(ext) = path.extension() {
                if video_extensions.contains(&ext.to_str().unwrap_or("")) {
                    videos.push(path.to_path_buf());
                }
            }
        }

        info!("Found {} video files", videos.len());
        Ok(videos)
    }

    pub fn open_video(&self, path: &Path) -> Result<VideoReader> {
        info!("Opening video: {}", path.display());

        let cap = VideoCapture::from_file(path.to_str().unwrap(), videoio::CAP_ANY)?;

        if !cap.is_opened()? {
            anyhow::bail!("Failed to open video file");
        }

        let fps = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FPS)?;
        let total_frames = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FRAME_COUNT)? as i32;
        let width = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FRAME_WIDTH)? as i32;
        let height = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FRAME_HEIGHT)? as i32;

        info!(
            "Video properties: {}x{} @ {:.1} FPS, {} frames",
            width, height, fps, total_frames
        );

        Ok(VideoReader {
            cap,
            fps,
            total_frames,
            current_frame: 0,
            width,
            height,
        })
    }

    pub fn create_writer(
        &self,
        input_path: &Path,
        width: i32,
        height: i32,
        fps: f64,
    ) -> Result<Option<VideoWriter>> {
        if !self.config.video.save_annotated {
            return Ok(None);
        }

        std::fs::create_dir_all(&self.config.video.output_dir)?;

        let input_name = input_path.file_stem().unwrap().to_str().unwrap();
        let output_path = PathBuf::from(&self.config.video.output_dir)
            .join(format!("{}_annotated.mp4", input_name));

        info!("Output video: {}", output_path.display());

        let fourcc = VideoWriter::fourcc('m', 'p', '4', 'v')?;
        let writer = VideoWriter::new(
            output_path.to_str().unwrap(),
            fourcc,
            fps,
            core::Size::new(width, height),
            true,
        )?;

        Ok(Some(writer))
    }
}

pub struct VideoReader {
    pub cap: VideoCapture,
    pub fps: f64,
    pub total_frames: i32,
    pub current_frame: i32,
    pub width: i32,
    pub height: i32,
}

impl VideoReader {
    pub fn read_frame(&mut self) -> Result<Option<crate::types::Frame>> {
        use opencv::videoio::VideoCaptureTrait;

        let mut mat = Mat::default();

        if !VideoCaptureTrait::read(&mut self.cap, &mut mat)? || mat.empty() {
            return Ok(None);
        }

        self.current_frame += 1;
        let timestamp_ms = (self.current_frame as f64 / self.fps) * 1000.0;

        let mut rgb_mat = Mat::default();
        imgproc::cvt_color(&mat, &mut rgb_mat, imgproc::COLOR_BGR2RGB, 0)?;

        let data = rgb_mat.data_bytes()?.to_vec();

        Ok(Some(crate::types::Frame {
            data,
            width: self.width as usize,
            height: self.height as usize,
            timestamp_ms,
        }))
    }

    pub fn progress(&self) -> f32 {
        if self.total_frames == 0 {
            return 0.0;
        }
        (self.current_frame as f32 / self.total_frames as f32) * 100.0
    }
}

/// Draw lanes with Python-style state machine info overlay
pub fn draw_lanes_with_state(
    frame: &[u8],
    width: i32,
    height: i32,
    lanes: &[DetectedLane],
    state: &str,
    vehicle_state: Option<&VehicleState>,
) -> Result<Mat> {
    let mat = Mat::from_slice(frame)?;
    let mat = mat.reshape(3, height)?;

    let mut bgr_mat = Mat::default();
    imgproc::cvt_color(&mat, &mut bgr_mat, imgproc::COLOR_RGB2BGR, 0)?;
    let mut output = bgr_mat.try_clone()?;

    // Lane colors
    let colors = vec![
        core::Scalar::new(0.0, 0.0, 255.0, 0.0),   // Red
        core::Scalar::new(0.0, 255.0, 0.0, 0.0),   // Green
        core::Scalar::new(255.0, 0.0, 0.0, 0.0),   // Blue
        core::Scalar::new(0.0, 255.0, 255.0, 0.0), // Yellow
    ];

    // Draw lanes
    for (i, lane) in lanes.iter().enumerate() {
        let color = colors[i % colors.len()];

        // Draw lane points
        for point in &lane.points {
            let pt = core::Point::new(point.0 as i32, point.1 as i32);
            imgproc::circle(&mut output, pt, 3, color, -1, imgproc::LINE_8, 0)?;
        }

        // Draw lane lines
        for window in lane.points.windows(2) {
            let pt1 = core::Point::new(window[0].0 as i32, window[0].1 as i32);
            let pt2 = core::Point::new(window[1].0 as i32, window[1].1 as i32);
            imgproc::line(&mut output, pt1, pt2, color, 2, imgproc::LINE_AA, 0)?;
        }
    }

    // Draw vehicle position marker
    let vehicle_x = width / 2;
    let vehicle_y = (height as f32 * 0.85) as i32;

    imgproc::circle(
        &mut output,
        core::Point::new(vehicle_x, vehicle_y),
        10,
        core::Scalar::new(0.0, 255.0, 255.0, 0.0),
        -1,
        imgproc::LINE_8,
        0,
    )?;

    // State color based on state machine state
    let state_color = match state {
        "CENTERED" => core::Scalar::new(0.0, 255.0, 0.0, 0.0),
        "DRIFTING" => core::Scalar::new(0.0, 255.0, 255.0, 0.0),
        "CROSSING" => core::Scalar::new(0.0, 165.0, 255.0, 0.0),
        "COMPLETED" => core::Scalar::new(0.0, 0.0, 255.0, 0.0),
        _ => core::Scalar::new(255.0, 255.0, 255.0, 0.0),
    };

    // Draw info overlay background
    imgproc::rectangle(
        &mut output,
        core::Rect::new(5, 5, 550, 70),
        core::Scalar::new(40.0, 40.0, 40.0, 0.0),
        -1,
        imgproc::LINE_8,
        0,
    )?;

    // Draw state text
    imgproc::put_text(
        &mut output,
        &format!("State: {}", state),
        core::Point::new(15, 32),
        imgproc::FONT_HERSHEY_SIMPLEX,
        0.8,
        state_color,
        2,
        imgproc::LINE_8,
        false,
    )?;

    // Draw vehicle state info if available
    if let Some(vs) = vehicle_state {
        if vs.is_valid() {
            let normalized = vs.normalized_offset().unwrap_or(0.0);
            let info = format!(
                "Offset: {:.1}px ({:+.1}%) | Width: {:.0}px",
                vs.lateral_offset,
                normalized * 100.0,
                vs.lane_width.unwrap_or(0.0)
            );
            imgproc::put_text(
                &mut output,
                &info,
                core::Point::new(200, 32),
                imgproc::FONT_HERSHEY_SIMPLEX,
                0.5,
                core::Scalar::new(255.0, 255.0, 255.0, 0.0),
                1,
                imgproc::LINE_8,
                false,
            )?;
        }
    }

    // Draw lanes count
    let lanes_info = format!("Lanes: {}", lanes.len());
    imgproc::put_text(
        &mut output,
        &lanes_info,
        core::Point::new(15, 60),
        imgproc::FONT_HERSHEY_SIMPLEX,
        0.5,
        core::Scalar::new(200.0, 200.0, 200.0, 0.0),
        1,
        imgproc::LINE_8,
        false,
    )?;

    Ok(output)
}
// src/analysis/state_machine.rs

use crate::types::{Direction, LaneChangeConfig, LaneChangeEvent, LaneChangeState, VehicleState};
use tracing::{debug, info};

pub struct LaneChangeStateMachine {
    config: LaneChangeConfig,
    source_id: String,
    state: LaneChangeState,
    frames_in_state: u32,
    pending_state: Option<LaneChangeState>,
    pending_frames: u32,
    change_direction: Direction,
    change_start_frame: Option<u64>,
    change_start_time: Option<f64>,
    cooldown_remaining: u32,
}

impl LaneChangeStateMachine {
    pub fn new(config: LaneChangeConfig) -> Self {
        Self {
            config,
            source_id: String::new(),
            state: LaneChangeState::Centered,
            frames_in_state: 0,
            pending_state: None,
            pending_frames: 0,
            change_direction: Direction::Unknown,
            change_start_frame: None,
            change_start_time: None,
            cooldown_remaining: 0,
        }
    }

    pub fn current_state(&self) -> &str {
        self.state.as_str()
    }

    pub fn update(
        &mut self,
        vehicle_state: &VehicleState,
        frame_id: u64,
        timestamp_ms: f64,
    ) -> Option<LaneChangeEvent> {
        if self.cooldown_remaining > 0 {
            self.cooldown_remaining -= 1;
            if self.cooldown_remaining == 0 {
                self.state = LaneChangeState::Centered;
                self.frames_in_state = 0;
            }
            return None;
        }

        if !vehicle_state.is_valid() {
            return None;
        }

        let lane_width = vehicle_state.lane_width.unwrap();
        let normalized_offset = (vehicle_state.lateral_offset / lane_width).abs();
        let direction = Direction::from_offset(vehicle_state.lateral_offset);

        let target_state = self.determine_target_state(normalized_offset);

        self.check_transition(target_state, direction, frame_id, timestamp_ms)
    }

    fn determine_target_state(&self, normalized_offset: f32) -> LaneChangeState {
        if normalized_offset >= self.config.crossing_threshold {
            LaneChangeState::Crossing
        } else if normalized_offset >= self.config.drift_threshold {
            LaneChangeState::Drifting
        } else {
            if self.state == LaneChangeState::Crossing {
                LaneChangeState::Completed
            } else {
                LaneChangeState::Centered
            }
        }
    }

    fn check_transition(
        &mut self,
        target_state: LaneChangeState,
        direction: Direction,
        frame_id: u64,
        timestamp_ms: f64,
    ) -> Option<LaneChangeEvent> {
        if target_state == self.state {
            self.pending_state = None;
            self.pending_frames = 0;
            self.frames_in_state += 1;
            return None;
        }

        if self.pending_state == Some(target_state) {
            self.pending_frames += 1;
        } else {
            self.pending_state = Some(target_state);
            self.pending_frames = 1;
        }

        if self.pending_frames < self.config.min_frames_confirm {
            return None;
        }

        self.execute_transition(target_state, direction, frame_id, timestamp_ms)
    }

    fn execute_transition(
        &mut self,
        target_state: LaneChangeState,
        direction: Direction,
        frame_id: u64,
        timestamp_ms: f64,
    ) -> Option<LaneChangeEvent> {
        let from_state = self.state;

        if target_state == LaneChangeState::Drifting && from_state == LaneChangeState::Centered {
            self.change_direction = direction;
            self.change_start_frame = Some(frame_id);
            self.change_start_time = Some(timestamp_ms);
            debug!(
                "Lane change started: {} at frame {}",
                direction.as_str(),
                frame_id
            );
        }

        let duration_ms = if target_state == LaneChangeState::Completed {
            self.change_start_time.map(|start| timestamp_ms - start)
        } else {
            None
        };

        self.state = target_state;
        self.frames_in_state = 0;
        self.pending_state = None;
        self.pending_frames = 0;

        if target_state == LaneChangeState::Completed {
            self.cooldown_remaining = self.config.cooldown_frames;

            let mut event =
                LaneChangeEvent::new(timestamp_ms, frame_id, self.change_direction, 0.9);
            event.duration_ms = duration_ms;
            event.source_id = self.source_id.clone();
            event.metadata.insert(
                "start_frame".to_string(),
                serde_json::json!(self.change_start_frame),
            );
            event
                .metadata
                .insert("end_frame".to_string(), serde_json::json!(frame_id));

            info!(
                "Lane change completed: {} (duration: {:.0}ms) at frame {}",
                event.direction_name(),
                duration_ms.unwrap_or(0.0),
                frame_id
            );

            self.change_direction = Direction::Unknown;
            self.change_start_frame = None;
            self.change_start_time = None;

            return Some(event);
        }

        None
    }

    pub fn reset(&mut self) {
        self.state = LaneChangeState::Centered;
        self.frames_in_state = 0;
        self.pending_state = None;
        self.pending_frames = 0;
        self.change_direction = Direction::Unknown;
        self.change_start_frame = None;
        self.change_start_time = None;
        self.cooldown_remaining = 0;
    }

    pub fn set_source_id(&mut self, source_id: String) {
        self.source_id = source_id;
    }
}
// src/analysis/position_estimator.rs

use crate::types::{Lane, VehicleState};

pub struct PositionEstimator {
    pub reference_y_ratio: f32,
    pub min_lane_width: f32,
    pub max_lane_width: f32,
}

impl PositionEstimator {
    pub fn new(reference_y_ratio: f32) -> Self {
        Self {
            reference_y_ratio,
            min_lane_width: 100.0,
            max_lane_width: 1000.0,
        }
    }

    pub fn estimate(&self, lanes: &[Lane], frame_width: u32, frame_height: u32) -> VehicleState {
        let vehicle_x = frame_width as f32 / 2.0;
        let reference_y = frame_height as f32 * self.reference_y_ratio;

        let left_lane = self.find_ego_lane(lanes, vehicle_x, true);
        let right_lane = self.find_ego_lane(lanes, vehicle_x, false);

        let left_x = left_lane.and_then(|l: &Lane| l.get_x_at_y(reference_y));
        let right_x = right_lane.and_then(|l: &Lane| l.get_x_at_y(reference_y));

        let mut lane_width: Option<f32> = None;
        let mut lateral_offset = 0.0f32;

        match (left_x, right_x) {
            (Some(lx), Some(rx)) => {
                let width = rx - lx;
                if width >= self.min_lane_width && width <= self.max_lane_width {
                    lane_width = Some(width);
                    let lane_center = (lx + rx) / 2.0;
                    lateral_offset = vehicle_x - lane_center;
                }
            }
            (Some(lx), None) => {
                lateral_offset = vehicle_x - lx;
            }
            (None, Some(rx)) => {
                lateral_offset = vehicle_x - rx;
            }
            (None, None) => {}
        }

        VehicleState {
            lateral_offset,
            lane_width,
            heading_offset: 0.0,
            frame_id: 0,
            timestamp_ms: 0.0,
        }
    }

    fn find_ego_lane<'a>(
        &self,
        lanes: &'a [Lane],
        vehicle_x: f32,
        is_left: bool,
    ) -> Option<&'a Lane> {
        let mut candidates: Vec<(&Lane, f32)> = Vec::new();

        for lane in lanes {
            if lane.points.is_empty() {
                continue;
            }
            let avg_x = lane.avg_x();

            if is_left && avg_x < vehicle_x {
                candidates.push((lane, vehicle_x - avg_x));
            } else if !is_left && avg_x > vehicle_x {
                candidates.push((lane, avg_x - vehicle_x));
            }
        }

        candidates.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap_or(std::cmp::Ordering::Equal));
        candidates.first().map(|(lane, _)| *lane)
    }
}

pub struct PositionSmoother {
    alpha: f32,
    smoothed_offset: Option<f32>,
    smoothed_width: Option<f32>,
}

impl PositionSmoother {
    pub fn new(alpha: f32) -> Self {
        Self {
            alpha,
            smoothed_offset: None,
            smoothed_width: None,
        }
    }

    pub fn smooth(&mut self, state: VehicleState) -> VehicleState {
        let smoothed_offset = match self.smoothed_offset {
            None => {
                self.smoothed_offset = Some(state.lateral_offset);
                state.lateral_offset
            }
            Some(prev) => {
                let new_val = self.alpha * state.lateral_offset + (1.0 - self.alpha) * prev;
                self.smoothed_offset = Some(new_val);
                new_val
            }
        };

        let smoothed_width = if let Some(width) = state.lane_width {
            match self.smoothed_width {
                None => {
                    self.smoothed_width = Some(width);
                    Some(width)
                }
                Some(prev) => {
                    let new_val = self.alpha * width + (1.0 - self.alpha) * prev;
                    self.smoothed_width = Some(new_val);
                    Some(new_val)
                }
            }
        } else {
            self.smoothed_width
        };

        VehicleState {
            lateral_offset: smoothed_offset,
            lane_width: smoothed_width,
            heading_offset: state.heading_offset,
            frame_id: state.frame_id,
            timestamp_ms: state.timestamp_ms,
        }
    }

    pub fn reset(&mut self) {
        self.smoothed_offset = None;
        self.smoothed_width = None;
    }
}
// src/analysis/mod.rs

mod lane_analyzer;
mod position_estimator;
mod state_machine;

pub use lane_analyzer::LaneChangeAnalyzer;
// src/analysis/lane_analyzer.rs

use crate::analysis::position_estimator::{PositionEstimator, PositionSmoother};
use crate::analysis::state_machine::LaneChangeStateMachine;
use crate::types::{Lane, LaneChangeConfig, LaneChangeEvent, VehicleState};

pub struct LaneChangeAnalyzer {
    position_estimator: PositionEstimator,
    smoother: PositionSmoother,
    state_machine: LaneChangeStateMachine,
    config: LaneChangeConfig,
    last_state: Option<VehicleState>,
}

impl LaneChangeAnalyzer {
    pub fn new(config: LaneChangeConfig) -> Self {
        let position_estimator = PositionEstimator::new(config.reference_y_ratio);
        let smoother = PositionSmoother::new(config.smoothing_alpha);
        let state_machine = LaneChangeStateMachine::new(config.clone());

        Self {
            position_estimator,
            smoother,
            state_machine,
            config,
            last_state: None,
        }
    }

    pub fn analyze(
        &mut self,
        lanes: &[Lane],
        frame_width: u32,
        frame_height: u32,
        frame_id: u64,
        timestamp_ms: f64,
    ) -> Option<LaneChangeEvent> {
        let mut raw_state = self
            .position_estimator
            .estimate(lanes, frame_width, frame_height);
        raw_state.frame_id = frame_id;
        raw_state.timestamp_ms = timestamp_ms;

        let smoothed_state = self.smoother.smooth(raw_state);
        self.last_state = Some(smoothed_state);

        self.state_machine
            .update(&smoothed_state, frame_id, timestamp_ms)
    }

    pub fn current_state(&self) -> &str {
        self.state_machine.current_state()
    }

    pub fn last_vehicle_state(&self) -> Option<&VehicleState> {
        self.last_state.as_ref()
    }

    pub fn reset(&mut self) {
        self.state_machine.reset();
        self.smoother.reset();
        self.last_state = None;
    }

    pub fn set_source_id(&mut self, source_id: String) {
        self.state_machine.set_source_id(source_id);
    }

    pub fn config(&self) -> &LaneChangeConfig {
        &self.config
    }
}
use crate::types::Config;
use anyhow::Result;
use std::fs;

impl Config {
    pub fn load(path: &str) -> Result<Self> {
        let contents = fs::read_to_string(path)?;
        let config: Config = serde_yaml::from_str(&contents)?;
        Ok(config)
    }
}
// src/lane_detection.rs

use crate::types::{Config, DetectedLane};
use anyhow::Result;
use tracing::info;

pub struct LaneDetectionResult {
    pub lanes: Vec<DetectedLane>,
    pub timestamp_ms: f64,
}

pub fn parse_lanes(
    output: &[f32],
    frame_width: f32,
    frame_height: f32,
    config: &Config,
    timestamp_ms: f64,
) -> Result<LaneDetectionResult> {
    let griding_num = config.model.griding_num; // 200
    let num_anchors = config.model.num_anchors; // 72
    let num_lanes = config.model.num_lanes; // 4

    // Constants matching Python implementation (UFLDv2Postprocessor)
    // These define the start and end Y-coordinates in the original 720p image space
    const ROW_ANCHOR_START: f32 = 160.0;
    const ROW_ANCHOR_END: f32 = 710.0;
    const ORIGINAL_HEIGHT: f32 = 720.0;

    let mut lanes = Vec::new();

    for lane_idx in 0..num_lanes {
        let mut points: Vec<(f32, f32)> = Vec::new();
        let mut total_confidence = 0.0;
        let mut point_count = 0;

        for anchor_idx in 0..num_anchors {
            let mut max_prob = f32::NEG_INFINITY;
            let mut max_grid_idx = 0;

            // Find the grid cell with highest probability for this row/lane
            for grid_idx in 0..griding_num {
                let idx = grid_idx * (num_anchors * num_lanes) + anchor_idx * num_lanes + lane_idx;
                let prob = output[idx];
                if prob > max_prob {
                    max_prob = prob;
                    max_grid_idx = grid_idx;
                }
            }

            // Sigmoid for confidence
            let confidence = 1.0 / (1.0 + (-max_prob).exp());

            // Threshold
            if confidence >= 0.1 && max_grid_idx > 0 && max_grid_idx < griding_num {
                // Calculate X coordinate
                // Map grid index (0..200) to width (0..frame_width)
                let x = ((max_grid_idx as f32 - 1.0) / (griding_num as f32 - 1.0)) * frame_width;

                // Calculate Y coordinate
                // Match Python: np.linspace(160, 710, 72)
                let y_norm = ROW_ANCHOR_START
                    + (ROW_ANCHOR_END - ROW_ANCHOR_START)
                        * (anchor_idx as f32 / (num_anchors as f32 - 1.0));

                // Scale normalized Y (from 720p space) to current frame height
                let y = (y_norm / ORIGINAL_HEIGHT) * frame_height;

                points.push((x, y));
                total_confidence += confidence;
                point_count += 1;
            }
        }

        if points.len() >= 2 {
            let avg_confidence = if point_count > 0 {
                total_confidence / point_count as f32
            } else {
                0.0
            };

            lanes.push(DetectedLane {
                points,
                confidence: avg_confidence,
            });
        }
    }

    Ok(LaneDetectionResult {
        lanes,
        timestamp_ms,
    })
}

pub fn find_vehicle_lane_with_confidence(
    lanes: &[DetectedLane],
    frame_width: f32,
) -> Option<(usize, f32, f32)> {
    if lanes.len() < 2 {
        return None;
    }

    let vehicle_x = frame_width / 2.0;

    let mut lane_positions: Vec<(usize, f32, f32)> = lanes
        .iter()
        .enumerate()
        .filter_map(|(idx, lane)| lane.points.last().map(|p| (idx, p.0, lane.confidence)))
        .collect();

    lane_positions.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap());

    for i in 0..lane_positions.len() - 1 {
        let (_, left_x, left_conf) = lane_positions[i];
        let (_, right_x, right_conf) = lane_positions[i + 1];

        if left_x <= vehicle_x && vehicle_x <= right_x {
            let lane_width = right_x - left_x;
            let offset_from_left = vehicle_x - left_x;
            let normalized_offset = (offset_from_left / lane_width - 0.5) * 2.0;
            let confidence = left_conf.min(right_conf);

            return Some((i, normalized_offset, confidence));
        }
    }

    None
}
// src/overtake_detector.rs

use crate::types::{Config, Direction, LaneChangeEvent, OvertakeEvent, VehiclePosition};
use std::collections::VecDeque;
use tracing::info;

pub struct DetectorResult {
    pub lane_change: Option<LaneChangeEvent>,
    pub overtake: Option<OvertakeEvent>,
}

pub struct OvertakeDetector {
    config: Config,
    lane_history: VecDeque<(i32, f64)>,
    last_stable_lane: Option<i32>,
    last_change_time: Option<f64>,
    recent_changes: Vec<LaneChangeEvent>,
    calibration_frames: Vec<i32>,
    baseline_lane: Option<i32>,
    is_calibrated: bool,
}

impl OvertakeDetector {
    pub fn new(config: Config) -> Self {
        Self {
            config,
            lane_history: VecDeque::with_capacity(30),
            last_stable_lane: None,
            last_change_time: None,
            recent_changes: Vec::new(),
            calibration_frames: Vec::new(),
            baseline_lane: None,
            is_calibrated: false,
        }
    }

    /// Update with VehiclePosition (smoothed position)
    pub fn update_with_position(&mut self, position: VehiclePosition) -> DetectorResult {
        // Handle calibration phase
        if !self.is_calibrated {
            self.calibration_frames.push(position.lane_index);

            if self.calibration_frames.len() >= self.config.detection.calibration_frames {
                self.baseline_lane = Some(self.compute_baseline_lane());
                self.last_stable_lane = self.baseline_lane;
                self.is_calibrated = true;
                info!(
                    "âœ… Calibration complete! Baseline lane: {}",
                    self.baseline_lane.unwrap()
                );
            }

            return DetectorResult {
                lane_change: None,
                overtake: None,
            };
        }

        // After calibration, detect lane changes and overtakes
        let overtake = self.update(
            position.lane_index,
            position.lateral_offset,
            position.timestamp,
        );

        // Extract the lane change event if one occurred
        let lane_change = if overtake.is_some() {
            self.recent_changes.last().cloned()
        } else {
            None
        };

        DetectorResult {
            lane_change,
            overtake,
        }
    }

    /// Check if calibration is complete
    pub fn is_calibrated(&self) -> bool {
        self.is_calibrated
    }

    /// Get the baseline lane from calibration
    pub fn get_baseline_lane(&self) -> Option<i32> {
        self.baseline_lane
    }

    /// Original update method (used internally)
    pub fn update(
        &mut self,
        current_lane: i32,
        _lateral_offset: f32,
        timestamp: f64,
    ) -> Option<OvertakeEvent> {
        // Add to history
        self.lane_history.push_back((current_lane, timestamp));
        if self.lane_history.len() > 30 {
            self.lane_history.pop_front();
        }

        // Get stable lane (mode of last 10 frames)
        let stable_lane = self.get_stable_lane();

        // Detect lane change
        if let Some(prev_stable) = self.last_stable_lane {
            if stable_lane != prev_stable {
                let event = LaneChangeEvent {
                    timestamp,
                    direction: if stable_lane > prev_stable {
                        Direction::Right
                    } else {
                        Direction::Left
                    },
                    from_lane: prev_stable,
                    to_lane: stable_lane,
                    confidence: 0.8, // You can calculate actual confidence
                };

                info!(
                    "Lane change detected: {:?} from {} to {}",
                    event.direction, event.from_lane, event.to_lane
                );

                // Check for overtake
                let overtake = self.check_overtake(&event);

                self.last_stable_lane = Some(stable_lane);
                self.last_change_time = Some(timestamp);

                return overtake;
            }
        } else {
            self.last_stable_lane = Some(stable_lane);
        }

        None
    }

    fn get_stable_lane(&self) -> i32 {
        if self.lane_history.is_empty() {
            return -1;
        }

        // Get mode of last 10 frames
        let recent: Vec<i32> = self
            .lane_history
            .iter()
            .rev()
            .take(10)
            .map(|(lane, _)| *lane)
            .collect();

        let mut counts = std::collections::HashMap::new();
        for &lane in &recent {
            *counts.entry(lane).or_insert(0) += 1;
        }

        counts
            .into_iter()
            .max_by_key(|(_, count)| *count)
            .map(|(lane, _)| lane)
            .unwrap_or(-1)
    }

    fn check_overtake(&mut self, current_event: &LaneChangeEvent) -> Option<OvertakeEvent> {
        self.recent_changes.push(current_event.clone());

        self.recent_changes.retain(|e| {
            current_event.timestamp - e.timestamp < self.config.overtake.max_window_seconds
        });

        if self.recent_changes.len() < 2 {
            return None;
        }

        let prev = &self.recent_changes[self.recent_changes.len() - 2];
        let curr = current_event;
        let delta = curr.timestamp - prev.timestamp;

        // Check timing constraints
        if delta < self.config.overtake.min_interval_seconds
            || delta > self.config.overtake.max_window_seconds
        {
            return None;
        }

        // â­ NEW: Only process opposite directions
        let is_complete = (prev.direction == Direction::Left && curr.direction == Direction::Right)
            || (prev.direction == Direction::Right && curr.direction == Direction::Left);

        // â­ NEW: Don't return anything for same-direction pairs
        if !is_complete {
            return None; // Changed from creating incomplete event
        }

        if is_complete {
            info!("ðŸš— OVERTAKE DETECTED!");
        }

        Some(OvertakeEvent {
            start_timestamp: prev.timestamp,
            end_timestamp: curr.timestamp,
            first_direction: prev.direction,
            second_direction: curr.direction,
            start_lane: prev.from_lane,
            end_lane: curr.to_lane,
            is_complete,
            confidence: (prev.confidence + curr.confidence) / 2.0,
        })
    }

    /// Compute the baseline lane from calibration frames (mode)
    fn compute_baseline_lane(&self) -> i32 {
        let mut counts = std::collections::HashMap::new();
        for &lane in &self.calibration_frames {
            *counts.entry(lane).or_insert(0) += 1;
        }

        *counts
            .iter()
            .max_by_key(|(_, count)| *count)
            .map(|(lane, _)| lane)
            .unwrap_or(&1) // Default to lane 1 if no data
    }

    /// Reset the detector (useful for new video or scene changes)
    pub fn reset(&mut self) {
        self.lane_history.clear();
        self.last_stable_lane = None;
        self.last_change_time = None;
        self.recent_changes.clear();
        self.calibration_frames.clear();
        self.baseline_lane = None;
        self.is_calibrated = false;
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    fn create_test_config() -> Config {
        // You'll need to create a minimal valid config for testing
        // This is just a placeholder structure
        Config {
            model: crate::types::ModelConfig {
                path: "test.onnx".to_string(),
                input_width: 1600,
                input_height: 320,
                num_anchors: 72,
                num_lanes: 4,
                griding_num: 200,
            },
            inference: crate::types::InferenceConfig {
                use_tensorrt: false,
                use_fp16: false,
                enable_engine_cache: false,
                engine_cache_path: "".to_string(),
                num_threads: 4,
            },
            detection: crate::types::DetectionConfig {
                confidence_threshold: 0.5,
                min_points_per_lane: 5,
                smoother_window_size: 10,
                calibration_frames: 90,
                debounce_frames: 15,
                confirm_frames: 20,
                min_lane_confidence: 0.6,
                min_position_confidence: 0.5,
            },
            overtake: crate::types::OvertakeConfig {
                lane_change_offset_threshold: 0.7,
                debounce_frames: 15,
                confirm_frames: 20,
                max_window_seconds: 10.0,
                min_interval_seconds: 1.0,
            },
            video: crate::types::VideoConfig {
                input_dir: "".to_string(),
                output_dir: "".to_string(),
                source_width: 1920,
                source_height: 1080,
                target_fps: 30,
                save_annotated: true,
                save_events_only: false,
            },
            logging: crate::types::LoggingConfig {
                level: "info".to_string(),
            },
        }
    }

    #[test]
    fn test_calibration() {
        let config = create_test_config();
        let mut detector = OvertakeDetector::new(config);

        assert!(!detector.is_calibrated());
        assert_eq!(detector.get_baseline_lane(), None);

        // Simulate calibration with 90 frames in lane 1
        for i in 0..90 {
            let position = VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: i as f64 * 0.033,
            };
            detector.update_with_position(position);
        }

        assert!(detector.is_calibrated());
        assert_eq!(detector.get_baseline_lane(), Some(1));
    }

    #[test]
    fn test_lane_change_detection() {
        let config = create_test_config();
        let mut detector = OvertakeDetector::new(config);

        // Complete calibration
        for i in 0..90 {
            let position = VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: i as f64 * 0.033,
            };
            detector.update_with_position(position);
        }

        // Stay in lane 1 for a bit
        for i in 90..120 {
            let position = VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: i as f64 * 0.033,
            };
            let result = detector.update_with_position(position);
            assert!(result.lane_change.is_none());
        }

        // Change to lane 2
        for i in 120..150 {
            let position = VehiclePosition {
                lane_index: 2,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: i as f64 * 0.033,
            };
            let result = detector.update_with_position(position);

            // Should detect lane change at some point
            if result.lane_change.is_some() {
                let event = result.lane_change.unwrap();
                assert_eq!(event.from_lane, 1);
                assert_eq!(event.to_lane, 2);
                assert_eq!(event.direction, Direction::Right);
                return; // Test passed
            }
        }
    }
}
// src/main.rs

mod analysis;
mod inference;
mod lane_detection;
mod preprocessing;
mod types;
mod video_processor;

use analysis::LaneChangeAnalyzer;
use anyhow::Result;
use std::path::Path;
use tracing::{debug, error, info, warn}; // Added warn
use types::{DetectedLane, Lane, LaneChangeConfig, LaneChangeEvent};

#[tokio::main]
async fn main() -> Result<()> {
    tracing_subscriber::fmt()
        .with_env_filter("overtake_detection=info,ort=warn")
        .init();

    info!("ðŸš— Lane Change Detection System Starting");

    let config = types::Config::load("config.yaml")?;
    info!("âœ“ Configuration loaded");

    let mut inference_engine = inference::InferenceEngine::new(config.clone())?;
    info!("âœ“ Inference engine ready");

    let video_processor = video_processor::VideoProcessor::new(config.clone());

    let video_files = video_processor.find_video_files()?;

    if video_files.is_empty() {
        error!("No video files found in {}", config.video.input_dir);
        return Ok(());
    }

    info!("Found {} video file(s) to process", video_files.len());

    for (idx, video_path) in video_files.iter().enumerate() {
        info!("\n========================================");
        info!(
            "Processing video {}/{}: {}",
            idx + 1,
            video_files.len(),
            video_path.display()
        );
        info!("========================================\n");

        match process_video(
            &video_path,
            &mut inference_engine,
            &video_processor,
            &config,
        )
        .await
        {
            Ok(stats) => {
                info!("\nâœ“ Video processed successfully!");
                info!("  Total frames: {}", stats.total_frames);
                info!("  Lane changes detected: {}", stats.lane_changes_detected);
            }
            Err(e) => {
                error!("Failed to process video: {}", e);
            }
        }
    }

    Ok(())
}

struct ProcessingStats {
    total_frames: u64,
    frames_with_position: u64,
    lane_changes_detected: usize,
    duration_secs: f64,
    avg_fps: f64,
}

async fn process_video(
    video_path: &Path,
    inference_engine: &mut inference::InferenceEngine,
    video_processor: &video_processor::VideoProcessor,
    config: &types::Config,
) -> Result<ProcessingStats> {
    use std::time::Instant;

    let start_time = Instant::now();

    let mut reader = video_processor.open_video(video_path)?;

    let mut writer =
        video_processor.create_writer(video_path, reader.width, reader.height, reader.fps)?;

    let lane_change_config = LaneChangeConfig {
        drift_threshold: 0.2,    // 20% deviation starts tracking
        crossing_threshold: 0.4, // 40% deviation means crossing
        min_frames_confirm: 3,   // Reduced from 5 to 3 for faster detection
        cooldown_frames: 30,
        smoothing_alpha: 0.3,
        reference_y_ratio: 0.8,
    };

    let mut analyzer = LaneChangeAnalyzer::new(lane_change_config);
    analyzer.set_source_id(video_path.to_string_lossy().to_string());

    let mut lane_changes: Vec<LaneChangeEvent> = Vec::new();
    let mut frame_count: u64 = 0;
    let mut frames_with_valid_position: u64 = 0;

    while let Some(frame) = reader.read_frame()? {
        frame_count += 1;
        let timestamp_ms = frame.timestamp_ms;

        match process_frame(&frame, inference_engine, config).await {
            Ok(detected_lanes) => {
                let analysis_lanes: Vec<Lane> = detected_lanes
                    .iter()
                    .enumerate()
                    .map(|(i, dl)| Lane::from_detected(i, dl))
                    .collect();

                // Run analysis
                if let Some(event) = analyzer.analyze(
                    &analysis_lanes,
                    frame.width as u32,
                    frame.height as u32,
                    frame_count,
                    timestamp_ms,
                ) {
                    lane_changes.push(event.clone());
                    // ðŸš¨ CRITICAL LOG: This will show when an event actually triggers
                    info!(
                        "ðŸš€ LANE CHANGE DETECTED: {} at {:.2}s (frame {})",
                        event.direction_name(),
                        event.video_timestamp_ms / 1000.0,
                        event.frame_id
                    );
                }

                // Debug log every 30 frames to check offset values
                if frame_count % 30 == 0 {
                    if let Some(vs) = analyzer.last_vehicle_state() {
                        if vs.is_valid() {
                            let normalized = vs.normalized_offset().unwrap_or(0.0);
                            let width = vs.lane_width.unwrap_or(0.0);
                            // Only log if offset is significant (> 10%)
                            if normalized.abs() > 0.1 {
                                info!(
                                    "Frame {}: State={} | Offset: {:.1}px ({:.1}%) | Width: {:.0}px",
                                    frame_count,
                                    analyzer.current_state(),
                                    vs.lateral_offset,
                                    normalized * 100.0,
                                    width
                                );
                            } else {
                                debug!(
                                    "Frame {}: State=CENTERED (Offset {:.1}%)",
                                    frame_count,
                                    normalized * 100.0
                                );
                            }
                        } else {
                            warn!(
                                "Frame {}: Invalid vehicle state (no lane width)",
                                frame_count
                            );
                        }
                    }
                }

                if analyzer
                    .last_vehicle_state()
                    .map_or(false, |s| s.is_valid())
                {
                    frames_with_valid_position += 1;
                }

                if let Some(ref mut w) = writer {
                    if let Ok(annotated) = video_processor::draw_lanes_with_state(
                        &frame.data,
                        reader.width,
                        reader.height,
                        &detected_lanes,
                        analyzer.current_state(),
                        analyzer.last_vehicle_state(),
                    ) {
                        use opencv::videoio::VideoWriterTrait;
                        w.write(&annotated)?;
                    }
                }
            }
            Err(e) => error!("Frame {} failed: {}", frame_count, e),
        }
    }

    let duration = start_time.elapsed();
    let avg_fps = frame_count as f64 / duration.as_secs_f64();

    info!("\nðŸ“Š Final Report:");
    info!("  Total Lane Changes: {}", lane_changes.len());

    // Print all events at the end
    for (i, event) in lane_changes.iter().enumerate() {
        info!(
            "  {}. {} at {:.2}s",
            i + 1,
            event.direction_name(),
            event.video_timestamp_ms / 1000.0
        );
    }

    save_results(video_path, &lane_changes, config)?;

    Ok(ProcessingStats {
        total_frames: frame_count,
        frames_with_position: frames_with_valid_position,
        lane_changes_detected: lane_changes.len(),
        duration_secs: duration.as_secs_f64(),
        avg_fps,
    })
}

async fn process_frame(
    frame: &types::Frame,
    inference_engine: &mut inference::InferenceEngine,
    config: &types::Config,
) -> Result<Vec<DetectedLane>> {
    let preprocessed = preprocessing::preprocess(
        &frame.data,
        frame.width,
        frame.height,
        config.model.input_width,
        config.model.input_height,
    )?;

    let output = inference_engine.infer(&preprocessed)?;

    let lane_detection = lane_detection::parse_lanes(
        &output,
        frame.width as f32,
        frame.height as f32,
        config,
        frame.timestamp_ms,
    )?;

    let high_confidence_lanes: Vec<DetectedLane> = lane_detection
        .lanes
        .into_iter()
        .filter(|lane| lane.confidence > config.detection.min_lane_confidence)
        .collect();

    Ok(high_confidence_lanes)
}

fn save_results(
    video_path: &Path,
    lane_changes: &[LaneChangeEvent],
    config: &types::Config,
) -> Result<()> {
    use std::fs::File;
    use std::io::Write;

    std::fs::create_dir_all(&config.video.output_dir)?;
    let video_name = video_path.file_stem().unwrap().to_str().unwrap();
    let jsonl_path =
        Path::new(&config.video.output_dir).join(format!("{}_lane_changes.jsonl", video_name));

    let mut file = File::create(&jsonl_path)?;
    for event in lane_changes {
        let json_line = serde_json::to_string(&event.to_json())?;
        writeln!(file, "{}", json_line)?;
    }
    info!("ðŸ’¾ Saved to: {}", jsonl_path.display());
    Ok(())
}
// src/preprocessing.rs

use anyhow::Result;

/// Preprocess raw RGB image for model input
pub fn preprocess(
    src: &[u8],
    src_width: usize,
    src_height: usize,
    dst_width: usize,
    dst_height: usize,
) -> Result<Vec<f32>> {
    // Resize
    let resized = resize_bilinear(src, src_width, src_height, dst_width, dst_height);

    // Normalize and convert HWC -> CHW
    const MEAN: [f32; 3] = [0.485, 0.456, 0.406];
    const STD: [f32; 3] = [0.229, 0.224, 0.225];

    let mut output = vec![0.0f32; 3 * dst_height * dst_width];

    for c in 0..3 {
        for h in 0..dst_height {
            for w in 0..dst_width {
                let hwc_idx = (h * dst_width + w) * 3 + c;
                let chw_idx = c * dst_height * dst_width + h * dst_width + w;

                let pixel = resized[hwc_idx] as f32 / 255.0;
                output[chw_idx] = (pixel - MEAN[c]) / STD[c];
            }
        }
    }

    Ok(output)
}

/// Bilinear image resize
fn resize_bilinear(src: &[u8], src_w: usize, src_h: usize, dst_w: usize, dst_h: usize) -> Vec<u8> {
    let mut dst = vec![0u8; dst_h * dst_w * 3];

    let x_ratio = src_w as f32 / dst_w as f32;
    let y_ratio = src_h as f32 / dst_h as f32;

    for dy in 0..dst_h {
        for dx in 0..dst_w {
            let sx = dx as f32 * x_ratio;
            let sy = dy as f32 * y_ratio;

            let sx0 = sx.floor() as usize;
            let sy0 = sy.floor() as usize;
            let sx1 = (sx0 + 1).min(src_w - 1);
            let sy1 = (sy0 + 1).min(src_h - 1);

            let fx = sx - sx0 as f32;
            let fy = sy - sy0 as f32;

            for c in 0..3 {
                let p00 = src[(sy0 * src_w + sx0) * 3 + c] as f32;
                let p10 = src[(sy0 * src_w + sx1) * 3 + c] as f32;
                let p01 = src[(sy1 * src_w + sx0) * 3 + c] as f32;
                let p11 = src[(sy1 * src_w + sx1) * 3 + c] as f32;

                let val = p00 * (1.0 - fx) * (1.0 - fy)
                    + p10 * fx * (1.0 - fy)
                    + p01 * (1.0 - fx) * fy
                    + p11 * fx * fy;

                dst[(dy * dst_w + dx) * 3 + c] = val.round() as u8;
            }
        }
    }

    dst
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_preprocess() {
        let src = vec![128u8; 640 * 480 * 3];
        let result = preprocess(&src, 640, 480, 1600, 320);
        assert!(result.is_ok());
        assert_eq!(result.unwrap().len(), 3 * 320 * 1600);
    }

    #[test]
    fn test_resize() {
        let src = vec![255u8; 100 * 100 * 3];
        let dst = resize_bilinear(&src, 100, 100, 50, 50);
        assert_eq!(dst.len(), 50 * 50 * 3);
    }
}
use opencv::{core, imgproc, prelude::*};

pub fn visualize_lanes(frame: &Mat, lanes: &[Lane], position: &VehiclePosition) -> Result<Mat> {
    let mut debug_frame = frame.clone();

    // Draw detected lanes with different colors
    let colors = [
        core::Scalar::new(255.0, 0.0, 0.0, 0.0),   // Blue - Lane 0
        core::Scalar::new(0.0, 255.0, 0.0, 0.0),   // Green - Lane 1
        core::Scalar::new(0.0, 0.0, 255.0, 0.0),   // Red - Lane 2
        core::Scalar::new(255.0, 255.0, 0.0, 0.0), // Cyan - Lane 3
    ];

    for (i, lane) in lanes.iter().enumerate() {
        // Draw lane points
        for window in lane.points.windows(2) {
            let p1 = core::Point::new(window[0].x as i32, window[0].y as i32);
            let p2 = core::Point::new(window[1].x as i32, window[1].y as i32);
            imgproc::line(
                &mut debug_frame,
                p1,
                p2,
                colors[i % 4],
                3,
                imgproc::LINE_8,
                0,
            )?;
        }

        // Draw lane ID
        if let Some(first_point) = lane.points.first() {
            imgproc::put_text(
                &mut debug_frame,
                &format!("L{} ({:.2})", i, lane.confidence),
                core::Point::new(first_point.x as i32, first_point.y as i32 - 10),
                imgproc::FONT_HERSHEY_SIMPLEX,
                0.6,
                colors[i % 4],
                2,
                imgproc::LINE_8,
                false,
            )?;
        }
    }

    // Draw vehicle position indicator
    let vehicle_x = frame.cols() / 2;
    let vehicle_y = (frame.rows() as f32 * 0.85) as i32;

    imgproc::circle(
        &mut debug_frame,
        core::Point::new(vehicle_x, vehicle_y),
        10,
        core::Scalar::new(0.0, 255.0, 255.0, 0.0), // Yellow
        -1,
        imgproc::LINE_8,
        0,
    )?;

    // Draw current lane info
    let info = format!(
        "Lane: {} | Offset: {:.2} | Conf: {:.2}",
        position.lane_index, position.lateral_offset, position.confidence
    );
    imgproc::put_text(
        &mut debug_frame,
        &info,
        core::Point::new(10, 30),
        imgproc::FONT_HERSHEY_SIMPLEX,
        0.8,
        core::Scalar::new(0.0, 255.0, 0.0, 0.0),
        2,
        imgproc::LINE_8,
        false,
    )?;

    Ok(debug_frame)
}
// src/inference.rs

use crate::types::Config;
use anyhow::{Context, Result};
use ort::{
    execution_providers::CUDAExecutionProvider,
    session::{builder::GraphOptimizationLevel, Session},
};
use tracing::{debug, info};

pub struct InferenceEngine {
    session: Session,
    config: Config,
}

impl InferenceEngine {
    pub fn new(config: Config) -> Result<Self> {
        info!("Initializing inference engine");
        info!("Model path: {}", config.model.path);

        let mut session_builder = Session::builder()?;

        // CUDA execution provider
        info!("Enabling CUDA execution provider");
        session_builder =
            session_builder.with_execution_providers([CUDAExecutionProvider::default()
                .with_device_id(0)
                .build()])?;

        info!("Building ONNX Runtime session...");
        let session = session_builder
            .with_optimization_level(GraphOptimizationLevel::Level3)?
            .with_intra_threads(config.inference.num_threads)?
            .with_inter_threads(1)?
            .commit_from_file(&config.model.path)
            .context("Failed to load model")?;

        info!("âœ“ Inference engine initialized successfully");

        Ok(Self { session, config })
    }

    pub fn infer(&mut self, input: &[f32]) -> Result<Vec<f32>> {
        debug!("Running inference");

        // Create shape tuple
        let shape = [
            1,
            3,
            self.config.model.input_height,
            self.config.model.input_width,
        ];

        // Create input value from tuple (shape, data)
        let input_value =
            ort::value::Value::from_array((shape.as_slice(), input.to_vec().into_boxed_slice()))?;

        // Run inference
        let outputs = self.session.run(ort::inputs!["input" => input_value])?;

        // Extract output
        let output = &outputs[0];
        let (output_shape, data_slice) = output.try_extract_tensor::<f32>()?;

        // DEBUG: Print actual output shape
        info!("Model output shape: {:?}", output_shape);
        info!("Model output size: {}", data_slice.len());

        // Convert slice to Vec
        let output_data: Vec<f32> = data_slice.to_vec();

        Ok(output_data)
    }
}
// src/detection/smoother.rs
use super::types::VehiclePosition;
use std::collections::{HashMap, VecDeque};

pub struct LanePositionSmoother {
    history: VecDeque<VehiclePosition>,
    window_size: usize,
}

impl LanePositionSmoother {
    pub fn new(window_size: usize) -> Self {
        Self {
            history: VecDeque::with_capacity(window_size),
            window_size,
        }
    }

    /// Smooth the position using temporal window
    pub fn smooth(&mut self, position: VehiclePosition) -> VehiclePosition {
        self.history.push_back(position);
        if self.history.len() > self.window_size {
            self.history.pop_front();
        }

        // Need at least 3 frames for smoothing
        if self.history.len() < 3 {
            return position;
        }

        VehiclePosition {
            lane_index: self.smooth_lane_index(),
            lateral_offset: self.smooth_lateral_offset(),
            confidence: self.smooth_confidence(),
            left_boundary: self.smooth_boundary(|p| p.left_boundary),
            right_boundary: self.smooth_boundary(|p| p.right_boundary),
            timestamp: position.timestamp, // Keep current timestamp
        }
    }

    /// Use mode (most common) for discrete lane index
    fn smooth_lane_index(&self) -> i32 {
        let mut counts: HashMap<i32, usize> = HashMap::new();
        for pos in &self.history {
            *counts.entry(pos.lane_index).or_insert(0) += 1;
        }

        counts
            .into_iter()
            .max_by_key(|(_, count)| *count)
            .map(|(lane, _)| lane)
            .unwrap_or(-1)
    }

    /// Use median for lateral offset (resistant to outliers)
    fn smooth_lateral_offset(&self) -> f32 {
        let mut offsets: Vec<f32> = self.history.iter().map(|p| p.lateral_offset).collect();
        offsets.sort_by(|a, b| a.partial_cmp(b).unwrap());
        offsets[offsets.len() / 2]
    }

    /// Average confidence
    fn smooth_confidence(&self) -> f32 {
        self.history.iter().map(|p| p.confidence).sum::<f32>() / self.history.len() as f32
    }

    /// Median for boundaries
    fn smooth_boundary<F>(&self, getter: F) -> f32
    where
        F: Fn(&VehiclePosition) -> f32,
    {
        let mut values: Vec<f32> = self.history.iter().map(&getter).collect();
        values.sort_by(|a, b| a.partial_cmp(b).unwrap());
        values[values.len() / 2]
    }

    /// Reset the smoother (e.g., after scene change)
    pub fn reset(&mut self) {
        self.history.clear();
    }
}
// src/detection/state_machine.rs
use super::types::{Direction, LaneChangeEvent, VehiclePosition};
use std::time::{Duration, Instant};

#[derive(Debug, Clone, Copy, PartialEq)]
pub enum PipelineState {
    Calibrating,
    StableInLane,
    ChangingLane,
    LaneChanged,
}

pub struct StateMachine {
    config: Config,
    state: PipelineState,
    current_position: VehiclePosition,
    previous_position: VehiclePosition,

    // Calibration
    calibration_frames: Vec<i32>,
    baseline_lane: Option<i32>,

    // Lane change tracking
    frames_above_threshold: u32,
    frames_in_new_lane: u32,
    lane_change_start_time: Option<Instant>,
    pending_direction: Direction,
}

#[derive(Debug, Clone)]
pub struct Config {
    pub offset_threshold: f32,
    pub debounce_frames: u32,
    pub confirm_frames: u32,
    pub timeout_ms: u64,
    pub calibration_frames: usize,
}

impl Default for Config {
    fn default() -> Self {
        Self {
            offset_threshold: 0.85, // Stricter than 0.7
            debounce_frames: 15,    // More than 5
            confirm_frames: 20,     // More than 10
            timeout_ms: 8000,
            calibration_frames: 90, // 3 seconds @ 30fps
        }
    }
}

impl StateMachine {
    pub fn new(config: Config) -> Self {
        Self {
            config,
            state: PipelineState::Calibrating,
            current_position: VehiclePosition::invalid(),
            previous_position: VehiclePosition::invalid(),
            calibration_frames: Vec::new(),
            baseline_lane: None,
            frames_above_threshold: 0,
            frames_in_new_lane: 0,
            lane_change_start_time: None,
            pending_direction: Direction::None,
        }
    }

    pub fn update(&mut self, position: VehiclePosition) -> Option<LaneChangeEvent> {
        self.previous_position = self.current_position;
        self.current_position = position;

        // Skip invalid positions
        if !position.is_valid() {
            return None;
        }

        match self.state {
            PipelineState::Calibrating => {
                self.calibration_frames.push(position.lane_index);

                if self.calibration_frames.len() >= self.config.calibration_frames {
                    self.baseline_lane = Some(self.compute_baseline_lane());
                    self.state = PipelineState::StableInLane;
                    println!(
                        "âœ“ Calibration complete. Baseline lane: {}",
                        self.baseline_lane.unwrap()
                    );
                }
                None
            }

            PipelineState::StableInLane => {
                if position.lateral_offset.abs() > self.config.offset_threshold {
                    self.frames_above_threshold += 1;

                    if self.frames_above_threshold >= self.config.debounce_frames {
                        self.state = PipelineState::ChangingLane;
                        self.lane_change_start_time = Some(Instant::now());
                        self.pending_direction = if position.lateral_offset < 0.0 {
                            Direction::Left
                        } else {
                            Direction::Right
                        };
                        println!("â†’ Lane change started: {:?}", self.pending_direction);
                    }
                } else {
                    self.frames_above_threshold = 0;
                }
                None
            }

            PipelineState::ChangingLane => {
                // Check timeout
                if let Some(start_time) = self.lane_change_start_time {
                    if start_time.elapsed() > Duration::from_millis(self.config.timeout_ms) {
                        println!("âœ— Lane change timeout");
                        self.reset_to_stable();
                        return None;
                    }
                }

                // Check if lane index changed
                if position.lane_index != self.previous_position.lane_index
                    && position.lane_index >= 0
                    && self.previous_position.lane_index >= 0
                {
                    self.state = PipelineState::LaneChanged;
                    self.frames_in_new_lane = 1;
                    println!(
                        "â†’ Lane index changed: {} â†’ {}",
                        self.previous_position.lane_index, position.lane_index
                    );
                }
                None
            }

            PipelineState::LaneChanged => {
                self.frames_in_new_lane += 1;

                if self.frames_in_new_lane >= self.config.confirm_frames {
                    println!("âœ“ Lane change confirmed");

                    let event = LaneChangeEvent {
                        timestamp: Instant::now(),
                        direction: self.pending_direction,
                        from_lane: self.previous_position.lane_index,
                        to_lane: position.lane_index,
                        confidence: position.confidence,
                    };

                    self.reset_to_stable();
                    Some(event)
                } else {
                    None
                }
            }
        }
    }

    fn reset_to_stable(&mut self) {
        self.state = PipelineState::StableInLane;
        self.frames_above_threshold = 0;
        self.frames_in_new_lane = 0;
        self.lane_change_start_time = None;
    }

    fn compute_baseline_lane(&self) -> i32 {
        let mut counts = std::collections::HashMap::new();
        for &lane in &self.calibration_frames {
            *counts.entry(lane).or_insert(0) += 1;
        }
        *counts
            .iter()
            .max_by_key(|(_, count)| *count)
            .map(|(lane, _)| lane)
            .unwrap_or(&1) // Default to lane 1
    }

    pub fn is_calibrated(&self) -> bool {
        self.baseline_lane.is_some()
    }
}
// src/detection/types.rs
use std::time::Instant;

#[derive(Debug, Clone, Copy)]
pub struct VehiclePosition {
    pub lane_index: i32,
    pub lateral_offset: f32,
    pub left_boundary: f32,
    pub right_boundary: f32,
    pub confidence: f32,
    pub timestamp: Instant,
}

impl VehiclePosition {
    pub fn invalid() -> Self {
        Self {
            lane_index: -1,
            lateral_offset: 0.0,
            left_boundary: 0.0,
            right_boundary: 0.0,
            confidence: 0.0,
            timestamp: Instant::now(),
        }
    }

    pub fn is_valid(&self) -> bool {
        self.lane_index >= 0 && self.confidence > 0.5
    }
}

#[derive(Debug, Clone)]
pub struct Lane {
    pub points: Vec<LanePoint>,
    pub lane_id: usize,
    pub confidence: f32,
}

#[derive(Debug, Clone, Copy)]
pub struct LanePoint {
    pub x: f32,
    pub y: f32,
    pub confidence: f32,
}

#[derive(Debug, Clone, Copy, PartialEq)]
pub enum Direction {
    None,
    Left,
    Right,
}

#[derive(Debug, Clone, Copy)]
pub struct LaneChangeEvent {
    pub timestamp: Instant,
    pub direction: Direction,
    pub from_lane: i32,
    pub to_lane: i32,
    pub confidence: f32,
}

#[derive(Debug, Clone)]
pub struct OvertakeEvent {
    pub start_timestamp: Instant,
    pub end_timestamp: Instant,
    pub first_direction: Direction,
    pub second_direction: Direction,
    pub start_lane: i32,
    pub end_lane: i32,
    pub is_complete: bool,
    pub confidence: f32,
}
// src/detection/position_calculator.rs
use super::types::{Lane, VehiclePosition};

const MIN_LANE_CONFIDENCE: f32 = 0.6;
const MIN_POINTS_PER_LANE: usize = 5;

pub fn calculate_vehicle_position(
    lanes: &[Lane],
    image_width: u32,
    image_height: u32,
) -> VehiclePosition {
    let vehicle_center_x = image_width as f32 / 2.0;
    let sample_y = image_height as f32 * 0.85;

    // Filter lanes by confidence and point count
    let valid_lanes: Vec<&Lane> = lanes
        .iter()
        .filter(|lane| {
            lane.confidence > MIN_LANE_CONFIDENCE && lane.points.len() >= MIN_POINTS_PER_LANE
        })
        .collect();

    if valid_lanes.len() < 2 {
        return VehiclePosition::invalid();
    }

    // Get x-coordinates at sample height
    let mut lane_xs: Vec<(usize, f32)> = valid_lanes
        .iter()
        .enumerate()
        .filter_map(|(i, lane)| interpolate_lane_x(lane, sample_y).map(|x| (i, x)))
        .collect();

    // Sort by x-coordinate
    lane_xs.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap());

    // Filter out lanes too far from vehicle center (likely road edges)
    let max_distance = image_width as f32 * 0.6;
    lane_xs.retain(|(_, x)| (x - vehicle_center_x).abs() < max_distance);

    if lane_xs.len() < 2 {
        return VehiclePosition::invalid();
    }

    // Find which lane boundaries the vehicle is between
    for i in 0..lane_xs.len() - 1 {
        let (left_idx, left_x) = lane_xs[i];
        let (right_idx, right_x) = lane_xs[i + 1];

        if left_x <= vehicle_center_x && vehicle_center_x <= right_x {
            let lane_width = right_x - left_x;
            let offset_normalized = ((vehicle_center_x - left_x) / lane_width - 0.5) * 2.0;

            return VehiclePosition {
                lane_index: i as i32,
                lateral_offset: offset_normalized,
                left_boundary: left_x,
                right_boundary: right_x,
                confidence: valid_lanes[left_idx]
                    .confidence
                    .min(valid_lanes[right_idx].confidence),
                timestamp: std::time::Instant::now(),
            };
        }
    }

    VehiclePosition::invalid()
}

fn interpolate_lane_x(lane: &Lane, target_y: f32) -> Option<f32> {
    // Find two points bracketing target_y
    let mut lower: Option<&crate::detection::types::LanePoint> = None;
    let mut upper: Option<&crate::detection::types::LanePoint> = None;

    for point in &lane.points {
        if point.y <= target_y {
            if lower.is_none() || point.y > lower.unwrap().y {
                lower = Some(point);
            }
        }
        if point.y >= target_y {
            if upper.is_none() || point.y < upper.unwrap().y {
                upper = Some(point);
            }
        }
    }

    match (lower, upper) {
        (Some(p1), Some(p2)) if (p2.y - p1.y).abs() > 0.1 => {
            // Linear interpolation
            let t = (target_y - p1.y) / (p2.y - p1.y);
            Some(p1.x + t * (p2.x - p1.x))
        }
        (Some(p), None) | (None, Some(p)) => Some(p.x),
        _ => None,
    }
}
// src/detection/mod.rs

mod overtake_detector;
mod position_calculator;
mod smoother;
mod state_machine;
mod types;

// Re-export public APIs
pub use overtake_detector::OvertakeDetector;
pub use position_calculator::calculate_vehicle_position;
pub use smoother::LanePositionSmoother;
pub use state_machine::StateMachine;
pub use types::*;
use std::collections::VecDeque;

pub struct LanePositionSmoother {
    history: VecDeque<VehiclePosition>,
    window_size: usize,
}

impl LanePositionSmoother {
    pub fn new(window_size: usize) -> Self {
        Self {
            history: VecDeque::with_capacity(window_size),
            window_size,
        }
    }

    pub fn smooth(&mut self, position: VehiclePosition) -> VehiclePosition {
        self.history.push_back(position);
        if self.history.len() > self.window_size {
            self.history.pop_front();
        }

        // Mode for lane_index (most common in window)
        let lane_index = self.most_common_lane();

        // Median for lateral_offset (reduce noise)
        let mut offsets: Vec<f32> = self.history.iter().map(|p| p.lateral_offset).collect();
        offsets.sort_by(|a, b| a.partial_cmp(b).unwrap());
        let lateral_offset = offsets[offsets.len() / 2];

        // Average confidence
        let confidence =
            self.history.iter().map(|p| p.confidence).sum::<f32>() / self.history.len() as f32;

        VehiclePosition {
            lane_index,
            lateral_offset,
            confidence,
            ..position
        }
    }

    fn most_common_lane(&self) -> i32 {
        let mut counts = std::collections::HashMap::new();
        for pos in &self.history {
            *counts.entry(pos.lane_index).or_insert(0) += 1;
        }
        *counts
            .iter()
            .max_by_key(|(_, count)| *count)
            .map(|(lane, _)| lane)
            .unwrap_or(&-1)
    }
}
