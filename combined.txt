//
// EVERYTHING BELOW THIS POINT WAS AUTO-GENERATED DURING COMPILATION. DO NOT MODIFY.
//
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The Continuous Integration platform detected during compilation."#]
#[allow(dead_code)]
pub static CI_PLATFORM: Option<&str> = None;
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The full version."#]
#[allow(dead_code)]
pub static PKG_VERSION: &str = "0.8.1";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The major version."#]
#[allow(dead_code)]
pub static PKG_VERSION_MAJOR: &str = "0";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The minor version."#]
#[allow(dead_code)]
pub static PKG_VERSION_MINOR: &str = "8";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The patch version."#]
#[allow(dead_code)]
pub static PKG_VERSION_PATCH: &str = "1";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The pre-release version."#]
#[allow(dead_code)]
pub static PKG_VERSION_PRE: &str = "";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"A colon-separated list of authors."#]
#[allow(dead_code)]
pub static PKG_AUTHORS: &str = "Thomas Daede <tdaede@xiph.org>";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The name of the package."#]
#[allow(dead_code)]
pub static PKG_NAME: &str = "rav1e";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The description."#]
#[allow(dead_code)]
pub static PKG_DESCRIPTION: &str = "The fastest and safest AV1 encoder";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The homepage."#]
#[allow(dead_code)]
pub static PKG_HOMEPAGE: &str = "";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The license."#]
#[allow(dead_code)]
pub static PKG_LICENSE: &str = "BSD-2-Clause";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The source repository as advertised in Cargo.toml."#]
#[allow(dead_code)]
pub static PKG_REPOSITORY: &str = "https://github.com/xiph/rav1e/";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The target triple that was being compiled for."#]
#[allow(dead_code)]
pub static TARGET: &str = "aarch64-apple-darwin";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The host triple of the rust compiler."#]
#[allow(dead_code)]
pub static HOST: &str = "aarch64-apple-darwin";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"`release` for release builds, `debug` for other builds."#]
#[allow(dead_code)]
pub static PROFILE: &str = "debug";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The compiler that cargo resolved to use."#]
#[allow(dead_code)]
pub static RUSTC: &str = "/Users/abraxas/.rustup/toolchains/stable-aarch64-apple-darwin/bin/rustc";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The documentation generator that cargo resolved to use."#]
#[allow(dead_code)]
pub static RUSTDOC: &str = "/Users/abraxas/.rustup/toolchains/stable-aarch64-apple-darwin/bin/rustdoc";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"Value of OPT_LEVEL for the profile used during compilation."#]
#[allow(dead_code)]
pub static OPT_LEVEL: &str = "0";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The parallelism that was specified during compilation."#]
#[allow(dead_code)]
pub static NUM_JOBS: u32 = 12;
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"Value of DEBUG for the profile used during compilation."#]
#[allow(dead_code)]
pub static DEBUG: bool = true;
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The features that were enabled during compilation."#]
#[allow(dead_code)]
pub static FEATURES: [&str; 1] = ["THREADING"];
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The features as a comma-separated string."#]
#[allow(dead_code)]
pub static FEATURES_STR: &str = "THREADING";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The features as above, as lowercase strings."#]
#[allow(dead_code)]
pub static FEATURES_LOWERCASE: [&str; 1] = ["threading"];
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The feature-string as above, from lowercase strings."#]
#[allow(dead_code)]
pub static FEATURES_LOWERCASE_STR: &str = "threading";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The output of `/Users/abraxas/.rustup/toolchains/stable-aarch64-apple-darwin/bin/rustc -V`"#]
#[allow(dead_code)]
pub static RUSTC_VERSION: &str = "rustc 1.92.0 (ded5c06cf 2025-12-08)";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The output of `/Users/abraxas/.rustup/toolchains/stable-aarch64-apple-darwin/bin/rustdoc -V`; empty string if `/Users/abraxas/.rustup/toolchains/stable-aarch64-apple-darwin/bin/rustdoc -V` failed to execute"#]
#[allow(dead_code)]
pub static RUSTDOC_VERSION: &str = "rustdoc 1.92.0 (ded5c06cf 2025-12-08)";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The target architecture, given by `CARGO_CFG_TARGET_ARCH`."#]
#[allow(dead_code)]
pub static CFG_TARGET_ARCH: &str = "aarch64";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The endianness, given by `CARGO_CFG_TARGET_ENDIAN`."#]
#[allow(dead_code)]
pub static CFG_ENDIAN: &str = "little";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The toolchain-environment, given by `CARGO_CFG_TARGET_ENV`."#]
#[allow(dead_code)]
pub static CFG_ENV: &str = "";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The OS-family, given by `CARGO_CFG_TARGET_FAMILY`."#]
#[allow(dead_code)]
pub static CFG_FAMILY: &str = "unix";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The operating system, given by `CARGO_CFG_TARGET_OS`."#]
#[allow(dead_code)]
pub static CFG_OS: &str = "macos";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The pointer width, given by `CARGO_CFG_TARGET_POINTER_WIDTH`."#]
#[allow(dead_code)]
pub static CFG_POINTER_WIDTH: &str = "64";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The override-variables that were used during compilation."#]
#[allow(dead_code)]
pub static OVERRIDE_VARIABLES_USED: [&str; 0] = [];
//
// EVERYTHING ABOVE THIS POINT WAS AUTO-GENERATED DURING COMPILATION. DO NOT MODIFY.
//
#[doc(hidden)]
pub mod __private17 {
    #[doc(hidden)]
    pub use crate::private::*;
}
#[doc(hidden)]
pub mod __private228 {
    #[doc(hidden)]
    pub use crate::private::*;
}
use serde_core::__private228 as serde_core_private;
#[doc(hidden)]
pub mod __private228 {
    #[doc(hidden)]
    pub use crate::private::*;
}
// src/smoother.rs

use crate::types::VehiclePosition;
use std::collections::{HashMap, VecDeque};

/// Temporal smoother for vehicle position using a sliding window
pub struct LanePositionSmoother {
    history: VecDeque<VehiclePosition>,
    window_size: usize,
}

impl LanePositionSmoother {
    /// Create a new smoother with specified window size
    ///
    /// # Arguments
    /// * `window_size` - Number of frames to use for smoothing (e.g., 10 frames)
    pub fn new(window_size: usize) -> Self {
        Self {
            history: VecDeque::with_capacity(window_size),
            window_size,
        }
    }

    /// Smooth the current position using temporal window
    ///
    /// Uses different strategies for different components:
    /// - Lane index: Mode (most common value)
    /// - Lateral offset: Median (resistant to outliers)
    /// - Confidence: Average
    pub fn smooth(&mut self, position: VehiclePosition) -> VehiclePosition {
        self.history.push_back(position);

        // Maintain window size
        if self.history.len() > self.window_size {
            self.history.pop_front();
        }

        // Need at least 3 frames for meaningful smoothing
        if self.history.len() < 3 {
            return position;
        }

        VehiclePosition {
            lane_index: self.smooth_lane_index(),
            lateral_offset: self.smooth_lateral_offset(),
            confidence: self.smooth_confidence(),
            timestamp: position.timestamp, // Keep current timestamp
        }
    }

    /// Get the most common lane index (mode)
    fn smooth_lane_index(&self) -> i32 {
        let mut counts: HashMap<i32, usize> = HashMap::new();

        for pos in &self.history {
            *counts.entry(pos.lane_index).or_insert(0) += 1;
        }

        counts
            .into_iter()
            .max_by_key(|(_, count)| *count)
            .map(|(lane, _)| lane)
            .unwrap_or(-1)
    }

    /// Get median lateral offset (resistant to outliers)
    fn smooth_lateral_offset(&self) -> f32 {
        let mut offsets: Vec<f32> = self.history.iter().map(|p| p.lateral_offset).collect();
        offsets.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
        offsets[offsets.len() / 2]
    }

    /// Get average confidence
    fn smooth_confidence(&self) -> f32 {
        let sum: f32 = self.history.iter().map(|p| p.confidence).sum();
        sum / self.history.len() as f32
    }

    /// Reset the smoother (e.g., when video changes)
    pub fn reset(&mut self) {
        self.history.clear();
    }

    /// Get the number of frames currently in the history
    pub fn history_size(&self) -> usize {
        self.history.len()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_smoother_mode_for_lane_index() {
        let mut smoother = LanePositionSmoother::new(5);

        // Feed noisy lane detections: [1, 1, 2, 1, 1]
        let positions = vec![
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.0,
            },
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.033,
            },
            VehiclePosition {
                lane_index: 2, // noise
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.066,
            },
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.099,
            },
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.132,
            },
        ];

        for pos in positions {
            smoother.smooth(pos);
        }

        // Last smoothed position should have lane_index = 1 (mode)
        let last_pos = positions.last().unwrap();
        let smoothed = smoother.smooth(*last_pos);
        assert_eq!(smoothed.lane_index, 1);
    }

    #[test]
    fn test_smoother_median_for_offset() {
        let mut smoother = LanePositionSmoother::new(5);

        // Feed offsets with outlier: [-0.1, -0.05, 0.0, 0.05, 2.0 (outlier)]
        let offsets = vec![-0.1, -0.05, 0.0, 0.05, 2.0];

        for (i, offset) in offsets.iter().enumerate() {
            let pos = VehiclePosition {
                lane_index: 1,
                lateral_offset: *offset,
                confidence: 0.8,
                timestamp: i as f64 * 0.033,
            };
            smoother.smooth(pos);
        }

        let last_pos = VehiclePosition {
            lane_index: 1,
            lateral_offset: 2.0,
            confidence: 0.8,
            timestamp: 0.165,
        };
        let smoothed = smoother.smooth(last_pos);

        // Median should be 0.0 (middle value), not affected by 2.0 outlier
        assert_eq!(smoothed.lateral_offset, 0.0);
    }
}
// src/frame_buffer.rs

use crate::types::{Frame, LaneChangeEvent};
use base64::{engine::general_purpose::STANDARD, Engine as _};
use serde::{Deserialize, Serialize};
use std::collections::VecDeque;
use std::path::Path;
use tracing::{error, info};

/// Buffer to capture frames during a lane change event with pre-buffering
pub struct LaneChangeFrameBuffer {
    frames: Vec<Frame>,
    max_frames: usize,
    is_capturing: bool,
    capture_start_frame_id: Option<u64>,
    /// Pre-buffer: keeps last N frames before lane change starts
    pre_buffer: VecDeque<Frame>,
    pre_buffer_size: usize,
}

impl LaneChangeFrameBuffer {
    pub fn new(max_frames: usize) -> Self {
        // Pre-buffer holds frames BEFORE lane change starts (e.g., 20 frames)
        let pre_buffer_size = 20;

        Self {
            frames: Vec::with_capacity(max_frames),
            max_frames,
            is_capturing: false,
            capture_start_frame_id: None,
            pre_buffer: VecDeque::with_capacity(pre_buffer_size),
            pre_buffer_size,
        }
    }

    /// Add frame to pre-buffer (called continuously while in CENTERED state)
    pub fn add_to_pre_buffer(&mut self, frame: Frame) {
        self.pre_buffer.push_back(frame);
        if self.pre_buffer.len() > self.pre_buffer_size {
            self.pre_buffer.pop_front();
        }
    }

    pub fn start_capture(&mut self, frame_id: u64) {
        self.frames.clear();
        self.is_capturing = true;
        self.capture_start_frame_id = Some(frame_id);

        // Transfer pre-buffer frames to main buffer
        let pre_buffer_count = self.pre_buffer.len();
        for frame in self.pre_buffer.drain(..) {
            if self.frames.len() < self.max_frames {
                self.frames.push(frame);
            }
        }

        info!(
            "ðŸ“¹ Started capturing at frame {} (included {} pre-buffered frames)",
            frame_id, pre_buffer_count
        );
    }

    pub fn add_frame(&mut self, frame: Frame) {
        if self.is_capturing && self.frames.len() < self.max_frames {
            self.frames.push(frame);
        }
    }

    pub fn stop_capture(&mut self) -> Vec<Frame> {
        self.is_capturing = false;
        self.capture_start_frame_id = None;
        let frames = std::mem::take(&mut self.frames);
        info!("ðŸ“¹ Stopped capturing. Total frames: {}", frames.len());
        frames
    }

    pub fn is_capturing(&self) -> bool {
        self.is_capturing
    }

    pub fn frame_count(&self) -> usize {
        self.frames.len()
    }

    pub fn cancel_capture(&mut self) {
        self.frames.clear();
        self.is_capturing = false;
        self.capture_start_frame_id = None;
    }

    pub fn pre_buffer_count(&self) -> usize {
        self.pre_buffer.len()
    }
}

// ============================================================================
// ENHANCED API STRUCTURES WITH DETECTION METADATA
// ============================================================================

/// Detection quality metadata to help AI make better decisions
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DetectionMetadata {
    /// Confidence of the lane change detection (0.0-1.0)
    pub detection_confidence: f32,
    /// Maximum lateral offset reached during maneuver (normalized, 0.0-1.0)
    pub max_offset_normalized: f32,
    /// Average lane detection confidence across frames (0.0-1.0)
    pub avg_lane_confidence: f32,
    /// Percentage of frames where both lanes were detected (0.0-1.0)
    pub both_lanes_ratio: f32,
    /// Video resolution (e.g., "1280x720")
    pub video_resolution: String,
    /// Frames per second
    pub fps: f32,
    /// Country/region for traffic rules (e.g., "PE" for Peru)
    pub region: String,
    /// Average lane width in pixels during the maneuver
    pub avg_lane_width_px: Option<f32>,
}

/// Enhanced payload for the legality analysis API
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LaneChangeLegalityRequest {
    pub event_id: String,
    pub direction: String,
    pub start_frame_id: u64,
    pub end_frame_id: u64,
    pub video_timestamp_ms: f64,
    pub duration_ms: Option<f64>,
    pub source_id: String,
    pub frames: Vec<FrameData>,
    /// NEW: Detection quality metadata
    pub detection_metadata: DetectionMetadata,
}

/// Enhanced frame data with per-frame metadata
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FrameData {
    pub frame_index: usize,
    pub timestamp_ms: f64,
    pub width: usize,
    pub height: usize,
    pub base64_image: String,
    /// NEW: Lane detection confidence for this frame (if available)
    #[serde(skip_serializing_if = "Option::is_none")]
    pub lane_confidence: Option<f32>,
    /// NEW: Lateral offset as percentage of lane width (if available)
    #[serde(skip_serializing_if = "Option::is_none")]
    pub offset_percentage: Option<f32>,
}

/// Response from the legality API
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LaneChangeLegalityResponse {
    pub event_id: String,
    pub status: String,
    pub message: String,
}

// ============================================================================
// HELPER FUNCTIONS
// ============================================================================

/// Extract key frames emphasizing CONTEXT and PROGRESSION
pub fn extract_key_frames_for_lane_change(frames: &[Frame], count: usize) -> Vec<&Frame> {
    if frames.is_empty() || count == 0 {
        return vec![];
    }

    if frames.len() <= count {
        return frames.iter().collect();
    }

    let mut selected_indices = Vec::with_capacity(count);

    // Strategy: Include frames from BEFORE, DURING, and AFTER the maneuver
    // This gives the AI context about what was "normal" before the change

    match count {
        5 => {
            // Frame 0: Start (should be from pre-buffer, BEFORE maneuver)
            // Frame 1: Early (25%)
            // Frame 2: Middle (50%)
            // Frame 3: Late (75%)
            // Frame 4: End (100%)
            selected_indices.push(0);
            selected_indices.push(frames.len() / 4);
            selected_indices.push(frames.len() / 2);
            selected_indices.push((frames.len() * 3) / 4);
            selected_indices.push(frames.len() - 1);
        }
        7 => {
            // More granular: every ~16%
            selected_indices.push(0); // 0%
            selected_indices.push(frames.len() / 6); // 16%
            selected_indices.push(frames.len() / 3); // 33%
            selected_indices.push(frames.len() / 2); // 50%
            selected_indices.push((frames.len() * 2) / 3); // 66%
            selected_indices.push((frames.len() * 5) / 6); // 83%
            selected_indices.push(frames.len() - 1); // 100%
        }
        _ => {
            // Evenly distributed
            let step = (frames.len() - 1) as f32 / (count - 1) as f32;
            for i in 0..count {
                let index = (i as f32 * step).round() as usize;
                selected_indices.push(index.min(frames.len() - 1));
            }
        }
    }

    selected_indices.into_iter().map(|i| &frames[i]).collect()
}

/// Convert frame to base64 JPEG with quality optimization
pub fn frame_to_base64(frame: &Frame) -> Result<String, anyhow::Error> {
    use image::{codecs::jpeg::JpegEncoder, ImageBuffer, Rgb};
    use std::io::Cursor;

    let img: ImageBuffer<Rgb<u8>, Vec<u8>> =
        ImageBuffer::from_raw(frame.width as u32, frame.height as u32, frame.data.clone())
            .ok_or_else(|| anyhow::anyhow!("Failed to create image buffer"))?;

    let mut buffer = Cursor::new(Vec::new());

    // Use explicit JPEG encoder with quality setting
    let mut encoder = JpegEncoder::new_with_quality(&mut buffer, 85);
    encoder.encode(
        img.as_raw(),
        img.width(),
        img.height(),
        image::ExtendedColorType::Rgb8,
    )?;

    Ok(STANDARD.encode(buffer.into_inner()))
}

/// Build the API request payload with enhanced metadata
pub fn build_legality_request(
    event: &LaneChangeEvent,
    captured_frames: &[Frame],
    num_frames_to_send: usize,
) -> Result<LaneChangeLegalityRequest, anyhow::Error> {
    let key_frames = extract_key_frames_for_lane_change(captured_frames, num_frames_to_send);

    if key_frames.is_empty() {
        anyhow::bail!("No frames to send");
    }

    let mut frame_data_list = Vec::with_capacity(key_frames.len());

    // Log which frames were selected
    let selected_indices: Vec<usize> = key_frames
        .iter()
        .filter_map(|kf| captured_frames.iter().position(|f| std::ptr::eq(*kf, f)))
        .collect();

    info!(
        "ðŸ“¸ Selected {} frames from {} total: indices {:?}",
        key_frames.len(),
        captured_frames.len(),
        selected_indices
    );

    // Process each frame
    for (i, frame) in key_frames.iter().enumerate() {
        let base64_image = frame_to_base64(frame)?;

        let lane_confidence = None;
        let offset_percentage = None;

        frame_data_list.push(FrameData {
            frame_index: i,
            timestamp_ms: frame.timestamp_ms,
            width: frame.width,
            height: frame.height,
            base64_image,
            lane_confidence,
            offset_percentage,
        });
    }

    // Calculate video metadata
    let video_resolution = format!(
        "{}x{}",
        key_frames.first().unwrap().width,
        key_frames.first().unwrap().height
    );

    // Calculate FPS from frame timestamps
    let fps = if key_frames.len() >= 2 {
        let time_span =
            key_frames.last().unwrap().timestamp_ms - key_frames.first().unwrap().timestamp_ms;
        if time_span > 0.0 {
            ((key_frames.len() - 1) as f64 / (time_span / 1000.0)) as f32
        } else {
            25.0
        }
    } else {
        25.0
    };

    let max_offset_normalized = event
        .metadata
        .get("max_offset_normalized")
        .and_then(|v| v.as_f64())
        .map(|v| v as f32)
        .unwrap_or(0.5);

    let both_lanes_ratio = event
        .metadata
        .get("both_lanes_ratio")
        .and_then(|v| v.as_f64())
        .map(|v| v as f32)
        .unwrap_or(0.7);

    let avg_lane_confidence = event
        .metadata
        .get("avg_lane_confidence")
        .and_then(|v| v.as_f64())
        .map(|v| v as f32)
        .unwrap_or(0.6);

    let avg_lane_width_px = event
        .metadata
        .get("avg_lane_width_px")
        .and_then(|v| v.as_f64())
        .map(|v| v as f32);

    let metadata = DetectionMetadata {
        detection_confidence: event.confidence,
        max_offset_normalized,
        avg_lane_confidence,
        both_lanes_ratio,
        video_resolution,
        fps,
        region: "PE".to_string(),
        avg_lane_width_px,
    };

    info!(
        "ðŸ“Š Detection quality: conf={:.1}%, max_offset={:.1}%, lanes={:.0}%",
        metadata.detection_confidence * 100.0,
        metadata.max_offset_normalized * 100.0,
        metadata.both_lanes_ratio * 100.0
    );

    Ok(LaneChangeLegalityRequest {
        event_id: event.event_id.clone(),
        direction: event.direction_name().to_string(),
        start_frame_id: event.start_frame_id,
        end_frame_id: event.end_frame_id,
        video_timestamp_ms: event.video_timestamp_ms,
        duration_ms: event.duration_ms,
        source_id: event.source_id.clone(),
        frames: frame_data_list,
        detection_metadata: metadata,
    })
}

/// Send the request to the legality analysis API
pub async fn send_to_legality_api(
    request: &LaneChangeLegalityRequest,
    api_url: &str,
) -> Result<LaneChangeLegalityResponse, anyhow::Error> {
    let client = reqwest::Client::builder()
        .timeout(std::time::Duration::from_secs(60))
        .build()?;

    info!(
        "ðŸ“¤ Sending event {} to legality API at {}",
        request.event_id, api_url
    );

    let response = client.post(api_url).json(request).send().await;

    match response {
        Ok(resp) => {
            let status = resp.status();

            if !status.is_success() {
                let body = resp.text().await.unwrap_or_default();
                anyhow::bail!("API error {}: {}", status, body);
            }

            let result = resp.json::<LaneChangeLegalityResponse>().await?;

            info!(
                "ðŸ“¨ API response for {}: {} - {}",
                result.event_id, result.status, result.message
            );

            Ok(result)
        }
        Err(e) => {
            error!("âŒ Failed to connect to API: {}", e);
            anyhow::bail!("Failed to connect to API: {}", e)
        }
    }
}

/// Print the request payload to console with enhanced metadata
pub fn print_legality_request(request: &LaneChangeLegalityRequest) {
    println!("\n============================================================");
    println!("ðŸš— LANE CHANGE LEGALITY CHECK REQUEST");
    println!("============================================================");
    println!("Event ID: {}", request.event_id);
    println!("Direction: {}", request.direction);
    println!(
        "Frames: {} -> {}",
        request.start_frame_id, request.end_frame_id
    );
    println!("Timestamp: {:.2}s", request.video_timestamp_ms / 1000.0);
    if let Some(duration) = request.duration_ms {
        println!("Duration: {:.0}ms", duration);
    }
    println!("Source: {}", request.source_id);

    println!("\nðŸ“Š Detection Quality:");
    println!(
        "  â€¢ Confidence:       {:.0}%",
        request.detection_metadata.detection_confidence * 100.0
    );
    println!(
        "  â€¢ Max offset:       {:.0}%",
        request.detection_metadata.max_offset_normalized * 100.0
    );
    println!(
        "  â€¢ Lane confidence:  {:.0}%",
        request.detection_metadata.avg_lane_confidence * 100.0
    );
    println!(
        "  â€¢ Both lanes ratio: {:.0}%",
        request.detection_metadata.both_lanes_ratio * 100.0
    );
    println!(
        "  â€¢ Resolution:       {}",
        request.detection_metadata.video_resolution
    );
    println!(
        "  â€¢ FPS:              {:.1}",
        request.detection_metadata.fps
    );
    if let Some(width) = request.detection_metadata.avg_lane_width_px {
        println!("  â€¢ Avg lane width:   {:.0}px", width);
    }

    println!("\nðŸŽ¬ Frames for analysis: {}", request.frames.len());
    for frame_data in &request.frames {
        print!(
            "  Frame {}: {}x{} @ {:.2}s | base64: {} chars",
            frame_data.frame_index,
            frame_data.width,
            frame_data.height,
            frame_data.timestamp_ms / 1000.0,
            frame_data.base64_image.len()
        );
        if let Some(conf) = frame_data.lane_confidence {
            print!(" | lane_conf: {:.0}%", conf * 100.0);
        }
        if let Some(offset) = frame_data.offset_percentage {
            print!(" | offset: {:.0}%", offset * 100.0);
        }
        println!();
    }
    println!("============================================================\n");
}

/// Save the request to a JSON file
pub fn save_legality_request_to_file(
    request: &LaneChangeLegalityRequest,
    output_dir: &str,
) -> Result<std::path::PathBuf, anyhow::Error> {
    let dir = Path::new(output_dir).join("legality_requests");
    std::fs::create_dir_all(&dir)?;

    let filename = format!("{}_legality_request.json", request.event_id);
    let filepath = dir.join(&filename);

    let json = serde_json::to_string_pretty(request)?;
    std::fs::write(&filepath, json)?;

    info!("ðŸ’¾ Saved legality request to: {}", filepath.display());
    Ok(filepath)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_extract_key_frames_for_lane_change() {
        let frames: Vec<Frame> = (0..10)
            .map(|i| Frame {
                data: vec![],
                width: 1280,
                height: 720,
                timestamp_ms: i as f64 * 100.0,
            })
            .collect();
        let key_frames = extract_key_frames_for_lane_change(&frames, 5);
        assert_eq!(key_frames.len(), 5);

        assert_eq!(key_frames[0].timestamp_ms, 0.0);
        assert_eq!(key_frames[4].timestamp_ms, 900.0);
    }
}
// src/types.rs

use serde::{Deserialize, Serialize};
use std::collections::HashMap;

// ============================================================================
// Configuration Structs
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Config {
    pub model: ModelConfig,
    pub inference: InferenceConfig,
    pub detection: DetectionConfig,
    pub video: VideoConfig,
    pub logging: LoggingConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelConfig {
    pub path: String,
    pub input_width: usize,
    pub input_height: usize,
    pub num_anchors: usize,
    pub num_lanes: usize,
    pub griding_num: usize,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct InferenceConfig {
    pub use_tensorrt: bool,
    pub use_fp16: bool,
    pub enable_engine_cache: bool,
    pub engine_cache_path: String,
    pub num_threads: usize,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DetectionConfig {
    pub confidence_threshold: f32,
    pub min_points_per_lane: usize,
    pub smoother_window_size: usize,
    pub calibration_frames: usize,
    pub debounce_frames: u32,
    pub confirm_frames: u32,
    pub min_lane_confidence: f32,
    pub min_position_confidence: f32,
    #[serde(default = "default_drift_threshold")]
    pub drift_threshold: f32,
    #[serde(default = "default_crossing_threshold")]
    pub crossing_threshold: f32,
    #[serde(default = "default_cooldown_frames")]
    pub cooldown_frames: u32,
    #[serde(default = "default_min_duration")]
    pub min_lane_change_duration_ms: f64,
    #[serde(default = "default_max_duration")]
    pub max_lane_change_duration_ms: f64,
    #[serde(default = "default_skip_initial")]
    pub skip_initial_frames: u64,
    #[serde(default = "default_require_both_lanes")]
    pub require_both_lanes: bool,
}

fn default_drift_threshold() -> f32 {
    0.30
}
fn default_crossing_threshold() -> f32 {
    0.55
}
fn default_cooldown_frames() -> u32 {
    90
}
fn default_min_duration() -> f64 {
    1500.0
}
fn default_max_duration() -> f64 {
    5000.0
}
fn default_skip_initial() -> u64 {
    150
}
fn default_require_both_lanes() -> bool {
    true
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VideoConfig {
    pub input_dir: String,
    pub output_dir: String,
    pub source_width: usize,
    pub source_height: usize,
    pub target_fps: u32,
    pub save_annotated: bool,
    pub save_events_only: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LoggingConfig {
    pub level: String,
}

impl Config {
    pub fn load(path: &str) -> anyhow::Result<Self> {
        let contents = std::fs::read_to_string(path)?;
        let config: Config = serde_yaml::from_str(&contents)?;
        Ok(config)
    }
}

// ============================================================================
// Frame Type
// ============================================================================

#[derive(Debug, Clone)]
pub struct Frame {
    pub data: Vec<u8>,
    pub width: usize,
    pub height: usize,
    pub timestamp_ms: f64,
}

// ============================================================================
// Lane Detection Types
// ============================================================================

#[derive(Debug, Clone)]
pub struct DetectedLane {
    pub points: Vec<(f32, f32)>,
    pub confidence: f32,
}

// ============================================================================
// Analysis Types
// ============================================================================

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub enum LaneChangeState {
    Centered,
    Drifting,
    Crossing,
    Completed,
}

impl LaneChangeState {
    pub fn as_str(&self) -> &'static str {
        match self {
            LaneChangeState::Centered => "CENTERED",
            LaneChangeState::Drifting => "DRIFTING",
            LaneChangeState::Crossing => "CROSSING",
            LaneChangeState::Completed => "COMPLETED",
        }
    }
}

impl std::fmt::Display for LaneChangeState {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", self.as_str())
    }
}

#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub struct Point {
    pub x: f32,
    pub y: f32,
}

impl Point {
    pub fn new(x: f32, y: f32) -> Self {
        Self { x, y }
    }

    pub fn distance_to(&self, other: &Point) -> f32 {
        ((self.x - other.x).powi(2) + (self.y - other.y).powi(2)).sqrt()
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum LanePosition {
    LeftFar,
    LeftNear,
    RightNear,
    RightFar,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Lane {
    pub lane_id: usize,
    pub points: Vec<Point>,
    pub confidence: f32,
    pub position: Option<LanePosition>,
}

impl Lane {
    pub fn from_detected(lane_id: usize, detected: &DetectedLane) -> Self {
        Self {
            lane_id,
            points: detected
                .points
                .iter()
                .map(|p| Point::new(p.0, p.1))
                .collect(),
            confidence: detected.confidence,
            position: None,
        }
    }

    pub fn get_x_at_y(&self, target_y: f32) -> Option<f32> {
        if self.points.len() < 2 {
            return None;
        }

        let mut sorted_points = self.points.clone();
        sorted_points.sort_by(|a, b| a.y.partial_cmp(&b.y).unwrap_or(std::cmp::Ordering::Equal));

        for i in 0..sorted_points.len() - 1 {
            let p1 = &sorted_points[i];
            let p2 = &sorted_points[i + 1];

            if p1.y <= target_y && target_y <= p2.y {
                if (p2.y - p1.y).abs() < 1e-6 {
                    return Some(p1.x);
                }
                let ratio = (target_y - p1.y) / (p2.y - p1.y);
                return Some(p1.x + ratio * (p2.x - p1.x));
            }
        }
        None
    }

    pub fn avg_x(&self) -> f32 {
        if self.points.is_empty() {
            return 0.0;
        }
        self.points.iter().map(|p| p.x).sum::<f32>() / self.points.len() as f32
    }

    pub fn bottom_point(&self) -> Option<&Point> {
        self.points
            .iter()
            .max_by(|a, b| a.y.partial_cmp(&b.y).unwrap_or(std::cmp::Ordering::Equal))
    }
}

// ============================================================================
// Vehicle State
// ============================================================================

#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub struct VehicleState {
    pub lateral_offset: f32,
    pub lane_width: Option<f32>,
    pub heading_offset: f32,
    pub frame_id: u64,
    pub timestamp_ms: f64,
    pub raw_offset: f32,
    pub detection_confidence: f32,
    pub both_lanes_detected: bool,
}

impl VehicleState {
    pub fn invalid() -> Self {
        Self {
            lateral_offset: 0.0,
            lane_width: None,
            heading_offset: 0.0,
            frame_id: 0,
            timestamp_ms: 0.0,
            raw_offset: 0.0,
            detection_confidence: 0.0,
            both_lanes_detected: false,
        }
    }

    pub fn normalized_offset(&self) -> Option<f32> {
        match self.lane_width {
            Some(width) if width > 1.0 => Some(self.lateral_offset / width),
            _ => None,
        }
    }

    pub fn is_valid(&self) -> bool {
        self.lane_width.map_or(false, |w| w > 50.0)
    }
}

// ============================================================================
// Direction
// ============================================================================

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum Direction {
    Left = -1,
    Unknown = 0,
    Right = 1,
}

impl Direction {
    pub fn from_offset(offset: f32) -> Self {
        if offset > 0.0 {
            Direction::Right
        } else if offset < 0.0 {
            Direction::Left
        } else {
            Direction::Unknown
        }
    }

    pub fn as_str(&self) -> &'static str {
        match self {
            Direction::Left => "LEFT",
            Direction::Right => "RIGHT",
            Direction::Unknown => "UNKNOWN",
        }
    }

    pub fn as_i32(&self) -> i32 {
        match self {
            Direction::Left => -1,
            Direction::Right => 1,
            Direction::Unknown => 0,
        }
    }
}

impl std::fmt::Display for Direction {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", self.as_str())
    }
}

// ============================================================================
// Evidence Paths
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EvidencePaths {
    pub start_image_path: String,
    pub end_image_path: String,
}

// ============================================================================
// Lane Change Event
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LaneChangeEvent {
    pub event_id: String,
    pub timestamp: String,
    pub video_timestamp_ms: f64,
    pub start_frame_id: u64,
    pub end_frame_id: u64,
    pub direction: Direction,
    pub confidence: f32,
    pub duration_ms: Option<f64>,
    pub source_id: String,
    pub evidence_images: Option<EvidencePaths>,
    pub metadata: HashMap<String, serde_json::Value>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub legality: Option<LegalityInfo>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LegalityInfo {
    pub is_legal: bool,
    pub lane_line_type: String,
    pub confidence: f32,
    pub analysis_details: Option<String>,
}

impl LaneChangeEvent {
    pub fn new(
        video_timestamp_ms: f64,
        start_frame_id: u64,
        end_frame_id: u64,
        direction: Direction,
        confidence: f32,
    ) -> Self {
        Self {
            event_id: uuid::Uuid::new_v4().to_string(),
            timestamp: chrono::Utc::now().to_rfc3339(),
            video_timestamp_ms,
            start_frame_id,
            end_frame_id,
            direction,
            confidence,
            duration_ms: None,
            source_id: String::new(),
            evidence_images: None,
            metadata: HashMap::new(),
            legality: None,
        }
    }

    pub fn direction_name(&self) -> &'static str {
        self.direction.as_str()
    }

    pub fn to_json(&self) -> serde_json::Value {
        serde_json::json!({
            "event_id": self.event_id,
            "type": "lane_change",
            "direction": self.direction_name(),
            "timestamp_ms": self.video_timestamp_ms,
            "frames": {
                "start": self.start_frame_id,
                "end": self.end_frame_id
            },
            "evidence": self.evidence_images,
            "duration_ms": self.duration_ms,
            "source_id": self.source_id,
            "metadata": self.metadata,
            "legality": self.legality,
        })
    }
}

// ============================================================================
// Lane Change Config
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LaneChangeConfig {
    pub drift_threshold: f32,
    pub crossing_threshold: f32,
    pub min_frames_confirm: u32,
    pub cooldown_frames: u32,
    pub smoothing_alpha: f32,
    pub reference_y_ratio: f32,
    pub hysteresis_factor: f32,
    pub min_duration_ms: f64,
    pub max_duration_ms: f64,
    pub skip_initial_frames: u64,
    pub require_both_lanes: bool,
}

impl Default for LaneChangeConfig {
    fn default() -> Self {
        Self {
            drift_threshold: 0.30,
            crossing_threshold: 0.55,
            min_frames_confirm: 12,
            cooldown_frames: 90,
            smoothing_alpha: 0.3,
            reference_y_ratio: 0.8,
            hysteresis_factor: 0.5,
            min_duration_ms: 1500.0,
            max_duration_ms: 5000.0,
            skip_initial_frames: 150,
            require_both_lanes: true,
        }
    }
}

impl LaneChangeConfig {
    pub fn from_detection_config(detection: &DetectionConfig) -> Self {
        Self {
            drift_threshold: detection.drift_threshold,
            crossing_threshold: detection.crossing_threshold,
            min_frames_confirm: detection.confirm_frames,
            cooldown_frames: detection.cooldown_frames,
            smoothing_alpha: 0.3,
            reference_y_ratio: 0.8,
            hysteresis_factor: 0.5,
            min_duration_ms: detection.min_lane_change_duration_ms,
            max_duration_ms: detection.max_lane_change_duration_ms,
            skip_initial_frames: detection.skip_initial_frames,
            require_both_lanes: detection.require_both_lanes,
        }
    }
}
// src/video_processor.rs

use crate::types::{Config, DetectedLane, VehicleState};
use anyhow::Result;
use opencv::{
    core::{self, Mat, Vector},
    imgcodecs, imgproc,
    prelude::*,
    videoio::{self, VideoCapture, VideoCaptureTraitConst, VideoWriter},
};
use std::path::{Path, PathBuf};
use tracing::info;
use walkdir::WalkDir;

pub struct VideoProcessor {
    config: Config,
}

impl VideoProcessor {
    pub fn new(config: Config) -> Self {
        Self { config }
    }

    pub fn find_video_files(&self) -> Result<Vec<PathBuf>> {
        let mut videos = Vec::new();
        let video_extensions = vec!["mp4", "avi", "mov", "mkv", "MP4", "AVI", "MOV", "MKV"];

        for entry in WalkDir::new(&self.config.video.input_dir)
            .follow_links(true)
            .into_iter()
            .filter_map(|e| e.ok())
        {
            let path = entry.path();
            if let Some(ext) = path.extension() {
                if video_extensions.contains(&ext.to_str().unwrap_or("")) {
                    videos.push(path.to_path_buf());
                }
            }
        }
        info!("Found {} video files", videos.len());
        Ok(videos)
    }

    pub fn open_video(&self, path: &Path) -> Result<VideoReader> {
        info!("Opening video: {}", path.display());
        let cap = VideoCapture::from_file(path.to_str().unwrap(), videoio::CAP_ANY)?;

        if !cap.is_opened()? {
            anyhow::bail!("Failed to open video file");
        }

        let fps = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FPS)?;
        let total_frames = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FRAME_COUNT)? as i32;
        let width = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FRAME_WIDTH)? as i32;
        let height = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FRAME_HEIGHT)? as i32;

        Ok(VideoReader {
            cap,
            fps,
            total_frames,
            current_frame: 0,
            width,
            height,
        })
    }

    pub fn create_writer(
        &self,
        input_path: &Path,
        width: i32,
        height: i32,
        fps: f64,
    ) -> Result<Option<VideoWriter>> {
        if !self.config.video.save_annotated {
            return Ok(None);
        }
        std::fs::create_dir_all(&self.config.video.output_dir)?;
        let input_name = input_path.file_stem().unwrap().to_str().unwrap();
        let output_path = PathBuf::from(&self.config.video.output_dir)
            .join(format!("{}_annotated.mp4", input_name));

        let fourcc = VideoWriter::fourcc('m', 'p', '4', 'v')?;
        let writer = VideoWriter::new(
            output_path.to_str().unwrap(),
            fourcc,
            fps,
            core::Size::new(width, height),
            true,
        )?;
        Ok(Some(writer))
    }

    /// Save a specific frame as an image file
    pub fn save_frame_to_disk(
        &self,
        frame: &crate::types::Frame,
        filename: &str,
    ) -> Result<PathBuf> {
        let output_dir = Path::new(&self.config.video.output_dir).join("evidence");
        std::fs::create_dir_all(&output_dir)?;

        let file_path = output_dir.join(filename);

        // Frame data is RGB, OpenCV needs BGR
        let mat = Mat::from_slice(&frame.data)?;
        let mat = mat.reshape(3, frame.height as i32)?;

        let mut bgr_mat = Mat::default();
        imgproc::cvt_color(&mat, &mut bgr_mat, imgproc::COLOR_RGB2BGR, 0)?;

        // Use imgcodecs::imwrite
        let params = Vector::new();
        imgcodecs::imwrite(file_path.to_str().unwrap(), &bgr_mat, &params)?;

        Ok(file_path)
    }
}

pub struct VideoReader {
    pub cap: VideoCapture,
    pub fps: f64,
    pub total_frames: i32,
    pub current_frame: i32,
    pub width: i32,
    pub height: i32,
}

impl VideoReader {
    pub fn read_frame(&mut self) -> Result<Option<crate::types::Frame>> {
        use opencv::videoio::VideoCaptureTrait;
        let mut mat = Mat::default();
        if !VideoCaptureTrait::read(&mut self.cap, &mut mat)? || mat.empty() {
            return Ok(None);
        }
        self.current_frame += 1;
        let timestamp_ms = (self.current_frame as f64 / self.fps) * 1000.0;

        let mut rgb_mat = Mat::default();
        imgproc::cvt_color(&mat, &mut rgb_mat, imgproc::COLOR_BGR2RGB, 0)?;
        let data = rgb_mat.data_bytes()?.to_vec();

        Ok(Some(crate::types::Frame {
            data,
            width: self.width as usize,
            height: self.height as usize,
            timestamp_ms,
        }))
    }

    pub fn progress(&self) -> f32 {
        if self.total_frames == 0 {
            return 0.0;
        }
        (self.current_frame as f32 / self.total_frames as f32) * 100.0
    }
}

pub fn draw_lanes_with_state(
    frame: &[u8],
    width: i32,
    height: i32,
    lanes: &[DetectedLane],
    state: &str,
    vehicle_state: Option<&VehicleState>,
) -> Result<Mat> {
    let mat = Mat::from_slice(frame)?;
    let mat = mat.reshape(3, height)?;
    let mut bgr_mat = Mat::default();
    imgproc::cvt_color(&mat, &mut bgr_mat, imgproc::COLOR_RGB2BGR, 0)?;
    let mut output = bgr_mat.try_clone()?;

    let colors = vec![
        core::Scalar::new(0.0, 0.0, 255.0, 0.0),
        core::Scalar::new(0.0, 255.0, 0.0, 0.0),
        core::Scalar::new(255.0, 0.0, 0.0, 0.0),
        core::Scalar::new(0.0, 255.0, 255.0, 0.0),
    ];

    for (i, lane) in lanes.iter().enumerate() {
        let color = colors[i % colors.len()];
        for point in &lane.points {
            let pt = core::Point::new(point.0 as i32, point.1 as i32);
            imgproc::circle(&mut output, pt, 3, color, -1, imgproc::LINE_8, 0)?;
        }
    }

    let vehicle_x = width / 2;
    let vehicle_y = (height as f32 * 0.85) as i32;
    imgproc::circle(
        &mut output,
        core::Point::new(vehicle_x, vehicle_y),
        10,
        core::Scalar::new(0.0, 255.0, 255.0, 0.0),
        -1,
        imgproc::LINE_8,
        0,
    )?;

    imgproc::put_text(
        &mut output,
        &format!("State: {}", state),
        core::Point::new(15, 32),
        imgproc::FONT_HERSHEY_SIMPLEX,
        0.8,
        core::Scalar::new(0.0, 255.0, 0.0, 0.0),
        2,
        imgproc::LINE_8,
        false,
    )?;

    if let Some(vs) = vehicle_state {
        if vs.is_valid() {
            let normalized = vs.normalized_offset().unwrap_or(0.0);
            let info = format!(
                "Offset: {:.1}px ({:+.1}%)",
                vs.lateral_offset,
                normalized * 100.0
            );
            imgproc::put_text(
                &mut output,
                &info,
                core::Point::new(200, 32),
                imgproc::FONT_HERSHEY_SIMPLEX,
                0.5,
                core::Scalar::new(255.0, 255.0, 255.0, 0.0),
                1,
                imgproc::LINE_8,
                false,
            )?;
        }
    }

    Ok(output)
}
// src/analysis/state_machine.rs
//
// LANE CHANGE DETECTION v2.3
//
// Features:
// - Kalman filter for position smoothing
// - EWMA adaptive baseline (STICKY - slow adaptation)
// - Early baseline freeze when potential lane change detected
// - 8 detection paths including VELOCITY SPIKE for zigzags
// - Tracks max offset during pending phase
//

use super::boundary_detector::CrossingType;
use super::curve_detector::CurveDetector;
use super::velocity_tracker::LateralVelocityTracker;
use crate::types::{Direction, LaneChangeConfig, LaneChangeEvent, LaneChangeState, VehicleState};
use std::collections::VecDeque;
use tracing::{debug, info, warn};

// ============================================================================
// CONSTANTS
// ============================================================================

const MIN_VELOCITY_FAST: f32 = 120.0;
const MIN_VELOCITY_MEDIUM: f32 = 60.0;
const MIN_VELOCITY_SLOW: f32 = 20.0;
const TLC_WARNING_THRESHOLD: f64 = 1.5;
const ANALYSIS_WINDOW_MS: f64 = 4000.0;

const DEVIATION_DRIFT_START: f32 = 0.20;
const DEVIATION_CROSSING: f32 = 0.30;
const DEVIATION_LANE_CENTER: f32 = 0.50;
const DEVIATION_SIGNIFICANT: f32 = 0.40;

const HYSTERESIS_EXIT: f32 = 0.6;
const DIRECTION_CONSISTENCY_THRESHOLD: f32 = 0.65;
const POST_CHANGE_GRACE_FRAMES: u32 = 90;

// Kalman filter
const KALMAN_PROCESS_NOISE: f32 = 0.001;
const KALMAN_MEASUREMENT_NOISE: f32 = 0.01;

// ðŸ†• STICKY EWMA baseline - much slower adaptation!
const EWMA_ALPHA_STABLE: f32 = 0.003; // Was 0.02 â†’ 6x slower
const EWMA_ALPHA_ADAPTING: f32 = 0.015; // Was 0.08 â†’ 5x slower
const EWMA_MIN_SAMPLES: u32 = 30;
const STABILITY_VARIANCE_THRESHOLD: f32 = 0.005;
const INSTABILITY_VARIANCE_THRESHOLD: f32 = 0.05;

const CURVE_COMPENSATION_FACTOR: f32 = 1.15;
const MAX_DRIFTING_MS: f64 = 8000.0;

// ðŸ†• Velocity spike detection thresholds
const VELOCITY_SPIKE_THRESHOLD: f32 = 180.0; // Very high velocity
const POSITION_CHANGE_THRESHOLD: f32 = 0.15; // 15% position swing

// ============================================================================
// KALMAN FILTER
// ============================================================================

#[derive(Clone)]
struct SimpleKalmanFilter {
    x: f32,
    p: f32,
    q: f32,
    r: f32,
    initialized: bool,
}

impl SimpleKalmanFilter {
    fn new() -> Self {
        Self {
            x: 0.0,
            p: 1.0,
            q: KALMAN_PROCESS_NOISE,
            r: KALMAN_MEASUREMENT_NOISE,
            initialized: false,
        }
    }

    fn update(&mut self, measurement: f32) -> f32 {
        if !self.initialized {
            self.x = measurement;
            self.p = self.r;
            self.initialized = true;
            return measurement;
        }
        let p_pred = self.p + self.q;
        let k = p_pred / (p_pred + self.r);
        self.x = self.x + k * (measurement - self.x);
        self.p = (1.0 - k) * p_pred;
        self.x
    }

    fn reset(&mut self) {
        self.x = 0.0;
        self.p = 1.0;
        self.initialized = false;
    }
}

// ============================================================================
// ADAPTIVE BASELINE (STICKY)
// ============================================================================

#[derive(Clone)]
struct AdaptiveBaseline {
    value: f32,
    variance: f32,
    sample_count: u32,
    is_valid: bool,
    recent_samples: VecDeque<f32>,
    is_adapting: bool,
    stable_frames: u32,
    is_frozen: bool,
    frozen_value: f32,
}

impl AdaptiveBaseline {
    fn new() -> Self {
        Self {
            value: 0.0,
            variance: 1.0,
            sample_count: 0,
            is_valid: false,
            recent_samples: VecDeque::with_capacity(30),
            is_adapting: true,
            stable_frames: 0,
            is_frozen: false,
            frozen_value: 0.0,
        }
    }

    fn freeze(&mut self) {
        if !self.is_frozen {
            self.is_frozen = true;
            self.frozen_value = self.value;
            info!("ðŸ§Š Baseline frozen at {:.1}%", self.frozen_value * 100.0);
        }
    }

    fn unfreeze(&mut self) {
        if self.is_frozen {
            self.is_frozen = false;
            debug!("ðŸ”¥ Baseline unfrozen");
        }
    }

    fn effective_value(&self) -> f32 {
        if self.is_frozen {
            self.frozen_value
        } else {
            self.value
        }
    }

    fn update(&mut self, measurement: f32) -> f32 {
        self.sample_count += 1;

        self.recent_samples.push_back(measurement);
        if self.recent_samples.len() > 30 {
            self.recent_samples.pop_front();
        }

        if self.recent_samples.len() >= 10 {
            let samples: Vec<f32> = self.recent_samples.iter().copied().collect();
            let mean: f32 = samples.iter().sum::<f32>() / samples.len() as f32;
            self.variance =
                samples.iter().map(|x| (x - mean).powi(2)).sum::<f32>() / samples.len() as f32;
        }

        if self.is_frozen {
            return self.frozen_value;
        }

        let deviation_from_baseline = (measurement - self.value).abs();

        if self.variance < STABILITY_VARIANCE_THRESHOLD {
            self.stable_frames += 1;
            if self.stable_frames > 30 {
                self.is_adapting = false;
            }
        } else {
            self.stable_frames = 0;
            if deviation_from_baseline > 0.15 {
                self.is_adapting = true;
            }
        }

        let alpha = if self.is_adapting || !self.is_valid {
            EWMA_ALPHA_ADAPTING
        } else {
            EWMA_ALPHA_STABLE
        };

        if self.sample_count == 1 {
            self.value = measurement;
        } else {
            self.value = alpha * measurement + (1.0 - alpha) * self.value;
        }

        if self.sample_count >= EWMA_MIN_SAMPLES && self.variance < INSTABILITY_VARIANCE_THRESHOLD {
            self.is_valid = true;
        }

        self.value
    }

    fn reset(&mut self) {
        self.value = 0.0;
        self.variance = 1.0;
        self.sample_count = 0;
        self.is_valid = false;
        self.recent_samples.clear();
        self.is_adapting = true;
        self.stable_frames = 0;
        self.is_frozen = false;
        self.frozen_value = 0.0;
    }
}

// ============================================================================
// DATA STRUCTURES
// ============================================================================

#[derive(Clone, Copy, Debug)]
struct OffsetSample {
    normalized_offset: f32,
    deviation: f32,
    timestamp_ms: f64,
    lateral_velocity: f32,
    direction: Direction,
}

#[derive(Debug, Default)]
struct WindowMetrics {
    total_displacement: f32,
    max_deviation: f32,
    avg_velocity: f32,
    peak_velocity: f32,
    direction_consistency: f32,
    time_span_ms: f64,
    tlc_estimate: Option<f64>,
    is_intentional_change: bool,
    is_sustained_movement: bool,
}

#[derive(Debug, Clone, Copy, PartialEq)]
enum DetectionPath {
    BoundaryCrossing,
    HighVelocity,
    MediumDeviation,
    GradualChange,
    LargeDeviation,
    TLCBased,
    CumulativeDisplacement,
    VelocitySpike, // ðŸ†• NEW: For zigzags with high velocity but low baseline deviation
}

// ============================================================================
// MAIN STATE MACHINE
// ============================================================================

pub struct LaneChangeStateMachine {
    config: LaneChangeConfig,
    source_id: String,

    state: LaneChangeState,
    frames_in_state: u32,
    pending_state: Option<LaneChangeState>,
    pending_frames: u32,

    change_direction: Direction,
    change_start_frame: Option<u64>,
    change_start_time: Option<f64>,
    change_detection_path: Option<DetectionPath>,
    max_offset_in_change: f32,

    cooldown_remaining: u32,
    total_frames_processed: u64,
    post_lane_change_grace: u32,

    position_filter: SimpleKalmanFilter,
    adaptive_baseline: AdaptiveBaseline,

    offset_history: Vec<f32>,
    velocity_history: VecDeque<f32>,
    offset_samples: VecDeque<OffsetSample>,
    direction_samples: VecDeque<Direction>,
    recent_deviations: Vec<f32>,

    stable_deviation_frames: u32,
    last_deviation: f32,

    peak_deviation_in_window: f32,
    peak_velocity_in_window: f32,
    peak_direction: Direction,

    curve_detector: CurveDetector,
    velocity_tracker: LateralVelocityTracker,

    is_in_curve: bool,
    curve_compensation_factor: f32,

    pending_change_direction: Direction,
    pending_max_offset: f32,
}

impl LaneChangeStateMachine {
    pub fn new(config: LaneChangeConfig) -> Self {
        Self {
            config,
            source_id: String::new(),
            state: LaneChangeState::Centered,
            frames_in_state: 0,
            pending_state: None,
            pending_frames: 0,
            change_direction: Direction::Unknown,
            change_start_frame: None,
            change_start_time: None,
            change_detection_path: None,
            max_offset_in_change: 0.0,
            cooldown_remaining: 0,
            total_frames_processed: 0,
            post_lane_change_grace: 0,
            position_filter: SimpleKalmanFilter::new(),
            adaptive_baseline: AdaptiveBaseline::new(),
            offset_history: Vec::with_capacity(60),
            velocity_history: VecDeque::with_capacity(30),
            offset_samples: VecDeque::with_capacity(150),
            direction_samples: VecDeque::with_capacity(30),
            recent_deviations: Vec::with_capacity(30),
            stable_deviation_frames: 0,
            last_deviation: 0.0,
            peak_deviation_in_window: 0.0,
            peak_velocity_in_window: 0.0,
            peak_direction: Direction::Unknown,
            curve_detector: CurveDetector::new(),
            velocity_tracker: LateralVelocityTracker::new(),
            is_in_curve: false,
            curve_compensation_factor: 1.0,
            pending_change_direction: Direction::Unknown,
            pending_max_offset: 0.0,
        }
    }

    pub fn current_state(&self) -> &str {
        self.state.as_str()
    }

    pub fn update_curve_detector(&mut self, lanes: &[crate::types::Lane]) -> bool {
        self.is_in_curve = self.curve_detector.is_in_curve(lanes);
        self.curve_compensation_factor = if self.is_in_curve {
            CURVE_COMPENSATION_FACTOR
        } else {
            1.0
        };
        self.is_in_curve
    }

    pub fn update(
        &mut self,
        vehicle_state: &VehicleState,
        frame_id: u64,
        timestamp_ms: f64,
        crossing_type: CrossingType,
    ) -> Option<LaneChangeEvent> {
        self.total_frames_processed += 1;

        if self.total_frames_processed < self.config.skip_initial_frames {
            return None;
        }

        if self.cooldown_remaining > 0 {
            self.cooldown_remaining -= 1;
            if self.cooldown_remaining == 0 {
                self.state = LaneChangeState::Centered;
                self.frames_in_state = 0;
            }
            return None;
        }

        if self.post_lane_change_grace > 0 {
            self.post_lane_change_grace -= 1;
        }

        // Timeout handling
        if self.state == LaneChangeState::Drifting {
            if let Some(start_time) = self.change_start_time {
                let elapsed = timestamp_ms - start_time;

                if elapsed > MAX_DRIFTING_MS {
                    if self.max_offset_in_change >= self.config.crossing_threshold {
                        info!(
                            "â° Long DRIFTING ({:.0}ms) with good offset ({:.1}%) - auto-completing",
                            elapsed,
                            self.max_offset_in_change * 100.0
                        );
                        return self.force_complete(frame_id, timestamp_ms);
                    }
                }

                if elapsed > self.config.max_duration_ms {
                    if self.max_offset_in_change >= self.config.crossing_threshold {
                        info!("â° Timeout but good offset - completing");
                        return self.force_complete(frame_id, timestamp_ms);
                    }
                    warn!(
                        "â° Timeout after {:.0}ms with max={:.1}%",
                        elapsed,
                        self.max_offset_in_change * 100.0
                    );
                    self.adaptive_baseline.unfreeze();
                    self.reset_lane_change();
                    self.cooldown_remaining = 30;
                    return None;
                }
            }
        }

        if self.state == LaneChangeState::Crossing {
            if let Some(start_time) = self.change_start_time {
                let elapsed = timestamp_ms - start_time;
                if elapsed > self.config.max_duration_ms {
                    info!("â° Timeout in CROSSING - completing anyway");
                    return self.force_complete(frame_id, timestamp_ms);
                }
            }
        }

        if !vehicle_state.is_valid() {
            return None;
        }

        let lane_width = vehicle_state.lane_width.unwrap();
        let raw_offset = vehicle_state.lateral_offset / lane_width;
        let normalized_offset = self.position_filter.update(raw_offset);

        let lateral_velocity = self
            .velocity_tracker
            .get_velocity(vehicle_state.lateral_offset, timestamp_ms);

        self.velocity_history.push_back(lateral_velocity);
        if self.velocity_history.len() > 30 {
            self.velocity_history.pop_front();
        }

        self.offset_history.push(normalized_offset);
        if self.offset_history.len() > 60 {
            self.offset_history.remove(0);
        }

        if self.post_lane_change_grace > 0 {
            self.adaptive_baseline.update(normalized_offset);
            return None;
        }

        self.adaptive_baseline.update(normalized_offset);

        if !self.adaptive_baseline.is_valid {
            if self.adaptive_baseline.sample_count % 30 == 0 {
                debug!(
                    "Baseline forming: {:.1}%",
                    self.adaptive_baseline.value * 100.0
                );
            }
            return None;
        }

        if self.adaptive_baseline.sample_count == EWMA_MIN_SAMPLES {
            info!(
                "âœ… Adaptive baseline ready: {:.1}% at frame {} ({:.1}s)",
                self.adaptive_baseline.value * 100.0,
                frame_id,
                timestamp_ms / 1000.0
            );
        }

        let baseline = self.adaptive_baseline.effective_value();
        let signed_deviation = normalized_offset - baseline;
        let deviation = signed_deviation.abs();
        let current_direction = Direction::from_offset(signed_deviation);

        // Track max offset during pending and active phases
        if self.pending_state == Some(LaneChangeState::Drifting)
            || self.state == LaneChangeState::Drifting
            || self.state == LaneChangeState::Crossing
        {
            if deviation > self.max_offset_in_change {
                self.max_offset_in_change = deviation;
            }
            if deviation > self.pending_max_offset {
                self.pending_max_offset = deviation;
            }
        }

        self.recent_deviations.push(deviation);
        if self.recent_deviations.len() > 30 {
            self.recent_deviations.remove(0);
        }

        let sample = OffsetSample {
            normalized_offset,
            deviation,
            timestamp_ms,
            lateral_velocity,
            direction: current_direction,
        };
        self.offset_samples.push_back(sample);

        while let Some(oldest) = self.offset_samples.front() {
            if timestamp_ms - oldest.timestamp_ms > ANALYSIS_WINDOW_MS {
                self.offset_samples.pop_front();
            } else {
                break;
            }
        }

        self.direction_samples.push_back(current_direction);
        if self.direction_samples.len() > 30 {
            self.direction_samples.pop_front();
        }

        if deviation > self.peak_deviation_in_window {
            self.peak_deviation_in_window = deviation;
            self.peak_direction = current_direction;
        }
        if lateral_velocity.abs() > self.peak_velocity_in_window {
            self.peak_velocity_in_window = lateral_velocity.abs();
        }

        let window_metrics = self.calculate_window_metrics(timestamp_ms, lane_width);

        let target_state = self.determine_target_state(
            deviation,
            crossing_type,
            lateral_velocity,
            current_direction,
            &window_metrics,
        );

        // ðŸ†• Debug logging for zigzag investigation (around 202s = frame ~6060)
        if frame_id >= 6000 && frame_id <= 6150 {
            info!(
                "ðŸ” F{}: pos={:.1}%, base={:.1}%, dev={:.1}%, vel={:.1}px/s, swing={:.1}%",
                frame_id,
                normalized_offset * 100.0,
                baseline * 100.0,
                deviation * 100.0,
                lateral_velocity,
                self.get_recent_position_change() * 100.0
            );
        }

        debug!(
            "F{}: off={:.1}%, base={:.1}%{}, dev={:.1}%, max={:.1}%, state={:?}â†’{:?}",
            frame_id,
            normalized_offset * 100.0,
            baseline * 100.0,
            if self.adaptive_baseline.is_frozen {
                "ðŸ§Š"
            } else {
                ""
            },
            deviation * 100.0,
            self.max_offset_in_change * 100.0,
            self.state,
            target_state
        );

        self.check_transition(
            target_state,
            current_direction,
            frame_id,
            timestamp_ms,
            deviation,
        )
    }

    fn force_complete(&mut self, frame_id: u64, timestamp_ms: f64) -> Option<LaneChangeEvent> {
        let start_frame = self.change_start_frame.unwrap_or(frame_id);
        let start_time = self.change_start_time.unwrap_or(timestamp_ms);
        let duration_ms = Some(timestamp_ms - start_time);
        let confidence = self.calculate_confidence(duration_ms);

        let mut event = LaneChangeEvent::new(
            start_time,
            start_frame,
            frame_id,
            self.change_direction,
            confidence,
        );
        event.duration_ms = duration_ms;
        event.source_id = self.source_id.clone();

        info!(
            "âœ… FORCE CONFIRMED: {} at {:.2}s, dur={:.0}ms, max={:.1}%, path={:?}",
            event.direction_name(),
            start_time / 1000.0,
            duration_ms.unwrap_or(0.0),
            self.max_offset_in_change * 100.0,
            self.change_detection_path
        );

        self.adaptive_baseline.reset();
        self.position_filter.reset();
        self.post_lane_change_grace = POST_CHANGE_GRACE_FRAMES;
        self.offset_samples.clear();
        self.cooldown_remaining = self.config.cooldown_frames;

        info!("ðŸ”„ Baseline reset - will adapt to new position");
        self.reset_lane_change();

        Some(event)
    }

    /// ðŸ†• Get the total position change over recent frames (ignoring baseline)
    /// Used for detecting zigzags where baseline has adapted
    fn get_recent_position_change(&self) -> f32 {
        if self.offset_history.len() < 10 {
            return 0.0;
        }

        let recent = &self.offset_history[self.offset_history.len() - 10..];
        let first = recent[0];
        let last = recent[recent.len() - 1];

        // Also check max swing (for zigzags that return to center)
        let max = recent.iter().fold(f32::MIN, |a, &b| a.max(b));
        let min = recent.iter().fold(f32::MAX, |a, &b| a.min(b));
        let swing = max - min;

        // Return the larger of: end-to-end change or total swing
        (last - first).abs().max(swing)
    }

    fn calculate_window_metrics(&self, _current_time_ms: f64, lane_width: f32) -> WindowMetrics {
        let mut metrics = WindowMetrics::default();

        if self.offset_samples.len() < 10 {
            return metrics;
        }

        let first = self.offset_samples.front().unwrap();
        let last = self.offset_samples.back().unwrap();

        metrics.time_span_ms = last.timestamp_ms - first.timestamp_ms;
        if metrics.time_span_ms < 300.0 {
            return metrics;
        }

        metrics.total_displacement = (last.deviation - first.deviation).abs();
        metrics.max_deviation = self
            .offset_samples
            .iter()
            .map(|s| s.deviation)
            .fold(0.0f32, |a, b| a.max(b));

        let velocities: Vec<f32> = self
            .offset_samples
            .iter()
            .map(|s| s.lateral_velocity)
            .collect();
        metrics.avg_velocity = velocities.iter().sum::<f32>() / velocities.len() as f32;
        metrics.peak_velocity = velocities
            .iter()
            .map(|v| v.abs())
            .fold(0.0f32, |a, b| a.max(b));

        if !self.direction_samples.is_empty() {
            let target_dir = self.peak_direction;
            let consistent = self
                .direction_samples
                .iter()
                .filter(|&&d| d == target_dir)
                .count();
            metrics.direction_consistency = consistent as f32 / self.direction_samples.len() as f32;
        }

        if metrics.avg_velocity.abs() > 5.0 {
            let distance_to_boundary = (0.5 - last.deviation.abs()) * lane_width;
            if distance_to_boundary > 0.0 {
                metrics.tlc_estimate =
                    Some((distance_to_boundary / metrics.avg_velocity.abs()) as f64);
            }
        }

        metrics.is_sustained_movement = metrics.direction_consistency
            >= DIRECTION_CONSISTENCY_THRESHOLD
            && metrics.time_span_ms >= 1000.0;
        metrics.is_intentional_change = metrics.max_deviation >= DEVIATION_DRIFT_START
            && metrics.is_sustained_movement
            && (metrics.avg_velocity.abs() > MIN_VELOCITY_SLOW || metrics.time_span_ms >= 2000.0);

        metrics
    }

    fn determine_target_state(
        &mut self,
        deviation: f32,
        crossing_type: CrossingType,
        lateral_velocity: f32,
        current_direction: Direction,
        metrics: &WindowMetrics,
    ) -> LaneChangeState {
        let drift_threshold = self.config.drift_threshold * self.curve_compensation_factor;
        let crossing_threshold = self.config.crossing_threshold * self.curve_compensation_factor;

        let vel_fast = MIN_VELOCITY_FAST * self.curve_compensation_factor;
        let vel_medium = MIN_VELOCITY_MEDIUM * self.curve_compensation_factor;

        match self.state {
            LaneChangeState::Centered => {
                // PATH 1: BOUNDARY CROSSING
                if crossing_type != CrossingType::None && lateral_velocity.abs() > vel_fast {
                    if self.is_deviation_sustained(drift_threshold * 0.9) {
                        self.change_detection_path = Some(DetectionPath::BoundaryCrossing);
                        info!(
                            "ðŸš¨ [BOUNDARY] {:?}, vel={:.1}px/s",
                            crossing_type, lateral_velocity
                        );
                        return LaneChangeState::Drifting;
                    }
                }

                // PATH 2: HIGH VELOCITY + DEVIATION
                if lateral_velocity.abs() > vel_fast && deviation >= drift_threshold {
                    if self.is_velocity_sustained(vel_medium) {
                        self.change_detection_path = Some(DetectionPath::HighVelocity);
                        info!(
                            "ðŸš¨ [HIGH-VEL] vel={:.1}px/s, dev={:.1}%",
                            lateral_velocity,
                            deviation * 100.0
                        );
                        return LaneChangeState::Drifting;
                    }
                }

                // ðŸ†• PATH 8: VELOCITY SPIKE (for zigzags where baseline has adapted)
                // High velocity movement should trigger even if baseline deviation is low
                if lateral_velocity.abs() > VELOCITY_SPIKE_THRESHOLD {
                    if self.is_velocity_sustained(vel_fast) {
                        let position_change = self.get_recent_position_change();
                        if position_change >= POSITION_CHANGE_THRESHOLD {
                            self.change_detection_path = Some(DetectionPath::VelocitySpike);
                            info!(
                                "ðŸš¨ [VELOCITY-SPIKE] vel={:.1}px/s, pos_change={:.1}%, dev={:.1}%",
                                lateral_velocity,
                                position_change * 100.0,
                                deviation * 100.0
                            );
                            return LaneChangeState::Drifting;
                        }
                    }
                }

                // PATH 3: TLC-BASED
                if let Some(tlc) = metrics.tlc_estimate {
                    if tlc < TLC_WARNING_THRESHOLD
                        && deviation >= drift_threshold
                        && metrics.is_sustained_movement
                    {
                        self.change_detection_path = Some(DetectionPath::TLCBased);
                        info!("ðŸš¨ [TLC] TLC={:.2}s, dev={:.1}%", tlc, deviation * 100.0);
                        return LaneChangeState::Drifting;
                    }
                }

                // PATH 4: MEDIUM SPEED + HIGH DEVIATION
                if deviation >= drift_threshold + 0.10 && lateral_velocity.abs() > vel_medium {
                    if self.is_deviation_sustained(drift_threshold) {
                        self.change_detection_path = Some(DetectionPath::MediumDeviation);
                        info!(
                            "ðŸš¨ [MEDIUM] dev={:.1}%, vel={:.1}px/s",
                            deviation * 100.0,
                            lateral_velocity
                        );
                        return LaneChangeState::Drifting;
                    }
                }

                // PATH 5: GRADUAL CHANGE
                if metrics.is_intentional_change && metrics.max_deviation >= DEVIATION_SIGNIFICANT {
                    if self.is_deviation_sustained_long(DEVIATION_DRIFT_START) {
                        self.change_detection_path = Some(DetectionPath::GradualChange);
                        info!(
                            "ðŸš¨ [GRADUAL] max={:.1}%, span={:.1}s",
                            metrics.max_deviation * 100.0,
                            metrics.time_span_ms / 1000.0
                        );
                        return LaneChangeState::Drifting;
                    }
                }

                // PATH 6: LARGE DEVIATION
                if deviation >= DEVIATION_LANE_CENTER {
                    if self.is_deviation_sustained(drift_threshold) {
                        self.change_detection_path = Some(DetectionPath::LargeDeviation);
                        info!("ðŸš¨ [LARGE] dev={:.1}%", deviation * 100.0);
                        return LaneChangeState::Drifting;
                    }
                }

                // PATH 7: CUMULATIVE
                if metrics.max_deviation >= DEVIATION_SIGNIFICANT
                    && metrics.direction_consistency >= DIRECTION_CONSISTENCY_THRESHOLD
                    && metrics.time_span_ms >= 2500.0
                    && !self.is_in_curve
                {
                    self.change_detection_path = Some(DetectionPath::CumulativeDisplacement);
                    info!(
                        "ðŸš¨ [CUMULATIVE] max={:.1}%, span={:.1}s",
                        metrics.max_deviation * 100.0,
                        metrics.time_span_ms / 1000.0
                    );
                    return LaneChangeState::Drifting;
                }

                LaneChangeState::Centered
            }

            LaneChangeState::Drifting => {
                // Check for crossing threshold
                if deviation >= crossing_threshold {
                    return LaneChangeState::Crossing;
                }

                // Also check max_offset
                if self.max_offset_in_change >= crossing_threshold {
                    return LaneChangeState::Crossing;
                }

                // Check if we should complete based on sustained high deviation
                if self.frames_in_state > 30 && self.max_offset_in_change >= drift_threshold + 0.08
                {
                    if self.is_deviation_stable() {
                        info!(
                            "âœ… DRIFTING complete: stabilized with max={:.1}%",
                            self.max_offset_in_change * 100.0
                        );
                        return LaneChangeState::Completed;
                    }
                }

                // Cancellation check - only if max offset is very low
                let cancel_threshold = drift_threshold * 0.5;
                if deviation < cancel_threshold && self.max_offset_in_change < drift_threshold {
                    warn!(
                        "âŒ Cancelled: max={:.1}% < drift={:.1}%",
                        self.max_offset_in_change * 100.0,
                        drift_threshold * 100.0
                    );
                    return LaneChangeState::Centered;
                }

                LaneChangeState::Drifting
            }

            LaneChangeState::Crossing => {
                let deviation_change = (deviation - self.last_deviation).abs();
                if deviation_change < 0.03 {
                    self.stable_deviation_frames += 1;
                } else {
                    self.stable_deviation_frames = 0;
                }
                self.last_deviation = deviation;

                if self.is_deviation_stable() && deviation < 0.35 {
                    info!("âœ… Completing: stabilized at {:.1}%", deviation * 100.0);
                    return LaneChangeState::Completed;
                }

                let return_threshold = self.config.drift_threshold * HYSTERESIS_EXIT;
                if deviation < return_threshold {
                    info!("âœ… Completing: returned to center");
                    return LaneChangeState::Completed;
                }

                if self.stable_deviation_frames >= 30 && deviation < 0.45 {
                    info!(
                        "âœ… Completing: stable for {} frames",
                        self.stable_deviation_frames
                    );
                    return LaneChangeState::Completed;
                }

                if self.max_offset_in_change >= self.config.crossing_threshold
                    && current_direction != self.change_direction
                    && current_direction != Direction::Unknown
                {
                    let reversal_count = self
                        .direction_samples
                        .iter()
                        .rev()
                        .take(10)
                        .filter(|&&d| d != self.change_direction && d != Direction::Unknown)
                        .count();
                    if reversal_count >= 7 {
                        info!("âœ… Completing: direction reversed");
                        return LaneChangeState::Completed;
                    }
                }

                LaneChangeState::Crossing
            }

            LaneChangeState::Completed => LaneChangeState::Centered,
        }
    }

    fn is_deviation_sustained(&self, threshold: f32) -> bool {
        if self.offset_history.len() < 8 {
            return false;
        }
        let baseline = self.adaptive_baseline.effective_value();
        self.offset_history
            .iter()
            .rev()
            .take(6)
            .filter(|o| (*o - baseline).abs() >= threshold)
            .count()
            >= 5
    }

    fn is_deviation_sustained_long(&self, threshold: f32) -> bool {
        if self.offset_history.len() < 20 {
            return false;
        }
        let baseline = self.adaptive_baseline.effective_value();
        self.offset_history
            .iter()
            .rev()
            .take(15)
            .filter(|o| (*o - baseline).abs() >= threshold)
            .count()
            >= 12
    }

    fn is_velocity_sustained(&self, threshold: f32) -> bool {
        if self.velocity_history.len() < 5 {
            return false;
        }
        self.velocity_history
            .iter()
            .rev()
            .take(5)
            .filter(|v| v.abs() >= threshold)
            .count()
            >= 4
    }

    fn is_deviation_stable(&self) -> bool {
        if self.recent_deviations.len() < 15 {
            return false;
        }
        let recent = &self.recent_deviations[self.recent_deviations.len() - 15..];
        let max = recent.iter().fold(f32::MIN, |a, &b| a.max(b));
        let min = recent.iter().fold(f32::MAX, |a, &b| a.min(b));
        if max - min > 0.08 {
            return false;
        }
        recent
            .windows(2)
            .filter(|w| (w[1] - w[0]).abs() > 0.03)
            .count()
            <= 2
    }

    fn reset_lane_change(&mut self) {
        self.state = LaneChangeState::Centered;
        self.frames_in_state = 0;
        self.pending_state = None;
        self.pending_frames = 0;
        self.change_direction = Direction::Unknown;
        self.change_start_frame = None;
        self.change_start_time = None;
        self.change_detection_path = None;
        self.max_offset_in_change = 0.0;
        self.stable_deviation_frames = 0;
        self.last_deviation = 0.0;
        self.recent_deviations.clear();
        self.peak_deviation_in_window = 0.0;
        self.peak_velocity_in_window = 0.0;
        self.peak_direction = Direction::Unknown;
        self.pending_change_direction = Direction::Unknown;
        self.pending_max_offset = 0.0;
    }

    fn check_transition(
        &mut self,
        target_state: LaneChangeState,
        direction: Direction,
        frame_id: u64,
        timestamp_ms: f64,
        current_deviation: f32,
    ) -> Option<LaneChangeEvent> {
        if target_state == self.state {
            self.pending_state = None;
            self.pending_frames = 0;
            self.frames_in_state += 1;
            return None;
        }

        // Freeze baseline immediately when we first detect potential lane change
        if target_state == LaneChangeState::Drifting && self.state == LaneChangeState::Centered {
            if self.pending_state != Some(LaneChangeState::Drifting) {
                self.adaptive_baseline.freeze();
                self.pending_change_direction = direction;
                self.pending_max_offset = current_deviation;
                info!(
                    "ðŸ§Š Early freeze: baseline at {:.1}%, initial dev={:.1}%",
                    self.adaptive_baseline.effective_value() * 100.0,
                    current_deviation * 100.0
                );
            }
        }

        if self.pending_state == Some(target_state) {
            self.pending_frames += 1;
        } else {
            self.pending_state = Some(target_state);
            self.pending_frames = 1;
        }

        // Unfreeze if we're NOT going to transition after all
        if target_state != LaneChangeState::Drifting
            && self.adaptive_baseline.is_frozen
            && self.state == LaneChangeState::Centered
            && self.pending_frames < self.config.min_frames_confirm
        {
            self.adaptive_baseline.unfreeze();
            self.pending_max_offset = 0.0;
        }

        if self.pending_frames < self.config.min_frames_confirm {
            return None;
        }

        self.execute_transition(target_state, direction, frame_id, timestamp_ms)
    }

    fn execute_transition(
        &mut self,
        target_state: LaneChangeState,
        direction: Direction,
        frame_id: u64,
        timestamp_ms: f64,
    ) -> Option<LaneChangeEvent> {
        let from_state = self.state;

        info!(
            "State: {:?} â†’ {:?} at frame {} ({:.2}s)",
            from_state,
            target_state,
            frame_id,
            timestamp_ms / 1000.0
        );

        if target_state == LaneChangeState::Drifting && from_state == LaneChangeState::Centered {
            self.change_direction = if self.pending_change_direction != Direction::Unknown {
                self.pending_change_direction
            } else {
                direction
            };
            self.change_start_frame = Some(frame_id);
            self.change_start_time = Some(timestamp_ms);
            self.max_offset_in_change = self.pending_max_offset;
            self.stable_deviation_frames = 0;
            self.last_deviation = 0.0;

            if !self.adaptive_baseline.is_frozen {
                self.adaptive_baseline.freeze();
            }

            info!(
                "ðŸš— Lane change started: {} at {:.2}s via {:?} (max so far: {:.1}%)",
                self.change_direction.as_str(),
                timestamp_ms / 1000.0,
                self.change_detection_path,
                self.max_offset_in_change * 100.0
            );
        }

        if target_state == LaneChangeState::Centered && from_state == LaneChangeState::Drifting {
            info!("â†©ï¸ Cancelled");
            self.adaptive_baseline.unfreeze();
            self.reset_lane_change();
            self.cooldown_remaining = 30;
            return None;
        }

        let duration_ms = if target_state == LaneChangeState::Completed {
            self.change_start_time.map(|start| timestamp_ms - start)
        } else {
            None
        };

        self.state = target_state;
        self.frames_in_state = 0;
        self.pending_state = None;
        self.pending_frames = 0;

        if target_state == LaneChangeState::Completed {
            if let Some(dur) = duration_ms {
                if dur < self.config.min_duration_ms
                    && self.max_offset_in_change < DEVIATION_SIGNIFICANT
                {
                    warn!("âŒ Rejected: short + low dev");
                    self.adaptive_baseline.unfreeze();
                    self.reset_lane_change();
                    self.cooldown_remaining = 60;
                    return None;
                }
            }

            let min_offset_for_valid = self.config.drift_threshold + 0.05;
            if self.max_offset_in_change < min_offset_for_valid {
                warn!(
                    "âŒ Rejected: max={:.1}% < {:.1}%",
                    self.max_offset_in_change * 100.0,
                    min_offset_for_valid * 100.0
                );
                self.adaptive_baseline.unfreeze();
                self.reset_lane_change();
                self.cooldown_remaining = 60;
                return None;
            }

            self.cooldown_remaining = self.config.cooldown_frames;

            let start_frame = self.change_start_frame.unwrap_or(frame_id);
            let start_time = self.change_start_time.unwrap_or(timestamp_ms);
            let confidence = self.calculate_confidence(duration_ms);

            let mut event = LaneChangeEvent::new(
                start_time,
                start_frame,
                frame_id,
                self.change_direction,
                confidence,
            );
            event.duration_ms = duration_ms;
            event.source_id = self.source_id.clone();

            info!(
                "âœ… CONFIRMED: {} at {:.2}s, dur={:.0}ms, max={:.1}%, path={:?}",
                event.direction_name(),
                start_time / 1000.0,
                duration_ms.unwrap_or(0.0),
                self.max_offset_in_change * 100.0,
                self.change_detection_path
            );

            self.adaptive_baseline.reset();
            self.position_filter.reset();
            self.post_lane_change_grace = POST_CHANGE_GRACE_FRAMES;
            self.offset_samples.clear();

            info!("ðŸ”„ Baseline reset - will adapt to new position");
            self.reset_lane_change();

            return Some(event);
        }

        None
    }

    fn calculate_confidence(&self, duration_ms: Option<f64>) -> f32 {
        let mut confidence: f32 = 0.5;
        if self.max_offset_in_change > 0.60 {
            confidence += 0.25;
        } else if self.max_offset_in_change > 0.50 {
            confidence += 0.20;
        } else if self.max_offset_in_change > 0.40 {
            confidence += 0.15;
        } else {
            confidence += 0.05;
        }

        if let Some(dur) = duration_ms {
            if dur > 1000.0 && dur < 6000.0 {
                confidence += 0.15;
            } else if dur > 500.0 && dur < 10000.0 {
                confidence += 0.10;
            } else {
                confidence += 0.05;
            }
        }

        if let Some(path) = &self.change_detection_path {
            match path {
                DetectionPath::BoundaryCrossing | DetectionPath::TLCBased => confidence += 0.05,
                DetectionPath::HighVelocity | DetectionPath::VelocitySpike => confidence += 0.03,
                _ => {}
            }
        }
        confidence.min(0.95)
    }

    pub fn reset(&mut self) {
        self.reset_lane_change();
        self.adaptive_baseline.unfreeze();
        self.cooldown_remaining = 0;
        self.total_frames_processed = 0;
        self.post_lane_change_grace = 0;
        self.position_filter.reset();
        self.adaptive_baseline.reset();
        self.offset_history.clear();
        self.velocity_history.clear();
        self.curve_detector.reset();
        self.velocity_tracker.reset();
        self.offset_samples.clear();
        self.direction_samples.clear();
        self.is_in_curve = false;
        self.curve_compensation_factor = 1.0;
    }

    pub fn set_source_id(&mut self, source_id: String) {
        self.source_id = source_id;
    }
}
// src/analysis/curve_detector.rs

use crate::types::Lane;
use std::collections::VecDeque;
use tracing::debug;

pub struct CurveDetector {
    lane_angle_history: VecDeque<f32>,
    history_size: usize,
    curve_threshold: f32,
}

impl CurveDetector {
    pub fn new() -> Self {
        Self {
            lane_angle_history: VecDeque::with_capacity(30),
            history_size: 30,
            curve_threshold: 5.0, // degrees
        }
    }

    pub fn is_in_curve(&mut self, lanes: &[Lane]) -> bool {
        let angle = self.calculate_lane_angle(lanes);

        self.lane_angle_history.push_back(angle);
        if self.lane_angle_history.len() > self.history_size {
            self.lane_angle_history.pop_front();
        }

        if self.lane_angle_history.len() < 10 {
            return false;
        }

        // Calculate average absolute angle
        let avg_angle: f32 = self.lane_angle_history.iter().map(|a| a.abs()).sum::<f32>()
            / self.lane_angle_history.len() as f32;

        let is_curve = avg_angle > self.curve_threshold;

        if is_curve {
            debug!(
                "ðŸŒ€ Curve detected: avg angle = {:.1}Â° (threshold: {:.1}Â°)",
                avg_angle, self.curve_threshold
            );
        }

        is_curve
    }

    fn calculate_lane_angle(&self, lanes: &[Lane]) -> f32 {
        // Find the most confident lane with enough points
        let best_lane = lanes.iter().filter(|l| l.points.len() >= 5).max_by(|a, b| {
            a.confidence
                .partial_cmp(&b.confidence)
                .unwrap_or(std::cmp::Ordering::Equal)
        });

        if let Some(lane) = best_lane {
            // Calculate angle between bottom and top points
            if lane.points.len() >= 2 {
                let bottom = &lane.points[0];
                let top = &lane.points[lane.points.len() - 1];

                let dx = top.x - bottom.x;
                let dy = top.y - bottom.y;

                if dy.abs() > 10.0 {
                    // Prevent division by near-zero
                    let angle_rad = (dx / dy).atan();
                    let angle_deg = angle_rad.to_degrees();
                    return angle_deg;
                }
            }
        }

        0.0 // No curve detected
    }

    pub fn reset(&mut self) {
        self.lane_angle_history.clear();
    }
}
// src/analysis/position_estimator.rs

use crate::types::{Lane, VehicleState};
use std::collections::VecDeque;
use tracing::debug;

pub struct PositionEstimator {
    pub reference_y_ratio: f32,
    pub min_lane_width: f32,
    pub max_lane_width: f32,
    pub default_lane_width: f32,
    lane_width_history: VecDeque<f32>,
    offset_history: VecDeque<f32>,
    history_size: usize,
    last_valid_width: Option<f32>,
}

impl PositionEstimator {
    pub fn new(reference_y_ratio: f32) -> Self {
        Self {
            reference_y_ratio,
            min_lane_width: 100.0,
            max_lane_width: 900.0,
            default_lane_width: 550.0,
            lane_width_history: VecDeque::with_capacity(15),
            offset_history: VecDeque::with_capacity(15),
            history_size: 15,
            last_valid_width: None,
        }
    }

    fn get_stable_lane_width(&mut self, measured: f32) -> f32 {
        if measured >= self.min_lane_width && measured <= self.max_lane_width {
            self.lane_width_history.push_back(measured);
            if self.lane_width_history.len() > self.history_size {
                self.lane_width_history.pop_front();
            }
            self.last_valid_width = Some(measured);
        }

        if self.lane_width_history.len() < 3 {
            return self.last_valid_width.unwrap_or(self.default_lane_width);
        }

        let mut sorted: Vec<f32> = self.lane_width_history.iter().copied().collect();
        sorted.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
        sorted[sorted.len() / 2]
    }

    fn update_offset_history(&mut self, offset: f32) {
        self.offset_history.push_back(offset);
        if self.offset_history.len() > self.history_size {
            self.offset_history.pop_front();
        }
    }

    pub fn estimate(
        &mut self,
        lanes: &[Lane],
        frame_width: u32,
        frame_height: u32,
    ) -> VehicleState {
        let vehicle_x = frame_width as f32 / 2.0;
        let reference_y = frame_height as f32 * self.reference_y_ratio;

        let confident_lanes: Vec<&Lane> = lanes
            .iter()
            .filter(|l| l.confidence > 0.2 && l.points.len() >= 3)
            .collect();

        let left_lane = self.find_ego_lane(&confident_lanes, vehicle_x, true);
        let right_lane = self.find_ego_lane(&confident_lanes, vehicle_x, false);

        let left_x = left_lane.and_then(|l| l.get_x_at_y(reference_y));
        let right_x = right_lane.and_then(|l| l.get_x_at_y(reference_y));

        let both_lanes_detected = left_x.is_some() && right_x.is_some();

        let detection_confidence = match (&left_lane, &right_lane) {
            (Some(l), Some(r)) => (l.confidence + r.confidence) / 2.0,
            (Some(l), None) => l.confidence * 0.6,
            (None, Some(r)) => r.confidence * 0.6,
            (None, None) => 0.0,
        };

        let mut lane_width: Option<f32> = None;
        let mut lateral_offset = 0.0f32;
        let mut raw_offset = 0.0f32;

        match (left_x, right_x) {
            (Some(lx), Some(rx)) => {
                let measured_width = rx - lx;
                let stable_width = self.get_stable_lane_width(measured_width);
                lane_width = Some(stable_width);

                let lane_center = (lx + rx) / 2.0;
                raw_offset = vehicle_x - lane_center;
                lateral_offset = raw_offset;

                self.update_offset_history(lateral_offset);
            }
            (Some(lx), None) => {
                let stable_width = self.get_stable_lane_width(self.default_lane_width);
                let estimated_center = lx + (stable_width / 2.0);
                raw_offset = vehicle_x - estimated_center;
                lateral_offset = raw_offset;
                lane_width = Some(stable_width);
                self.update_offset_history(lateral_offset);
            }
            (None, Some(rx)) => {
                let stable_width = self.get_stable_lane_width(self.default_lane_width);
                let estimated_center = rx - (stable_width / 2.0);
                raw_offset = vehicle_x - estimated_center;
                lateral_offset = raw_offset;
                lane_width = Some(stable_width);
                self.update_offset_history(lateral_offset);
            }
            (None, None) => {
                if let Some(width) = self.last_valid_width {
                    lane_width = Some(width);
                }
                if let Some(&last_offset) = self.offset_history.back() {
                    lateral_offset = last_offset;
                }
            }
        }

        VehicleState {
            lateral_offset,
            lane_width,
            heading_offset: 0.0,
            frame_id: 0,
            timestamp_ms: 0.0,
            raw_offset,
            detection_confidence,
            both_lanes_detected,
        }
    }

    fn find_ego_lane<'a>(
        &self,
        lanes: &[&'a Lane],
        vehicle_x: f32,
        is_left: bool,
    ) -> Option<&'a Lane> {
        let mut candidates: Vec<(&Lane, f32)> = Vec::new();

        for lane in lanes {
            if lane.points.len() < 2 {
                continue;
            }

            if let Some(p) = lane.bottom_point() {
                if is_left && p.x < vehicle_x {
                    candidates.push((lane, vehicle_x - p.x));
                } else if !is_left && p.x > vehicle_x {
                    candidates.push((lane, p.x - vehicle_x));
                }
            }
        }

        candidates.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap_or(std::cmp::Ordering::Equal));
        candidates.first().map(|(lane, _)| *lane)
    }

    pub fn reset(&mut self) {
        self.lane_width_history.clear();
        self.offset_history.clear();
        self.last_valid_width = None;
    }
}

pub struct PositionSmoother {
    alpha: f32,
    smoothed_offset: Option<f32>,
    smoothed_width: Option<f32>,
}

impl PositionSmoother {
    pub fn new(alpha: f32) -> Self {
        Self {
            alpha: alpha.clamp(0.1, 0.5),
            smoothed_offset: None,
            smoothed_width: None,
        }
    }

    pub fn smooth(&mut self, state: VehicleState) -> VehicleState {
        let smoothed_offset = match self.smoothed_offset {
            None => {
                self.smoothed_offset = Some(state.lateral_offset);
                state.lateral_offset
            }
            Some(prev) => {
                let new_val = self.alpha * state.lateral_offset + (1.0 - self.alpha) * prev;
                self.smoothed_offset = Some(new_val);
                new_val
            }
        };

        let smoothed_width = if let Some(width) = state.lane_width {
            match self.smoothed_width {
                None => {
                    self.smoothed_width = Some(width);
                    Some(width)
                }
                Some(prev) => {
                    let new_val = 0.1 * width + 0.9 * prev;
                    self.smoothed_width = Some(new_val);
                    Some(new_val)
                }
            }
        } else {
            self.smoothed_width
        };

        VehicleState {
            lateral_offset: smoothed_offset,
            lane_width: smoothed_width,
            heading_offset: state.heading_offset,
            frame_id: state.frame_id,
            timestamp_ms: state.timestamp_ms,
            raw_offset: state.raw_offset,
            detection_confidence: state.detection_confidence,
            both_lanes_detected: state.both_lanes_detected,
        }
    }

    pub fn reset(&mut self) {
        self.smoothed_offset = None;
        self.smoothed_width = None;
    }
}
// src/analysis/mod.rs

mod boundary_detector;
mod curve_detector;
mod lane_analyzer;
mod position_estimator;
mod state_machine;
mod velocity_tracker;

pub use lane_analyzer::LaneChangeAnalyzer;
// src/analysis/boundary_detector.rs

use std::collections::VecDeque;
use tracing::debug;

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum CrossingType {
    None,
    CrossedLeft,
    CrossedRight,
}

pub struct LaneBoundaryCrossingDetector {
    left_lane_x_history: VecDeque<f32>,
    right_lane_x_history: VecDeque<f32>,
    vehicle_x_history: VecDeque<f32>,
    history_size: usize,
    crossing_margin: f32,
}

impl LaneBoundaryCrossingDetector {
    pub fn new() -> Self {
        Self {
            left_lane_x_history: VecDeque::with_capacity(15),
            right_lane_x_history: VecDeque::with_capacity(15),
            vehicle_x_history: VecDeque::with_capacity(15),
            history_size: 15,
            crossing_margin: 20.0, // pixels - margin for noise tolerance
        }
    }

    pub fn detect_crossing(
        &mut self,
        left_x: Option<f32>,
        right_x: Option<f32>,
        vehicle_x: f32,
    ) -> CrossingType {
        // Need history to detect crossing
        if self.left_lane_x_history.is_empty() {
            self.update_history(left_x, right_x, vehicle_x);
            return CrossingType::None;
        }

        match (left_x, right_x) {
            (Some(lx), Some(rx)) => {
                // Get previous positions
                let prev_left = self.left_lane_x_history.back().copied();
                let prev_right = self.right_lane_x_history.back().copied();
                let prev_vehicle = self.vehicle_x_history.back().copied();

                if let (Some(prev_lx), Some(prev_rx), Some(prev_vx)) =
                    (prev_left, prev_right, prev_vehicle)
                {
                    // Check if vehicle WAS inside lane boundaries
                    let was_inside = prev_vx > (prev_lx + self.crossing_margin)
                        && prev_vx < (prev_rx - self.crossing_margin);

                    // Check if vehicle IS STILL inside lane boundaries
                    let is_inside = vehicle_x > (lx + self.crossing_margin)
                        && vehicle_x < (rx - self.crossing_margin);

                    // Crossing detected if vehicle went from inside to outside
                    if was_inside && !is_inside {
                        let crossing_type = if vehicle_x <= lx + self.crossing_margin {
                            CrossingType::CrossedLeft
                        } else if vehicle_x >= rx - self.crossing_margin {
                            CrossingType::CrossedRight
                        } else {
                            CrossingType::None
                        };

                        if crossing_type != CrossingType::None {
                            debug!(
                                "ðŸš¨ Boundary crossing detected: {:?} | Vehicle: {:.1} | Left: {:.1} | Right: {:.1}",
                                crossing_type, vehicle_x, lx, rx
                            );
                        }

                        self.update_history(left_x, right_x, vehicle_x);
                        return crossing_type;
                    }
                }

                self.update_history(left_x, right_x, vehicle_x);
                CrossingType::None
            }
            _ => {
                // Can't detect crossing without both lane boundaries
                self.update_history(left_x, right_x, vehicle_x);
                CrossingType::None
            }
        }
    }

    fn update_history(&mut self, left_x: Option<f32>, right_x: Option<f32>, vehicle_x: f32) {
        if let Some(lx) = left_x {
            self.left_lane_x_history.push_back(lx);
            if self.left_lane_x_history.len() > self.history_size {
                self.left_lane_x_history.pop_front();
            }
        }

        if let Some(rx) = right_x {
            self.right_lane_x_history.push_back(rx);
            if self.right_lane_x_history.len() > self.history_size {
                self.right_lane_x_history.pop_front();
            }
        }

        self.vehicle_x_history.push_back(vehicle_x);
        if self.vehicle_x_history.len() > self.history_size {
            self.vehicle_x_history.pop_front();
        }
    }

    pub fn reset(&mut self) {
        self.left_lane_x_history.clear();
        self.right_lane_x_history.clear();
        self.vehicle_x_history.clear();
    }
}
// src/analysis/velocity_tracker.rs

use std::collections::VecDeque;

pub struct LateralVelocityTracker {
    offset_history: VecDeque<(f32, f64)>, // (offset_px, timestamp_ms)
    history_size: usize,
}

impl LateralVelocityTracker {
    pub fn new() -> Self {
        Self {
            offset_history: VecDeque::with_capacity(20),
            history_size: 20,
        }
    }

    pub fn get_velocity(&mut self, offset_px: f32, timestamp_ms: f64) -> f32 {
        self.offset_history.push_back((offset_px, timestamp_ms));

        if self.offset_history.len() > self.history_size {
            self.offset_history.pop_front();
        }

        if self.offset_history.len() < 5 {
            return 0.0;
        }

        // Calculate velocity over the entire history window
        let first = self.offset_history.front().unwrap();
        let last = self.offset_history.back().unwrap();

        let delta_offset = last.0 - first.0;
        let delta_time = (last.1 - first.1) / 1000.0; // Convert to seconds

        if delta_time > 0.01 {
            // Avoid division by near-zero
            let velocity = delta_offset / delta_time as f32; // pixels per second
            velocity
        } else {
            0.0
        }
    }

    #[allow(dead_code)]
    pub fn is_moving_laterally(&self, min_velocity_px_per_sec: f32) -> bool {
        if self.offset_history.len() < 5 {
            return false;
        }

        let first = self.offset_history.front().unwrap();
        let last = self.offset_history.back().unwrap();

        let delta_offset = (last.0 - first.0).abs();
        let delta_time = (last.1 - first.1) / 1000.0;

        if delta_time > 0.01 {
            let velocity = delta_offset / delta_time as f32;
            velocity > min_velocity_px_per_sec
        } else {
            false
        }
    }

    pub fn reset(&mut self) {
        self.offset_history.clear();
    }
}
// src/analysis/lane_analyzer.rs

use crate::analysis::boundary_detector::{CrossingType, LaneBoundaryCrossingDetector};
use crate::analysis::position_estimator::{PositionEstimator, PositionSmoother};
use crate::analysis::state_machine::LaneChangeStateMachine;
use crate::types::{Lane, LaneChangeConfig, LaneChangeEvent, VehicleState};

pub struct LaneChangeAnalyzer {
    position_estimator: PositionEstimator,
    smoother: PositionSmoother,
    state_machine: LaneChangeStateMachine,
    boundary_detector: LaneBoundaryCrossingDetector,
    config: LaneChangeConfig,
    last_state: Option<VehicleState>,
    frame_count: u64,
    valid_estimates: u64,
}

impl LaneChangeAnalyzer {
    pub fn new(config: LaneChangeConfig) -> Self {
        let position_estimator = PositionEstimator::new(config.reference_y_ratio);
        let smoother = PositionSmoother::new(config.smoothing_alpha);
        let state_machine = LaneChangeStateMachine::new(config.clone());
        let boundary_detector = LaneBoundaryCrossingDetector::new();

        Self {
            position_estimator,
            smoother,
            state_machine,
            boundary_detector,
            config,
            last_state: None,
            frame_count: 0,
            valid_estimates: 0,
        }
    }

    pub fn analyze(
        &mut self,
        lanes: &[Lane],
        frame_width: u32,
        frame_height: u32,
        frame_id: u64,
        timestamp_ms: f64,
    ) -> Option<LaneChangeEvent> {
        self.frame_count += 1;

        // Update curve detector with current lanes
        let _is_in_curve = self.state_machine.update_curve_detector(lanes);

        // Get raw position estimate
        let mut raw_state = self
            .position_estimator
            .estimate(lanes, frame_width, frame_height);
        raw_state.frame_id = frame_id;
        raw_state.timestamp_ms = timestamp_ms;

        // Apply smoothing
        let smoothed_state = self.smoother.smooth(raw_state);

        if smoothed_state.is_valid() {
            self.valid_estimates += 1;
        }

        // Detect lane boundary crossing
        let (left_x, right_x) = self.get_lane_boundaries(lanes, frame_height);
        let vehicle_x = frame_width as f32 / 2.0;

        let crossing_type = self
            .boundary_detector
            .detect_crossing(left_x, right_x, vehicle_x);

        self.last_state = Some(smoothed_state);

        // Update state machine with crossing info
        self.state_machine
            .update(&smoothed_state, frame_id, timestamp_ms, crossing_type)
    }

    fn get_lane_boundaries(&self, lanes: &[Lane], frame_height: u32) -> (Option<f32>, Option<f32>) {
        let reference_y = frame_height as f32 * self.config.reference_y_ratio;

        // Find left and right ego lanes
        let mut left_x = None;
        let mut right_x = None;

        let vehicle_x = 640.0; // Approximate center, adjust if needed

        for lane in lanes {
            if let Some(x) = lane.get_x_at_y(reference_y) {
                if x < vehicle_x && (left_x.is_none() || x > left_x.unwrap()) {
                    left_x = Some(x);
                } else if x > vehicle_x && (right_x.is_none() || x < right_x.unwrap()) {
                    right_x = Some(x);
                }
            }
        }

        (left_x, right_x)
    }

    pub fn current_state(&self) -> &str {
        self.state_machine.current_state()
    }

    pub fn last_vehicle_state(&self) -> Option<&VehicleState> {
        self.last_state.as_ref()
    }

    pub fn reset(&mut self) {
        self.state_machine.reset();
        self.smoother.reset();
        self.position_estimator.reset();
        self.boundary_detector.reset();
        self.last_state = None;
        self.frame_count = 0;
        self.valid_estimates = 0;
    }

    pub fn set_source_id(&mut self, source_id: String) {
        self.state_machine.set_source_id(source_id);
    }

    pub fn config(&self) -> &LaneChangeConfig {
        &self.config
    }

    pub fn get_stats(&self) -> (u64, u64, f32) {
        let valid_ratio = if self.frame_count > 0 {
            self.valid_estimates as f32 / self.frame_count as f32
        } else {
            0.0
        };
        (self.frame_count, self.valid_estimates, valid_ratio)
    }
}
use crate::types::Config;
use anyhow::Result;
use std::fs;

impl Config {
    pub fn load(path: &str) -> Result<Self> {
        let contents = fs::read_to_string(path)?;
        let config: Config = serde_yaml::from_str(&contents)?;
        Ok(config)
    }
}
// src/lane_detection.rs

use crate::types::{Config, DetectedLane};
use anyhow::Result;
use tracing::debug;

pub struct LaneDetectionResult {
    pub lanes: Vec<DetectedLane>,
    pub timestamp_ms: f64,
}

/// Softmax along first axis
fn softmax_axis0(data: &[f32], dim0: usize, dim1: usize, dim2: usize) -> Vec<f32> {
    let mut result = vec![0.0f32; data.len()];

    for j in 0..dim1 {
        for k in 0..dim2 {
            // Find max for numerical stability
            let mut max_val = f32::NEG_INFINITY;
            for i in 0..dim0 {
                let idx = i * (dim1 * dim2) + j * dim2 + k;
                if data[idx] > max_val {
                    max_val = data[idx];
                }
            }

            // Compute exp and sum
            let mut sum = 0.0f32;
            for i in 0..dim0 {
                let idx = i * (dim1 * dim2) + j * dim2 + k;
                let exp_val = (data[idx] - max_val).exp();
                result[idx] = exp_val;
                sum += exp_val;
            }

            // Normalize
            for i in 0..dim0 {
                let idx = i * (dim1 * dim2) + j * dim2 + k;
                result[idx] /= sum;
            }
        }
    }

    result
}

pub fn parse_lanes(
    output: &[f32],
    frame_width: f32,
    frame_height: f32,
    config: &Config,
    timestamp_ms: f64,
) -> Result<LaneDetectionResult> {
    let griding_num = config.model.griding_num; // 200
    let num_anchors = config.model.num_anchors; // 72
    let num_lanes = config.model.num_lanes; // 4

    // Expected size for loc_row tensor [200, 72, 4]
    let loc_row_size = griding_num * num_anchors * num_lanes;

    if output.len() < loc_row_size {
        anyhow::bail!(
            "Output size mismatch: expected {}, got {}",
            loc_row_size,
            output.len()
        );
    }

    // Constants matching Python
    const ROW_ANCHOR_START: f32 = 160.0;
    const ROW_ANCHOR_END: f32 = 710.0;
    const ORIGINAL_HEIGHT: f32 = 720.0;

    // Apply softmax along grid dimension (like Python)
    let loc_row_prob = softmax_axis0(output, griding_num, num_anchors, num_lanes);

    let mut lanes = Vec::new();

    for lane_idx in 0..num_lanes {
        let mut points: Vec<(f32, f32)> = Vec::new();
        let mut total_confidence = 0.0;
        let mut valid_points = 0;

        for anchor_idx in 0..num_anchors {
            // Find argmax along grid dimension (after softmax)
            let mut max_prob = f32::NEG_INFINITY;
            let mut max_grid_idx = 0;

            for grid_idx in 0..griding_num {
                let idx = grid_idx * (num_anchors * num_lanes) + anchor_idx * num_lanes + lane_idx;
                let prob = loc_row_prob[idx];
                if prob > max_prob {
                    max_prob = prob;
                    max_grid_idx = grid_idx;
                }
            }

            // Skip grid_idx == 0 (no lane class) - matches Python
            if max_grid_idx == 0 {
                continue;
            }

            // Only include points with reasonable confidence
            if max_prob < 0.1 {
                continue;
            }

            // Calculate X coordinate - matches Python exactly
            // Python: x_norm = (grid_idx - 1) / (num_grid_cells - 1)
            let x_norm = (max_grid_idx as f32 - 1.0) / (griding_num as f32 - 1.0);
            let x = x_norm * frame_width;

            // Calculate Y coordinate - matches Python exactly
            // Python: np.linspace(160, 710, 72)
            let y_norm = ROW_ANCHOR_START
                + (ROW_ANCHOR_END - ROW_ANCHOR_START)
                    * (anchor_idx as f32 / (num_anchors as f32 - 1.0));
            let y = (y_norm / ORIGINAL_HEIGHT) * frame_height;

            points.push((x, y));
            total_confidence += max_prob;
            valid_points += 1;
        }

        // Require minimum points per lane
        if points.len() >= config.detection.min_points_per_lane {
            let avg_confidence = if valid_points > 0 {
                total_confidence / valid_points as f32
            } else {
                0.0
            };

            // Sort points by Y (bottom to top for consistency)
            points.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));

            lanes.push(DetectedLane {
                points,
                confidence: avg_confidence,
            });
        }
    }

    debug!("Detected {} lanes", lanes.len());

    Ok(LaneDetectionResult {
        lanes,
        timestamp_ms,
    })
}
// src/main.rs

mod analysis;
mod frame_buffer;
mod inference;
mod lane_detection;
mod preprocessing;
mod types;
mod video_processor;

use analysis::LaneChangeAnalyzer;
use anyhow::Result;
use frame_buffer::{
    build_legality_request, print_legality_request, save_legality_request_to_file,
    send_to_legality_api, LaneChangeFrameBuffer,
};
use std::path::Path;
use tracing::{debug, error, info, warn};
use types::{DetectedLane, Frame, Lane, LaneChangeConfig, LaneChangeEvent};

/// Configuration for legality analysis
struct LegalityAnalysisConfig {
    /// Number of frames to extract and send for analysis
    num_frames_to_analyze: usize,
    /// Maximum frames to buffer during lane change
    max_buffer_frames: usize,
    /// Whether to save the request payload to a file
    save_to_file: bool,
    /// Whether to print the request to console
    print_to_console: bool,
    /// Whether to send to the API
    send_to_api: bool,
    /// API URL for legality analysis
    api_url: String,
}

impl Default for LegalityAnalysisConfig {
    fn default() -> Self {
        Self {
            num_frames_to_analyze: 7,
            max_buffer_frames: 90,
            save_to_file: false,
            print_to_console: true,
            send_to_api: true,
            api_url: "http://localhost:3000/api/analyze".to_string(),
        }
    }
}

#[tokio::main]
async fn main() -> Result<()> {
    tracing_subscriber::fmt()
        .with_env_filter("overtake_detection=info,ort=warn")
        .init();

    info!("ðŸš— Lane Change Detection System Starting");

    let config = types::Config::load("config.yaml")?;
    info!("âœ“ Configuration loaded");

    // Log key detection parameters
    info!(
        "Detection thresholds: drift={:.2}, crossing={:.2}, confirm_frames={}",
        config.detection.drift_threshold,
        config.detection.crossing_threshold,
        config.detection.confirm_frames
    );

    let mut inference_engine = inference::InferenceEngine::new(config.clone())?;
    info!("âœ“ Inference engine ready");

    let video_processor = video_processor::VideoProcessor::new(config.clone());

    let video_files = video_processor.find_video_files()?;

    if video_files.is_empty() {
        error!("No video files found in {}", config.video.input_dir);
        return Ok(());
    }

    info!("Found {} video file(s) to process", video_files.len());

    // Legality analysis configuration
    let legality_config = LegalityAnalysisConfig {
        num_frames_to_analyze: 5,
        max_buffer_frames: 90,
        save_to_file: false,
        print_to_console: true,
        send_to_api: true,
        api_url: std::env::var("LEGALITY_API_URL")
            .unwrap_or_else(|_| "http://localhost:3000/api/analyze".to_string()),
    };

    info!("ðŸ“¡ Legality API URL: {}", legality_config.api_url);

    for (idx, video_path) in video_files.iter().enumerate() {
        info!("\n========================================");
        info!(
            "Processing video {}/{}: {}",
            idx + 1,
            video_files.len(),
            video_path.display()
        );
        info!("========================================\n");

        match process_video(
            video_path,
            &mut inference_engine,
            &video_processor,
            &config,
            &legality_config,
        )
        .await
        {
            Ok(stats) => {
                info!("\nâœ“ Video processed successfully!");
                info!("  Total frames: {}", stats.total_frames);
                info!(
                    "  Valid position frames: {} ({:.1}%)",
                    stats.frames_with_position,
                    100.0 * stats.frames_with_position as f64 / stats.total_frames as f64
                );
                info!("  Lane changes detected: {}", stats.lane_changes_detected);
                info!("  Events sent to API: {}", stats.events_sent_to_api);
            }
            Err(e) => {
                error!("Failed to process video: {}", e);
            }
        }
    }

    Ok(())
}

struct ProcessingStats {
    total_frames: u64,
    frames_with_position: u64,
    lane_changes_detected: usize,
    events_sent_to_api: usize,
    duration_secs: f64,
    avg_fps: f64,
}

async fn process_video(
    video_path: &Path,
    inference_engine: &mut inference::InferenceEngine,
    video_processor: &video_processor::VideoProcessor,
    config: &types::Config,
    legality_config: &LegalityAnalysisConfig,
) -> Result<ProcessingStats> {
    use std::time::Instant;

    let start_time = Instant::now();

    let mut reader = video_processor.open_video(video_path)?;

    let mut writer =
        video_processor.create_writer(video_path, reader.width, reader.height, reader.fps)?;

    // *** USE CONFIG VALUES INSTEAD OF HARDCODED ***
    let lane_change_config = LaneChangeConfig::from_detection_config(&config.detection);

    info!(
        "Lane change config: drift={:.2}, crossing={:.2}, confirm={}, cooldown={}, hysteresis={:.2}",
        lane_change_config.drift_threshold,
        lane_change_config.crossing_threshold,
        lane_change_config.min_frames_confirm,
        lane_change_config.cooldown_frames,
        lane_change_config.hysteresis_factor
    );

    let mut analyzer = LaneChangeAnalyzer::new(lane_change_config);
    analyzer.set_source_id(video_path.to_string_lossy().to_string());

    let mut lane_changes: Vec<LaneChangeEvent> = Vec::new();
    let mut frame_count: u64 = 0;
    let mut frames_with_valid_position: u64 = 0;
    let mut events_sent_to_api: usize = 0;

    let mut cached_start_frame: Option<Frame> = None;
    let mut previous_state = "CENTERED".to_string();

    // Frame buffer for capturing lane change frames
    let mut frame_buffer = LaneChangeFrameBuffer::new(legality_config.max_buffer_frames);

    // Confidence threshold from config
    let lane_confidence_threshold = config.detection.min_lane_confidence;

    // En la funciÃ³n process_video, reemplaza todo el loop while:

    while let Some(frame) = reader.read_frame()? {
        frame_count += 1;
        let timestamp_ms = frame.timestamp_ms;

        if frame_count % 50 == 0 {
            info!(
            "Progress: {:.1}% ({}/{}) | State: {} | Lane changes: {} | Buffered: {} | Pre-buffered: {}",
            reader.progress(),
            reader.current_frame,
            reader.total_frames,
            analyzer.current_state(),
            lane_changes.len(),
            frame_buffer.frame_count(),
            frame_buffer.pre_buffer_count()
        );
        }

        match process_frame(
            &frame,
            inference_engine,
            config,
            config.detection.min_lane_confidence,
        )
        .await
        {
            Ok(detected_lanes) => {
                let analysis_lanes: Vec<Lane> = detected_lanes
                    .iter()
                    .enumerate()
                    .map(|(i, dl)| Lane::from_detected(i, dl))
                    .collect();

                // âœ… IMPORTANTE: Agregar al pre-buffer ANTES de analizar (usa previous_state)
                if previous_state == "CENTERED" {
                    frame_buffer.add_to_pre_buffer(frame.clone());
                }

                // Check if lane change completed
                if let Some(mut event) = analyzer.analyze(
                    &analysis_lanes,
                    frame.width as u32,
                    frame.height as u32,
                    frame_count,
                    timestamp_ms,
                ) {
                    info!(
                        "ðŸš€ LANE CHANGE DETECTED: {} at {:.2}s (frame {})",
                        event.direction_name(),
                        event.video_timestamp_ms / 1000.0,
                        event.end_frame_id
                    );

                    // Get captured frames (includes pre-buffer)
                    let captured_frames = frame_buffer.stop_capture();

                    info!(
                        "ðŸ“¹ Captured {} frames total (includes pre-buffer context)",
                        captured_frames.len()
                    );

                    // Build and send legality request
                    if !captured_frames.is_empty() {
                        match build_legality_request(
                            &event,
                            &captured_frames,
                            legality_config.num_frames_to_analyze,
                        ) {
                            Ok(request) => {
                                if legality_config.print_to_console {
                                    print_legality_request(&request);
                                }

                                if legality_config.save_to_file {
                                    if let Err(e) = save_legality_request_to_file(
                                        &request,
                                        &config.video.output_dir,
                                    ) {
                                        warn!("Failed to save legality request: {}", e);
                                    }
                                }

                                if legality_config.send_to_api {
                                    match send_to_legality_api(&request, &legality_config.api_url)
                                        .await
                                    {
                                        Ok(response) => {
                                            info!(
                                                "âœ… Event {} sent to API: {} - {}",
                                                response.event_id,
                                                response.status,
                                                response.message
                                            );
                                            events_sent_to_api += 1;
                                        }
                                        Err(e) => {
                                            error!("âŒ Failed to send event to API: {}", e);
                                        }
                                    }
                                }
                            }
                            Err(e) => {
                                warn!("Failed to build legality request: {}", e);
                            }
                        }
                    } else {
                        warn!("No frames captured for lane change event");
                    }

                    // Save evidence images (use first captured frame as start)
                    let video_stem = video_path.file_stem().unwrap().to_str().unwrap();
                    let start_filename =
                        format!("{}_event_{}_start.jpg", video_stem, event.event_id);
                    let end_filename = format!("{}_event_{}_end.jpg", video_stem, event.event_id);

                    let mut start_path_str = String::new();
                    let mut end_path_str = String::new();

                    // Use first captured frame (from pre-buffer) as start
                    if !captured_frames.is_empty() {
                        if let Ok(path) =
                            video_processor.save_frame_to_disk(&captured_frames[0], &start_filename)
                        {
                            start_path_str = path.to_string_lossy().to_string();
                        }
                    }

                    if let Ok(path) = video_processor.save_frame_to_disk(&frame, &end_filename) {
                        end_path_str = path.to_string_lossy().to_string();
                    }

                    event.evidence_images = Some(types::EvidencePaths {
                        start_image_path: start_path_str,
                        end_image_path: end_path_str,
                    });

                    lane_changes.push(event);
                }

                // âœ… Obtener current_state DESPUÃ‰S del anÃ¡lisis
                let current_state = analyzer.current_state().to_string();

                // Start capturing when CENTERED -> DRIFTING
                if previous_state == "CENTERED" && current_state == "DRIFTING" {
                    frame_buffer.start_capture(frame_count);
                    debug!(
                        "ðŸ“¸ Started capturing at frame {} (with pre-buffer)",
                        frame_count
                    );
                }

                // Continue capturing during lane change
                if frame_buffer.is_capturing() {
                    frame_buffer.add_frame(frame.clone());
                }

                // Cancel if returned to CENTERED without completing
                if current_state == "CENTERED" && frame_buffer.is_capturing() {
                    frame_buffer.cancel_capture();
                    debug!("âŒ Lane change cancelled");
                }

                // âœ… Actualizar previous_state al final
                previous_state = current_state;

                if frame_count % 50 == 0 {
                    if let Some(vs) = analyzer.last_vehicle_state() {
                        if vs.is_valid() {
                            let normalized = vs.normalized_offset().unwrap_or(0.0);
                            let width = vs.lane_width.unwrap_or(0.0);
                            if normalized.abs() > 0.1 {
                                info!(
                                "Frame {}: State={} | Offset: {:.1}px ({:.1}%) | Width: {:.0}px",
                                frame_count,
                                analyzer.current_state(),
                                vs.lateral_offset,
                                normalized * 100.0,
                                width
                            );
                            }
                        }
                    }
                }

                if analyzer
                    .last_vehicle_state()
                    .map_or(false, |s| s.is_valid())
                {
                    frames_with_valid_position += 1;
                }

                if let Some(ref mut w) = writer {
                    if let Ok(annotated) = video_processor::draw_lanes_with_state(
                        &frame.data,
                        reader.width,
                        reader.height,
                        &detected_lanes,
                        analyzer.current_state(),
                        analyzer.last_vehicle_state(),
                    ) {
                        use opencv::videoio::VideoWriterTrait;
                        w.write(&annotated)?;
                    }
                }
            }
            Err(e) => error!("Frame {} failed: {}", frame_count, e),
        }
    }

    let duration = start_time.elapsed();
    let avg_fps = frame_count as f64 / duration.as_secs_f64();

    info!("\nðŸ“Š Final Report:");
    info!("  Total Lane Changes: {}", lane_changes.len());
    info!("  Events Sent to API: {}", events_sent_to_api);
    info!("  Processing Speed: {:.1} FPS", avg_fps);

    for (i, event) in lane_changes.iter().enumerate() {
        info!(
            "  {}. {} at {:.2}s (confidence: {:.2})",
            i + 1,
            event.direction_name(),
            event.video_timestamp_ms / 1000.0,
            event.confidence
        );
    }

    save_results(video_path, &lane_changes, config)?;

    Ok(ProcessingStats {
        total_frames: frame_count,
        frames_with_position: frames_with_valid_position,
        lane_changes_detected: lane_changes.len(),
        events_sent_to_api,
        duration_secs: duration.as_secs_f64(),
        avg_fps,
    })
}

async fn process_frame(
    frame: &Frame,
    inference_engine: &mut inference::InferenceEngine,
    config: &types::Config,
    confidence_threshold: f32,
) -> Result<Vec<DetectedLane>> {
    let preprocessed = preprocessing::preprocess(
        &frame.data,
        frame.width,
        frame.height,
        config.model.input_width,
        config.model.input_height,
    )?;

    let output = inference_engine.infer(&preprocessed)?;

    let lane_detection = lane_detection::parse_lanes(
        &output,
        frame.width as f32,
        frame.height as f32,
        config,
        frame.timestamp_ms,
    )?;

    // Use config threshold instead of hardcoded
    let high_confidence_lanes: Vec<DetectedLane> = lane_detection
        .lanes
        .into_iter()
        .filter(|lane| {
            lane.confidence > confidence_threshold
                && lane.points.len() >= config.detection.min_points_per_lane
        })
        .collect();

    Ok(high_confidence_lanes)
}

fn save_results(
    video_path: &Path,
    lane_changes: &[LaneChangeEvent],
    config: &types::Config,
) -> Result<()> {
    use std::fs::File;
    use std::io::Write;

    std::fs::create_dir_all(&config.video.output_dir)?;
    let video_name = video_path.file_stem().unwrap().to_str().unwrap();
    let jsonl_path =
        Path::new(&config.video.output_dir).join(format!("{}_lane_changes.jsonl", video_name));

    let mut file = File::create(&jsonl_path)?;
    for event in lane_changes {
        let json_line = serde_json::to_string(&event.to_json())?;
        writeln!(file, "{}", json_line)?;
    }
    info!("ðŸ’¾ Saved to: {}", jsonl_path.display());
    Ok(())
}
// src/preprocessing.rs

use anyhow::Result;

/// Preprocess raw RGB image for model input
pub fn preprocess(
    src: &[u8],
    src_width: usize,
    src_height: usize,
    dst_width: usize,
    dst_height: usize,
) -> Result<Vec<f32>> {
    // Resize
    let resized = resize_bilinear(src, src_width, src_height, dst_width, dst_height);

    // Normalize and convert HWC -> CHW
    const MEAN: [f32; 3] = [0.485, 0.456, 0.406];
    const STD: [f32; 3] = [0.229, 0.224, 0.225];

    let mut output = vec![0.0f32; 3 * dst_height * dst_width];

    for c in 0..3 {
        for h in 0..dst_height {
            for w in 0..dst_width {
                let hwc_idx = (h * dst_width + w) * 3 + c;
                let chw_idx = c * dst_height * dst_width + h * dst_width + w;

                let pixel = resized[hwc_idx] as f32 / 255.0;
                output[chw_idx] = (pixel - MEAN[c]) / STD[c];
            }
        }
    }

    Ok(output)
}

/// Bilinear image resize
fn resize_bilinear(src: &[u8], src_w: usize, src_h: usize, dst_w: usize, dst_h: usize) -> Vec<u8> {
    let mut dst = vec![0u8; dst_h * dst_w * 3];

    let x_ratio = src_w as f32 / dst_w as f32;
    let y_ratio = src_h as f32 / dst_h as f32;

    for dy in 0..dst_h {
        for dx in 0..dst_w {
            let sx = dx as f32 * x_ratio;
            let sy = dy as f32 * y_ratio;

            let sx0 = sx.floor() as usize;
            let sy0 = sy.floor() as usize;
            let sx1 = (sx0 + 1).min(src_w - 1);
            let sy1 = (sy0 + 1).min(src_h - 1);

            let fx = sx - sx0 as f32;
            let fy = sy - sy0 as f32;

            for c in 0..3 {
                let p00 = src[(sy0 * src_w + sx0) * 3 + c] as f32;
                let p10 = src[(sy0 * src_w + sx1) * 3 + c] as f32;
                let p01 = src[(sy1 * src_w + sx0) * 3 + c] as f32;
                let p11 = src[(sy1 * src_w + sx1) * 3 + c] as f32;

                let val = p00 * (1.0 - fx) * (1.0 - fy)
                    + p10 * fx * (1.0 - fy)
                    + p01 * (1.0 - fx) * fy
                    + p11 * fx * fy;

                dst[(dy * dst_w + dx) * 3 + c] = val.round() as u8;
            }
        }
    }

    dst
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_preprocess() {
        let src = vec![128u8; 640 * 480 * 3];
        let result = preprocess(&src, 640, 480, 1600, 320);
        assert!(result.is_ok());
        assert_eq!(result.unwrap().len(), 3 * 320 * 1600);
    }

    #[test]
    fn test_resize() {
        let src = vec![255u8; 100 * 100 * 3];
        let dst = resize_bilinear(&src, 100, 100, 50, 50);
        assert_eq!(dst.len(), 50 * 50 * 3);
    }
}
use opencv::{core, imgproc, prelude::*};

pub fn visualize_lanes(frame: &Mat, lanes: &[Lane], position: &VehiclePosition) -> Result<Mat> {
    let mut debug_frame = frame.clone();

    // Draw detected lanes with different colors
    let colors = [
        core::Scalar::new(255.0, 0.0, 0.0, 0.0),   // Blue - Lane 0
        core::Scalar::new(0.0, 255.0, 0.0, 0.0),   // Green - Lane 1
        core::Scalar::new(0.0, 0.0, 255.0, 0.0),   // Red - Lane 2
        core::Scalar::new(255.0, 255.0, 0.0, 0.0), // Cyan - Lane 3
    ];

    for (i, lane) in lanes.iter().enumerate() {
        // Draw lane points
        for window in lane.points.windows(2) {
            let p1 = core::Point::new(window[0].x as i32, window[0].y as i32);
            let p2 = core::Point::new(window[1].x as i32, window[1].y as i32);
            imgproc::line(
                &mut debug_frame,
                p1,
                p2,
                colors[i % 4],
                3,
                imgproc::LINE_8,
                0,
            )?;
        }

        // Draw lane ID
        if let Some(first_point) = lane.points.first() {
            imgproc::put_text(
                &mut debug_frame,
                &format!("L{} ({:.2})", i, lane.confidence),
                core::Point::new(first_point.x as i32, first_point.y as i32 - 10),
                imgproc::FONT_HERSHEY_SIMPLEX,
                0.6,
                colors[i % 4],
                2,
                imgproc::LINE_8,
                false,
            )?;
        }
    }

    // Draw vehicle position indicator
    let vehicle_x = frame.cols() / 2;
    let vehicle_y = (frame.rows() as f32 * 0.85) as i32;

    imgproc::circle(
        &mut debug_frame,
        core::Point::new(vehicle_x, vehicle_y),
        10,
        core::Scalar::new(0.0, 255.0, 255.0, 0.0), // Yellow
        -1,
        imgproc::LINE_8,
        0,
    )?;

    // Draw current lane info
    let info = format!(
        "Lane: {} | Offset: {:.2} | Conf: {:.2}",
        position.lane_index, position.lateral_offset, position.confidence
    );
    imgproc::put_text(
        &mut debug_frame,
        &info,
        core::Point::new(10, 30),
        imgproc::FONT_HERSHEY_SIMPLEX,
        0.8,
        core::Scalar::new(0.0, 255.0, 0.0, 0.0),
        2,
        imgproc::LINE_8,
        false,
    )?;

    Ok(debug_frame)
}
// src/inference.rs

use crate::types::Config;
use anyhow::{Context, Result};
use ort::{
    execution_providers::CUDAExecutionProvider,
    session::{builder::GraphOptimizationLevel, Session},
};
use tracing::{debug, info};

pub struct InferenceEngine {
    session: Session,
    config: Config,
}

impl InferenceEngine {
    pub fn new(config: Config) -> Result<Self> {
        info!("Initializing inference engine");
        info!("Model path: {}", config.model.path);

        let mut session_builder = Session::builder()?;

        // CUDA execution provider
        info!("Enabling CUDA execution provider");
        session_builder =
            session_builder.with_execution_providers([CUDAExecutionProvider::default()
                .with_device_id(0)
                .build()])?;

        info!("Building ONNX Runtime session...");
        let session = session_builder
            .with_optimization_level(GraphOptimizationLevel::Level3)?
            .with_intra_threads(config.inference.num_threads)?
            .with_inter_threads(1)?
            .commit_from_file(&config.model.path)
            .context("Failed to load model")?;

        info!("âœ“ Inference engine initialized successfully");

        Ok(Self { session, config })
    }

    pub fn infer(&mut self, input: &[f32]) -> Result<Vec<f32>> {
        debug!("Running inference");

        // Create shape tuple
        let shape = [
            1,
            3,
            self.config.model.input_height,
            self.config.model.input_width,
        ];

        // Create input value from tuple (shape, data)
        let input_value =
            ort::value::Value::from_array((shape.as_slice(), input.to_vec().into_boxed_slice()))?;

        // Run inference
        let outputs = self.session.run(ort::inputs!["input" => input_value])?;

        // Extract output
        let output = &outputs[0];
        let (output_shape, data_slice) = output.try_extract_tensor::<f32>()?;

        // Convert slice to Vec
        let output_data: Vec<f32> = data_slice.to_vec();

        Ok(output_data)
    }
}
