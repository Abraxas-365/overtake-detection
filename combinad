=== ./Cargo.lock ===
# This file is automatically @generated by Cargo.
# It is not intended for manual editing.
version = 4

[[package]]
name = "adler2"
version = "2.0.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "320119579fcad9c21884f5c4861d16174d0e06250625266f50fe6898340abefa"

[[package]]
name = "aho-corasick"
version = "1.1.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ddd31a130427c27518df266943a5308ed92d4b226cc639f5a8f1002816174301"
dependencies = [
 "memchr",
]

[[package]]
name = "aligned"
version = "0.4.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ee4508988c62edf04abd8d92897fca0c2995d907ce1dfeaf369dac3716a40685"
dependencies = [
 "as-slice",
]

[[package]]
name = "aligned-vec"
version = "0.6.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "dc890384c8602f339876ded803c97ad529f3842aba97f6392b3dba0dd171769b"
dependencies = [
 "equator",
]

[[package]]
name = "android_system_properties"
version = "0.1.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "819e7219dbd41043ac279b19830f2efc897156490d7fd6ea916720117ee66311"
dependencies = [
 "libc",
]

[[package]]
name = "anyhow"
version = "1.0.100"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a23eb6b1614318a8071c9b2521f36b424b2c83db5eb3a0fead4a6c0809af6e61"

[[package]]
name = "arbitrary"
version = "1.4.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c3d036a3c4ab069c7b410a2ce876bd74808d2d0888a82667669f8e783a898bf1"

[[package]]
name = "arg_enum_proc_macro"
version = "0.3.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0ae92a5119aa49cdbcf6b9f893fe4e1d98b04ccbf82ee0584ad948a44a734dea"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "arrayvec"
version = "0.7.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7c02d123df017efcdfbd739ef81735b36c5ba83ec3c59c80a9d7ecc718f92e50"

[[package]]
name = "as-slice"
version = "0.2.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "516b6b4f0e40d50dcda9365d53964ec74560ad4284da2e7fc97122cd83174516"
dependencies = [
 "stable_deref_trait",
]

[[package]]
name = "autocfg"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c08606f8c3cbf4ce6ec8e28fb0014a2c086708fe954eaa885384a6165172e7e8"

[[package]]
name = "av-scenechange"
version = "0.14.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0f321d77c20e19b92c39e7471cf986812cbb46659d2af674adc4331ef3f18394"
dependencies = [
 "aligned",
 "anyhow",
 "arg_enum_proc_macro",
 "arrayvec",
 "log",
 "num-rational",
 "num-traits",
 "pastey",
 "rayon",
 "thiserror 2.0.17",
 "v_frame",
 "y4m",
]

[[package]]
name = "av1-grain"
version = "0.2.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8cfddb07216410377231960af4fcab838eaa12e013417781b78bd95ee22077f8"
dependencies = [
 "anyhow",
 "arrayvec",
 "log",
 "nom",
 "num-rational",
 "v_frame",
]

[[package]]
name = "avif-serialize"
version = "0.8.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "47c8fbc0f831f4519fe8b810b6a7a91410ec83031b8233f730a0480029f6a23f"
dependencies = [
 "arrayvec",
]

[[package]]
name = "base64"
version = "0.21.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9d297deb1925b89f2ccc13d7635fa0714f12c87adce1c75356b39ca9b7178567"

[[package]]
name = "base64"
version = "0.22.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "72b3254f16251a8381aa12e40e3c4d2f0199f8c6508fbecb9d91f575e0fbb8c6"

[[package]]
name = "base64ct"
version = "1.8.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7d809780667f4410e7c41b07f52439b94d2bdf8528eeedc287fa38d3b7f95d82"

[[package]]
name = "bit_field"
version = "0.10.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1e4b40c7323adcfc0a41c4b88143ed58346ff65a288fc144329c5c45e05d70c6"

[[package]]
name = "bitflags"
version = "1.3.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bef38d45163c2f1dde094a7dfd33ccf595c92905c8f8f4fdc18d06fb1037718a"

[[package]]
name = "bitflags"
version = "2.10.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "812e12b5285cc515a9c72a5c1d3b6d46a19dac5acfef5265968c166106e31dd3"

[[package]]
name = "bitstream-io"
version = "4.9.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "60d4bd9d1db2c6bdf285e223a7fa369d5ce98ec767dec949c6ca62863ce61757"
dependencies = [
 "core2",
]

[[package]]
name = "built"
version = "0.8.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f4ad8f11f288f48ca24471bbd51ac257aaeaaa07adae295591266b792902ae64"

[[package]]
name = "bumpalo"
version = "3.19.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5dd9dc738b7a8311c7ade152424974d8115f2cdad61e8dab8dac9f2362298510"

[[package]]
name = "bytemuck"
version = "1.24.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1fbdf580320f38b612e485521afda1ee26d10cc9884efaaa750d383e13e3c5f4"

[[package]]
name = "byteorder"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1fd0f2584146f6f2ef48085050886acf353beff7305ebd1ae69500e27c67f64b"

[[package]]
name = "byteorder-lite"
version = "0.1.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8f1fe948ff07f4bd06c30984e69f5b4899c516a3ef74f34df92a2df2ab535495"

[[package]]
name = "bytes"
version = "1.11.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b35204fbdc0b3f4446b89fc1ac2cf84a8a68971995d0bf2e925ec7cd960f9cb3"

[[package]]
name = "cc"
version = "1.2.51"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7a0aeaff4ff1a90589618835a598e545176939b97874f7abc7851caa0618f203"
dependencies = [
 "find-msvc-tools",
 "jobserver",
 "libc",
 "shlex",
]

[[package]]
name = "cfg-if"
version = "1.0.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9330f8b2ff13f34540b44e946ef35111825727b38d33286ef986142615121801"

[[package]]
name = "chrono"
version = "0.4.42"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "145052bdd345b87320e369255277e3fb5152762ad123a901ef5c262dd38fe8d2"
dependencies = [
 "iana-time-zone",
 "js-sys",
 "num-traits",
 "serde",
 "wasm-bindgen",
 "windows-link",
]

[[package]]
name = "clang"
version = "2.0.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "84c044c781163c001b913cd018fc95a628c50d0d2dfea8bca77dad71edb16e37"
dependencies = [
 "clang-sys",
 "libc",
]

[[package]]
name = "clang-sys"
version = "1.8.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0b023947811758c97c59bf9d1c188fd619ad4718dcaa767947df1cadb14f39f4"
dependencies = [
 "glob",
 "libc",
]

[[package]]
name = "color_quant"
version = "1.1.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3d7b894f5411737b7867f4827955924d7c254fc9f4d91a6aad6b097804b1018b"

[[package]]
name = "core-foundation"
version = "0.9.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "91e195e091a93c46f7102ec7818a2aa394e1e1771c3ab4825963fa03e45afb8f"
dependencies = [
 "core-foundation-sys",
 "libc",
]

[[package]]
name = "core-foundation-sys"
version = "0.8.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "773648b94d0e5d620f64f280777445740e61fe701025087ec8b57f45c791888b"

[[package]]
name = "core2"
version = "0.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b49ba7ef1ad6107f8824dbe97de947cbaac53c44e7f9756a1fba0d37c1eec505"
dependencies = [
 "memchr",
]

[[package]]
name = "crc32fast"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9481c1c90cbf2ac953f07c8d4a58aa3945c425b7185c9154d67a65e4230da511"
dependencies = [
 "cfg-if",
]

[[package]]
name = "crossbeam-deque"
version = "0.8.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9dd111b7b7f7d55b72c0a6ae361660ee5853c9af73f70c3c2ef6858b950e2e51"
dependencies = [
 "crossbeam-epoch",
 "crossbeam-utils",
]

[[package]]
name = "crossbeam-epoch"
version = "0.9.18"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5b82ac4a3c2ca9c3460964f020e1402edd5753411d7737aa39c3714ad1b5420e"
dependencies = [
 "crossbeam-utils",
]

[[package]]
name = "crossbeam-utils"
version = "0.8.21"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d0a5c400df2834b80a4c3327b3aad3a4c4cd4de0629063962b03235697506a28"

[[package]]
name = "crunchy"
version = "0.2.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "460fbee9c2c2f33933d720630a6a0bac33ba7053db5344fac858d4b8952d77d5"

[[package]]
name = "der"
version = "0.7.10"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e7c1832837b905bbfb5101e07cc24c8deddf52f93225eee6ead5f4d63d53ddcb"
dependencies = [
 "pem-rfc7468",
 "zeroize",
]

[[package]]
name = "displaydoc"
version = "0.2.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "97369cbbc041bc366949bc74d34658d6cda5621039731c6310521892a3a20ae0"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "dunce"
version = "1.0.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "92773504d58c093f6de2459af4af33faa518c13451eb8f2b5698ed3d36e7c813"

[[package]]
name = "either"
version = "1.15.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "48c757948c5ede0e46177b7add2e67155f70e33c07fea8284df6576da70b3719"

[[package]]
name = "encoding_rs"
version = "0.8.35"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "75030f3c4f45dafd7586dd6780965a8c7e8e285a5ecb86713e63a79c5b2766f3"
dependencies = [
 "cfg-if",
]

[[package]]
name = "equator"
version = "0.4.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4711b213838dfee0117e3be6ac926007d7f433d7bbe33595975d4190cb07e6fc"
dependencies = [
 "equator-macro",
]

[[package]]
name = "equator-macro"
version = "0.4.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "44f23cf4b44bfce11a86ace86f8a73ffdec849c9fd00a386a53d278bd9e81fb3"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "equivalent"
version = "1.0.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "877a4ace8713b0bcf2a4e7eec82529c029f1d0619886d18145fea96c3ffe5c0f"

[[package]]
name = "errno"
version = "0.3.14"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "39cab71617ae0d63f51a36d69f866391735b51691dbda63cf6f96d042b63efeb"
dependencies = [
 "libc",
 "windows-sys 0.61.2",
]

[[package]]
name = "exr"
version = "1.74.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4300e043a56aa2cb633c01af81ca8f699a321879a7854d3896a0ba89056363be"
dependencies = [
 "bit_field",
 "half",
 "lebe",
 "miniz_oxide",
 "rayon-core",
 "smallvec",
 "zune-inflate",
]

[[package]]
name = "fastrand"
version = "2.3.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "37909eebbb50d72f9059c3b6d82c0463f2ff062c9e95845c43a6c9c0355411be"

[[package]]
name = "fax"
version = "0.2.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f05de7d48f37cd6730705cbca900770cab77a89f413d23e100ad7fad7795a0ab"
dependencies = [
 "fax_derive",
]

[[package]]
name = "fax_derive"
version = "0.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a0aca10fb742cb43f9e7bb8467c91aa9bcb8e3ffbc6a6f7389bb93ffc920577d"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "fdeflate"
version = "0.3.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1e6853b52649d4ac5c0bd02320cddc5ba956bdb407c4b75a2c6b75bf51500f8c"
dependencies = [
 "simd-adler32",
]

[[package]]
name = "find-msvc-tools"
version = "0.1.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "645cbb3a84e60b7531617d5ae4e57f7e27308f6445f5abf653209ea76dec8dff"

[[package]]
name = "flate2"
version = "1.1.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bfe33edd8e85a12a67454e37f8c75e730830d83e313556ab9ebf9ee7fbeb3bfb"
dependencies = [
 "crc32fast",
 "miniz_oxide",
]

[[package]]
name = "fnv"
version = "1.0.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3f9eec918d3f24069decb9af1554cad7c880e2da24a9afd88aca000531ab82c1"

[[package]]
name = "foreign-types"
version = "0.3.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f6f339eb8adc052cd2ca78910fda869aefa38d22d5cb648e6485e4d3fc06f3b1"
dependencies = [
 "foreign-types-shared",
]

[[package]]
name = "foreign-types-shared"
version = "0.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "00b0228411908ca8685dba7fc2cdd70ec9990a6e753e89b6ac91a84c40fbaf4b"

[[package]]
name = "form_urlencoded"
version = "1.2.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cb4cb245038516f5f85277875cdaa4f7d2c9a0fa0468de06ed190163b1581fcf"
dependencies = [
 "percent-encoding",
]

[[package]]
name = "futures-channel"
version = "0.3.31"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2dff15bf788c671c1934e366d07e30c1814a8ef514e1af724a602e8a2fbe1b10"
dependencies = [
 "futures-core",
]

[[package]]
name = "futures-core"
version = "0.3.31"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "05f29059c0c2090612e8d742178b0580d2dc940c837851ad723096f87af6663e"

[[package]]
name = "futures-sink"
version = "0.3.31"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e575fab7d1e0dcb8d0c7bcf9a63ee213816ab51902e6d244a95819acacf1d4f7"

[[package]]
name = "futures-task"
version = "0.3.31"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f90f7dce0722e95104fcb095585910c0977252f286e354b5e3bd38902cd99988"

[[package]]
name = "futures-util"
version = "0.3.31"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9fa08315bb612088cc391249efdc3bc77536f16c91f6cf495e6fbe85b20a4a81"
dependencies = [
 "futures-core",
 "futures-task",
 "pin-project-lite",
 "pin-utils",
]

[[package]]
name = "getrandom"
version = "0.3.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "899def5c37c4fd7b2664648c28120ecec138e4d395b459e5ca34f9cce2dd77fd"
dependencies = [
 "cfg-if",
 "libc",
 "r-efi",
 "wasip2",
]

[[package]]
name = "gif"
version = "0.14.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f5df2ba84018d80c213569363bdcd0c64e6933c67fe4c1d60ecf822971a3c35e"
dependencies = [
 "color_quant",
 "weezl",
]

[[package]]
name = "glob"
version = "0.3.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0cc23270f6e1808e30a928bdc84dea0b9b4136a8bc82338574f23baf47bbd280"

[[package]]
name = "h2"
version = "0.3.27"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0beca50380b1fc32983fc1cb4587bfa4bb9e78fc259aad4a0032d2080309222d"
dependencies = [
 "bytes",
 "fnv",
 "futures-core",
 "futures-sink",
 "futures-util",
 "http 0.2.12",
 "indexmap",
 "slab",
 "tokio",
 "tokio-util",
 "tracing",
]

[[package]]
name = "half"
version = "2.7.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6ea2d84b969582b4b1864a92dc5d27cd2b77b622a8d79306834f1be5ba20d84b"
dependencies = [
 "cfg-if",
 "crunchy",
 "zerocopy",
]

[[package]]
name = "hashbrown"
version = "0.16.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "841d1cc9bed7f9236f321df977030373f4a4163ae1a7dbfe1a51a2c1a51d9100"

[[package]]
name = "hmac-sha256"
version = "1.1.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ad6880c8d4a9ebf39c6e8b77007ce223f646a4d21ce29d99f70cb16420545425"

[[package]]
name = "http"
version = "0.2.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "601cbb57e577e2f5ef5be8e7b83f0f63994f25aa94d673e54a92d5c516d101f1"
dependencies = [
 "bytes",
 "fnv",
 "itoa",
]

[[package]]
name = "http"
version = "1.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e3ba2a386d7f85a81f119ad7498ebe444d2e22c2af0b86b069416ace48b3311a"
dependencies = [
 "bytes",
 "itoa",
]

[[package]]
name = "http-body"
version = "0.4.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7ceab25649e9960c0311ea418d17bee82c0dcec1bd053b5f9a66e265a693bed2"
dependencies = [
 "bytes",
 "http 0.2.12",
 "pin-project-lite",
]

[[package]]
name = "httparse"
version = "1.10.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6dbf3de79e51f3d586ab4cb9d5c3e2c14aa28ed23d180cf89b4df0454a69cc87"

[[package]]
name = "httpdate"
version = "1.0.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "df3b46402a9d5adb4c86a0cf463f42e19994e3ee891101b1841f30a545cb49a9"

[[package]]
name = "hyper"
version = "0.14.32"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "41dfc780fdec9373c01bae43289ea34c972e40ee3c9f6b3c8801a35f35586ce7"
dependencies = [
 "bytes",
 "futures-channel",
 "futures-core",
 "futures-util",
 "h2",
 "http 0.2.12",
 "http-body",
 "httparse",
 "httpdate",
 "itoa",
 "pin-project-lite",
 "socket2 0.5.10",
 "tokio",
 "tower-service",
 "tracing",
 "want",
]

[[package]]
name = "hyper-tls"
version = "0.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d6183ddfa99b85da61a140bea0efc93fdf56ceaa041b37d553518030827f9905"
dependencies = [
 "bytes",
 "hyper",
 "native-tls",
 "tokio",
 "tokio-native-tls",
]

[[package]]
name = "iana-time-zone"
version = "0.1.64"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "33e57f83510bb73707521ebaffa789ec8caf86f9657cad665b092b581d40e9fb"
dependencies = [
 "android_system_properties",
 "core-foundation-sys",
 "iana-time-zone-haiku",
 "js-sys",
 "log",
 "wasm-bindgen",
 "windows-core",
]

[[package]]
name = "iana-time-zone-haiku"
version = "0.1.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f31827a206f56af32e590ba56d5d2d085f558508192593743f16b2306495269f"
dependencies = [
 "cc",
]

[[package]]
name = "icu_collections"
version = "2.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4c6b649701667bbe825c3b7e6388cb521c23d88644678e83c0c4d0a621a34b43"
dependencies = [
 "displaydoc",
 "potential_utf",
 "yoke",
 "zerofrom",
 "zerovec",
]

[[package]]
name = "icu_locale_core"
version = "2.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "edba7861004dd3714265b4db54a3c390e880ab658fec5f7db895fae2046b5bb6"
dependencies = [
 "displaydoc",
 "litemap",
 "tinystr",
 "writeable",
 "zerovec",
]

[[package]]
name = "icu_normalizer"
version = "2.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5f6c8828b67bf8908d82127b2054ea1b4427ff0230ee9141c54251934ab1b599"
dependencies = [
 "icu_collections",
 "icu_normalizer_data",
 "icu_properties",
 "icu_provider",
 "smallvec",
 "zerovec",
]

[[package]]
name = "icu_normalizer_data"
version = "2.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7aedcccd01fc5fe81e6b489c15b247b8b0690feb23304303a9e560f37efc560a"

[[package]]
name = "icu_properties"
version = "2.1.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "020bfc02fe870ec3a66d93e677ccca0562506e5872c650f893269e08615d74ec"
dependencies = [
 "icu_collections",
 "icu_locale_core",
 "icu_properties_data",
 "icu_provider",
 "zerotrie",
 "zerovec",
]

[[package]]
name = "icu_properties_data"
version = "2.1.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "616c294cf8d725c6afcd8f55abc17c56464ef6211f9ed59cccffe534129c77af"

[[package]]
name = "icu_provider"
version = "2.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "85962cf0ce02e1e0a629cc34e7ca3e373ce20dda4c4d7294bbd0bf1fdb59e614"
dependencies = [
 "displaydoc",
 "icu_locale_core",
 "writeable",
 "yoke",
 "zerofrom",
 "zerotrie",
 "zerovec",
]

[[package]]
name = "idna"
version = "1.1.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3b0875f23caa03898994f6ddc501886a45c7d3d62d04d2d90788d47be1b1e4de"
dependencies = [
 "idna_adapter",
 "smallvec",
 "utf8_iter",
]

[[package]]
name = "idna_adapter"
version = "1.2.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3acae9609540aa318d1bc588455225fb2085b9ed0c4f6bd0d9d5bcd86f1a0344"
dependencies = [
 "icu_normalizer",
 "icu_properties",
]

[[package]]
name = "image"
version = "0.25.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e6506c6c10786659413faa717ceebcb8f70731c0a60cbae39795fdf114519c1a"
dependencies = [
 "bytemuck",
 "byteorder-lite",
 "color_quant",
 "exr",
 "gif",
 "image-webp",
 "moxcms",
 "num-traits",
 "png",
 "qoi",
 "ravif",
 "rayon",
 "rgb",
 "tiff",
 "zune-core 0.5.0",
 "zune-jpeg 0.5.8",
]

[[package]]
name = "image-webp"
version = "0.2.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "525e9ff3e1a4be2fbea1fdf0e98686a6d98b4d8f937e1bf7402245af1909e8c3"
dependencies = [
 "byteorder-lite",
 "quick-error",
]

[[package]]
name = "imgref"
version = "1.12.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e7c5cedc30da3a610cac6b4ba17597bdf7152cf974e8aab3afb3d54455e371c8"

[[package]]
name = "indexmap"
version = "2.13.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7714e70437a7dc3ac8eb7e6f8df75fd8eb422675fc7678aff7364301092b1017"
dependencies = [
 "equivalent",
 "hashbrown",
]

[[package]]
name = "interpolate_name"
version = "0.2.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c34819042dc3d3971c46c2190835914dfbe0c3c13f61449b2997f4e9722dfa60"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "ipnet"
version = "2.11.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "469fb0b9cefa57e3ef31275ee7cacb78f2fdca44e4765491884a2b119d4eb130"

[[package]]
name = "itertools"
version = "0.14.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2b192c782037fadd9cfa75548310488aabdbf3d2da73885b31bd0abd03351285"
dependencies = [
 "either",
]

[[package]]
name = "itoa"
version = "1.0.17"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "92ecc6618181def0457392ccd0ee51198e065e016d1d527a7ac1b6dc7c1f09d2"

[[package]]
name = "jobserver"
version = "0.1.34"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9afb3de4395d6b3e67a780b6de64b51c978ecf11cb9a462c66be7d4ca9039d33"
dependencies = [
 "getrandom",
 "libc",
]

[[package]]
name = "js-sys"
version = "0.3.83"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "464a3709c7f55f1f721e5389aa6ea4e3bc6aba669353300af094b29ffbdde1d8"
dependencies = [
 "once_cell",
 "wasm-bindgen",
]

[[package]]
name = "lazy_static"
version = "1.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bbd2bcb4c963f2ddae06a2efc7e9f3591312473c50c6685e1f298068316e66fe"

[[package]]
name = "lebe"
version = "0.5.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7a79a3332a6609480d7d0c9eab957bca6b455b91bb84e66d19f5ff66294b85b8"

[[package]]
name = "libc"
version = "0.2.179"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c5a2d376baa530d1238d133232d15e239abad80d05838b4b59354e5268af431f"

[[package]]
name = "libfuzzer-sys"
version = "0.4.10"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5037190e1f70cbeef565bd267599242926f724d3b8a9f510fd7e0b540cfa4404"
dependencies = [
 "arbitrary",
 "cc",
]

[[package]]
name = "linux-raw-sys"
version = "0.11.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "df1d3c3b53da64cf5760482273a98e575c651a67eec7f77df96b5b642de8f039"

[[package]]
name = "litemap"
version = "0.8.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6373607a59f0be73a39b6fe456b8192fcc3585f602af20751600e974dd455e77"

[[package]]
name = "lock_api"
version = "0.4.14"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "224399e74b87b5f3557511d98dff8b14089b3dadafcab6bb93eab67d3aace965"
dependencies = [
 "scopeguard",
]

[[package]]
name = "log"
version = "0.4.29"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5e5032e24019045c762d3c0f28f5b6b8bbf38563a65908389bf7978758920897"

[[package]]
name = "loop9"
version = "0.1.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0fae87c125b03c1d2c0150c90365d7d6bcc53fb73a9acaef207d2d065860f062"
dependencies = [
 "imgref",
]

[[package]]
name = "lzma-rust2"
version = "0.15.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "17f7337d278fec032975dc884152491580dd23750ee957047856735fe0e61ede"

[[package]]
name = "matchers"
version = "0.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d1525a2a28c7f4fa0fc98bb91ae755d1e2d1505079e05539e35bc876b5d65ae9"
dependencies = [
 "regex-automata",
]

[[package]]
name = "matrixmultiply"
version = "0.3.10"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a06de3016e9fae57a36fd14dba131fccf49f74b40b7fbdb472f96e361ec71a08"
dependencies = [
 "autocfg",
 "rawpointer",
]

[[package]]
name = "maybe-rayon"
version = "0.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8ea1f30cedd69f0a2954655f7188c6a834246d2bcf1e315e2ac40c4b24dc9519"
dependencies = [
 "cfg-if",
 "rayon",
]

[[package]]
name = "memchr"
version = "2.7.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f52b00d39961fc5b2736ea853c9cc86238e165017a493d1d5c8eac6bdc4cc273"

[[package]]
name = "mime"
version = "0.3.17"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6877bb514081ee2a7ff5ef9de3281f14a4dd4bceac4c09388074a6b5df8a139a"

[[package]]
name = "miniz_oxide"
version = "0.8.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1fa76a2c86f704bdb222d66965fb3d63269ce38518b83cb0575fca855ebb6316"
dependencies = [
 "adler2",
 "simd-adler32",
]

[[package]]
name = "mio"
version = "1.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a69bcab0ad47271a0234d9422b131806bf3968021e5dc9328caf2d4cd58557fc"
dependencies = [
 "libc",
 "wasi",
 "windows-sys 0.61.2",
]

[[package]]
name = "moxcms"
version = "0.7.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ac9557c559cd6fc9867e122e20d2cbefc9ca29d80d027a8e39310920ed2f0a97"
dependencies = [
 "num-traits",
 "pxfm",
]

[[package]]
name = "native-tls"
version = "0.2.14"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "87de3442987e9dbec73158d5c715e7ad9072fda936bb03d19d7fa10e00520f0e"
dependencies = [
 "libc",
 "log",
 "openssl",
 "openssl-probe",
 "openssl-sys",
 "schannel",
 "security-framework",
 "security-framework-sys",
 "tempfile",
]

[[package]]
name = "ndarray"
version = "0.15.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "adb12d4e967ec485a5f71c6311fe28158e9d6f4bc4a447b474184d0f91a8fa32"
dependencies = [
 "matrixmultiply",
 "num-complex",
 "num-integer",
 "num-traits",
 "rawpointer",
]

[[package]]
name = "ndarray"
version = "0.17.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0c7c9125e8f6f10c9da3aad044cc918cf8784fa34de857b1aa68038eb05a50a9"
dependencies = [
 "matrixmultiply",
 "num-complex",
 "num-integer",
 "num-traits",
 "portable-atomic",
 "portable-atomic-util",
 "rawpointer",
]

[[package]]
name = "new_debug_unreachable"
version = "1.0.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "650eef8c711430f1a879fdd01d4745a7deea475becfb90269c06775983bbf086"

[[package]]
name = "nom"
version = "8.0.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "df9761775871bdef83bee530e60050f7e54b1105350d6884eb0fb4f46c2f9405"
dependencies = [
 "memchr",
]

[[package]]
name = "noop_proc_macro"
version = "0.3.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0676bb32a98c1a483ce53e500a81ad9c3d5b3f7c920c28c24e9cb0980d0b5bc8"

[[package]]
name = "nu-ansi-term"
version = "0.50.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7957b9740744892f114936ab4a57b3f487491bbeafaf8083688b16841a4240e5"
dependencies = [
 "windows-sys 0.61.2",
]

[[package]]
name = "num-bigint"
version = "0.4.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a5e44f723f1133c9deac646763579fdb3ac745e418f2a7af9cd0c431da1f20b9"
dependencies = [
 "num-integer",
 "num-traits",
]

[[package]]
name = "num-complex"
version = "0.4.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "73f88a1307638156682bada9d7604135552957b7818057dcef22705b4d509495"
dependencies = [
 "num-traits",
]

[[package]]
name = "num-derive"
version = "0.4.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ed3955f1a9c7c0c15e092f9c887db08b1fc683305fdf6eb6684f22555355e202"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "num-integer"
version = "0.1.46"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7969661fd2958a5cb096e56c8e1ad0444ac2bbcd0061bd28660485a44879858f"
dependencies = [
 "num-traits",
]

[[package]]
name = "num-rational"
version = "0.4.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f83d14da390562dca69fc84082e73e548e1ad308d24accdedd2720017cb37824"
dependencies = [
 "num-bigint",
 "num-integer",
 "num-traits",
]

[[package]]
name = "num-traits"
version = "0.2.19"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "071dfc062690e90b734c0b2273ce72ad0ffa95f0c74596bc250dcfd960262841"
dependencies = [
 "autocfg",
]

[[package]]
name = "once_cell"
version = "1.21.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "42f5e15c9953c5e4ccceeb2e7382a716482c34515315f7b03532b8b4e8393d2d"

[[package]]
name = "opencv"
version = "0.91.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e64b5a733be752a917aa27981c1100fbc7836cf2cfe3fb06f5cac691339837b7"
dependencies = [
 "cc",
 "dunce",
 "jobserver",
 "libc",
 "num-traits",
 "once_cell",
 "opencv-binding-generator",
 "pkg-config",
 "rgb",
 "semver",
 "shlex",
 "vcpkg",
 "windows",
]

[[package]]
name = "opencv-binding-generator"
version = "0.89.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "81af1298c489597ffdbadc7710673ec26f8a2440228992681ffa3b8f00233bd9"
dependencies = [
 "clang",
 "clang-sys",
 "dunce",
 "once_cell",
 "percent-encoding",
 "regex",
]

[[package]]
name = "openssl"
version = "0.10.75"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "08838db121398ad17ab8531ce9de97b244589089e290a384c900cb9ff7434328"
dependencies = [
 "bitflags 2.10.0",
 "cfg-if",
 "foreign-types",
 "libc",
 "once_cell",
 "openssl-macros",
 "openssl-sys",
]

[[package]]
name = "openssl-macros"
version = "0.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a948666b637a0f465e8564c73e89d4dde00d72d4d473cc972f390fc3dcee7d9c"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "openssl-probe"
version = "0.1.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d05e27ee213611ffe7d6348b942e8f942b37114c00cc03cec254295a4a17852e"

[[package]]
name = "openssl-sys"
version = "0.9.111"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "82cab2d520aa75e3c58898289429321eb788c3106963d0dc886ec7a5f4adc321"
dependencies = [
 "cc",
 "libc",
 "pkg-config",
 "vcpkg",
]

[[package]]
name = "ort"
version = "2.0.0-rc.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4a5df903c0d2c07b56950f1058104ab0c8557159f2741782223704de9be73c3c"
dependencies = [
 "ndarray 0.17.1",
 "ort-sys",
 "smallvec",
 "tracing",
 "ureq",
]

[[package]]
name = "ort-sys"
version = "2.0.0-rc.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "06503bb33f294c5f1ba484011e053bfa6ae227074bdb841e9863492dc5960d4b"
dependencies = [
 "hmac-sha256",
 "lzma-rust2",
 "ureq",
]

[[package]]
name = "overtake-detection"
version = "0.1.0"
dependencies = [
 "anyhow",
 "base64 0.22.1",
 "chrono",
 "image",
 "ndarray 0.15.6",
 "opencv",
 "ort",
 "reqwest",
 "serde",
 "serde_json",
 "serde_yaml",
 "thiserror 1.0.69",
 "tokio",
 "tracing",
 "tracing-subscriber",
 "uuid",
 "walkdir",
]

[[package]]
name = "parking_lot"
version = "0.12.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "93857453250e3077bd71ff98b6a65ea6621a19bb0f559a85248955ac12c45a1a"
dependencies = [
 "lock_api",
 "parking_lot_core",
]

[[package]]
name = "parking_lot_core"
version = "0.9.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2621685985a2ebf1c516881c026032ac7deafcda1a2c9b7850dc81e3dfcb64c1"
dependencies = [
 "cfg-if",
 "libc",
 "redox_syscall",
 "smallvec",
 "windows-link",
]

[[package]]
name = "paste"
version = "1.0.15"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "57c0d7b74b563b49d38dae00a0c37d4d6de9b432382b2892f0574ddcae73fd0a"

[[package]]
name = "pastey"
version = "0.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "35fb2e5f958ec131621fdd531e9fc186ed768cbe395337403ae56c17a74c68ec"

[[package]]
name = "pem-rfc7468"
version = "0.7.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "88b39c9bfcfc231068454382784bb460aae594343fb030d46e9f50a645418412"
dependencies = [
 "base64ct",
]

[[package]]
name = "percent-encoding"
version = "2.3.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9b4f627cb1b25917193a259e49bdad08f671f8d9708acfd5fe0a8c1455d87220"

[[package]]
name = "pin-project-lite"
version = "0.2.16"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3b3cff922bd51709b605d9ead9aa71031d81447142d828eb4a6eba76fe619f9b"

[[package]]
name = "pin-utils"
version = "0.1.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8b870d8c151b6f2fb93e84a13146138f05d02ed11c7e7c54f8826aaaf7c9f184"

[[package]]
name = "pkg-config"
version = "0.3.32"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7edddbd0b52d732b21ad9a5fab5c704c14cd949e5e9a1ec5929a24fded1b904c"

[[package]]
name = "png"
version = "0.18.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "97baced388464909d42d89643fe4361939af9b7ce7a31ee32a168f832a70f2a0"
dependencies = [
 "bitflags 2.10.0",
 "crc32fast",
 "fdeflate",
 "flate2",
 "miniz_oxide",
]

[[package]]
name = "portable-atomic"
version = "1.13.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f89776e4d69bb58bc6993e99ffa1d11f228b839984854c7daeb5d37f87cbe950"

[[package]]
name = "portable-atomic-util"
version = "0.2.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d8a2f0d8d040d7848a709caf78912debcc3f33ee4b3cac47d73d1e1069e83507"
dependencies = [
 "portable-atomic",
]

[[package]]
name = "potential_utf"
version = "0.1.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b73949432f5e2a09657003c25bca5e19a0e9c84f8058ca374f49e0ebe605af77"
dependencies = [
 "zerovec",
]

[[package]]
name = "ppv-lite86"
version = "0.2.21"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "85eae3c4ed2f50dcfe72643da4befc30deadb458a9b590d720cde2f2b1e97da9"
dependencies = [
 "zerocopy",
]

[[package]]
name = "proc-macro2"
version = "1.0.105"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "535d180e0ecab6268a3e718bb9fd44db66bbbc256257165fc699dadf70d16fe7"
dependencies = [
 "unicode-ident",
]

[[package]]
name = "profiling"
version = "1.0.17"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3eb8486b569e12e2c32ad3e204dbaba5e4b5b216e9367044f25f1dba42341773"
dependencies = [
 "profiling-procmacros",
]

[[package]]
name = "profiling-procmacros"
version = "1.0.17"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "52717f9a02b6965224f95ca2a81e2e0c5c43baacd28ca057577988930b6c3d5b"
dependencies = [
 "quote",
 "syn",
]

[[package]]
name = "pxfm"
version = "0.1.27"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7186d3822593aa4393561d186d1393b3923e9d6163d3fbfd6e825e3e6cf3e6a8"
dependencies = [
 "num-traits",
]

[[package]]
name = "qoi"
version = "0.4.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7f6d64c71eb498fe9eae14ce4ec935c555749aef511cca85b5568910d6e48001"
dependencies = [
 "bytemuck",
]

[[package]]
name = "quick-error"
version = "2.0.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a993555f31e5a609f617c12db6250dedcac1b0a85076912c436e6fc9b2c8e6a3"

[[package]]
name = "quote"
version = "1.0.43"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "dc74d9a594b72ae6656596548f56f667211f8a97b3d4c3d467150794690dc40a"
dependencies = [
 "proc-macro2",
]

[[package]]
name = "r-efi"
version = "5.3.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "69cdb34c158ceb288df11e18b4bd39de994f6657d83847bdffdbd7f346754b0f"

[[package]]
name = "rand"
version = "0.9.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6db2770f06117d490610c7488547d543617b21bfa07796d7a12f6f1bd53850d1"
dependencies = [
 "rand_chacha",
 "rand_core",
]

[[package]]
name = "rand_chacha"
version = "0.9.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d3022b5f1df60f26e1ffddd6c66e8aa15de382ae63b3a0c1bfc0e4d3e3f325cb"
dependencies = [
 "ppv-lite86",
 "rand_core",
]

[[package]]
name = "rand_core"
version = "0.9.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4f1b3bc831f92381018fd9c6350b917c7b21f1eed35a65a51900e0e55a3d7afa"
dependencies = [
 "getrandom",
]

[[package]]
name = "rav1e"
version = "0.8.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "43b6dd56e85d9483277cde964fd1bdb0428de4fec5ebba7540995639a21cb32b"
dependencies = [
 "aligned-vec",
 "arbitrary",
 "arg_enum_proc_macro",
 "arrayvec",
 "av-scenechange",
 "av1-grain",
 "bitstream-io",
 "built",
 "cfg-if",
 "interpolate_name",
 "itertools",
 "libc",
 "libfuzzer-sys",
 "log",
 "maybe-rayon",
 "new_debug_unreachable",
 "noop_proc_macro",
 "num-derive",
 "num-traits",
 "paste",
 "profiling",
 "rand",
 "rand_chacha",
 "simd_helpers",
 "thiserror 2.0.17",
 "v_frame",
 "wasm-bindgen",
]

[[package]]
name = "ravif"
version = "0.12.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ef69c1990ceef18a116855938e74793a5f7496ee907562bd0857b6ac734ab285"
dependencies = [
 "avif-serialize",
 "imgref",
 "loop9",
 "quick-error",
 "rav1e",
 "rayon",
 "rgb",
]

[[package]]
name = "rawpointer"
version = "0.2.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "60a357793950651c4ed0f3f52338f53b2f809f32d83a07f72909fa13e4c6c1e3"

[[package]]
name = "rayon"
version = "1.11.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "368f01d005bf8fd9b1206fb6fa653e6c4a81ceb1466406b81792d87c5677a58f"
dependencies = [
 "either",
 "rayon-core",
]

[[package]]
name = "rayon-core"
version = "1.13.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "22e18b0f0062d30d4230b2e85ff77fdfe4326feb054b9783a3460d8435c8ab91"
dependencies = [
 "crossbeam-deque",
 "crossbeam-utils",
]

[[package]]
name = "redox_syscall"
version = "0.5.18"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ed2bf2547551a7053d6fdfafda3f938979645c44812fbfcda098faae3f1a362d"
dependencies = [
 "bitflags 2.10.0",
]

[[package]]
name = "regex"
version = "1.12.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "843bc0191f75f3e22651ae5f1e72939ab2f72a4bc30fa80a066bd66edefc24d4"
dependencies = [
 "aho-corasick",
 "memchr",
 "regex-automata",
 "regex-syntax",
]

[[package]]
name = "regex-automata"
version = "0.4.13"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5276caf25ac86c8d810222b3dbb938e512c55c6831a10f3e6ed1c93b84041f1c"
dependencies = [
 "aho-corasick",
 "memchr",
 "regex-syntax",
]

[[package]]
name = "regex-syntax"
version = "0.8.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7a2d987857b319362043e95f5353c0535c1f58eec5336fdfcf626430af7def58"

[[package]]
name = "reqwest"
version = "0.11.27"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "dd67538700a17451e7cba03ac727fb961abb7607553461627b97de0b89cf4a62"
dependencies = [
 "base64 0.21.7",
 "bytes",
 "encoding_rs",
 "futures-core",
 "futures-util",
 "h2",
 "http 0.2.12",
 "http-body",
 "hyper",
 "hyper-tls",
 "ipnet",
 "js-sys",
 "log",
 "mime",
 "native-tls",
 "once_cell",
 "percent-encoding",
 "pin-project-lite",
 "rustls-pemfile",
 "serde",
 "serde_json",
 "serde_urlencoded",
 "sync_wrapper",
 "system-configuration",
 "tokio",
 "tokio-native-tls",
 "tower-service",
 "url",
 "wasm-bindgen",
 "wasm-bindgen-futures",
 "web-sys",
 "winreg",
]

[[package]]
name = "rgb"
version = "0.8.52"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0c6a884d2998352bb4daf0183589aec883f16a6da1f4dde84d8e2e9a5409a1ce"
dependencies = [
 "bytemuck",
]

[[package]]
name = "rustix"
version = "1.1.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "146c9e247ccc180c1f61615433868c99f3de3ae256a30a43b49f67c2d9171f34"
dependencies = [
 "bitflags 2.10.0",
 "errno",
 "libc",
 "linux-raw-sys",
 "windows-sys 0.61.2",
]

[[package]]
name = "rustls-pemfile"
version = "1.0.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1c74cae0a4cf6ccbbf5f359f08efdf8ee7e1dc532573bf0db71968cb56b1448c"
dependencies = [
 "base64 0.21.7",
]

[[package]]
name = "rustls-pki-types"
version = "1.13.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "21e6f2ab2928ca4291b86736a8bd920a277a399bba1589409d72154ff87c1282"
dependencies = [
 "zeroize",
]

[[package]]
name = "rustversion"
version = "1.0.22"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b39cdef0fa800fc44525c84ccb54a029961a8215f9619753635a9c0d2538d46d"

[[package]]
name = "ryu"
version = "1.0.22"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a50f4cf475b65d88e057964e0e9bb1f0aa9bbb2036dc65c64596b42932536984"

[[package]]
name = "same-file"
version = "1.0.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "93fc1dc3aaa9bfed95e02e6eadabb4baf7e3078b0bd1b4d7b6b0b68378900502"
dependencies = [
 "winapi-util",
]

[[package]]
name = "schannel"
version = "0.1.28"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "891d81b926048e76efe18581bf793546b4c0eaf8448d72be8de2bbee5fd166e1"
dependencies = [
 "windows-sys 0.61.2",
]

[[package]]
name = "scopeguard"
version = "1.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "94143f37725109f92c262ed2cf5e59bce7498c01bcc1502d7b9afe439a4e9f49"

[[package]]
name = "security-framework"
version = "2.11.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "897b2245f0b511c87893af39b033e5ca9cce68824c4d7e7630b5a1d339658d02"
dependencies = [
 "bitflags 2.10.0",
 "core-foundation",
 "core-foundation-sys",
 "libc",
 "security-framework-sys",
]

[[package]]
name = "security-framework-sys"
version = "2.15.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cc1f0cbffaac4852523ce30d8bd3c5cdc873501d96ff467ca09b6767bb8cd5c0"
dependencies = [
 "core-foundation-sys",
 "libc",
]

[[package]]
name = "semver"
version = "1.0.27"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d767eb0aabc880b29956c35734170f26ed551a859dbd361d140cdbeca61ab1e2"

[[package]]
name = "serde"
version = "1.0.228"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9a8e94ea7f378bd32cbbd37198a4a91436180c5bb472411e48b5ec2e2124ae9e"
dependencies = [
 "serde_core",
 "serde_derive",
]

[[package]]
name = "serde_core"
version = "1.0.228"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "41d385c7d4ca58e59fc732af25c3983b67ac852c1a25000afe1175de458b67ad"
dependencies = [
 "serde_derive",
]

[[package]]
name = "serde_derive"
version = "1.0.228"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d540f220d3187173da220f885ab66608367b6574e925011a9353e4badda91d79"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "serde_json"
version = "1.0.149"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "83fc039473c5595ace860d8c4fafa220ff474b3fc6bfdb4293327f1a37e94d86"
dependencies = [
 "itoa",
 "memchr",
 "serde",
 "serde_core",
 "zmij",
]

[[package]]
name = "serde_urlencoded"
version = "0.7.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d3491c14715ca2294c4d6a88f15e84739788c1d030eed8c110436aafdaa2f3fd"
dependencies = [
 "form_urlencoded",
 "itoa",
 "ryu",
 "serde",
]

[[package]]
name = "serde_yaml"
version = "0.9.34+deprecated"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6a8b1a1a2ebf674015cc02edccce75287f1a0130d394307b36743c2f5d504b47"
dependencies = [
 "indexmap",
 "itoa",
 "ryu",
 "serde",
 "unsafe-libyaml",
]

[[package]]
name = "sharded-slab"
version = "0.1.7"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f40ca3c46823713e0d4209592e8d6e826aa57e928f09752619fc696c499637f6"
dependencies = [
 "lazy_static",
]

[[package]]
name = "shlex"
version = "1.3.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0fda2ff0d084019ba4d7c6f371c95d8fd75ce3524c3cb8fb653a3023f6323e64"

[[package]]
name = "signal-hook-registry"
version = "1.4.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c4db69cba1110affc0e9f7bcd48bbf87b3f4fc7c61fc9155afd4c469eb3d6c1b"
dependencies = [
 "errno",
 "libc",
]

[[package]]
name = "simd-adler32"
version = "0.3.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e320a6c5ad31d271ad523dcf3ad13e2767ad8b1cb8f047f75a8aeaf8da139da2"

[[package]]
name = "simd_helpers"
version = "0.1.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "95890f873bec569a0362c235787f3aca6e1e887302ba4840839bcc6459c42da6"
dependencies = [
 "quote",
]

[[package]]
name = "slab"
version = "0.4.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7a2ae44ef20feb57a68b23d846850f861394c2e02dc425a50098ae8c90267589"

[[package]]
name = "smallvec"
version = "1.15.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "67b1b7a3b5fe4f1376887184045fcf45c69e92af734b7aaddc05fb777b6fbd03"

[[package]]
name = "socket2"
version = "0.5.10"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e22376abed350d73dd1cd119b57ffccad95b4e585a7cda43e286245ce23c0678"
dependencies = [
 "libc",
 "windows-sys 0.52.0",
]

[[package]]
name = "socket2"
version = "0.6.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "17129e116933cf371d018bb80ae557e889637989d8638274fb25622827b03881"
dependencies = [
 "libc",
 "windows-sys 0.60.2",
]

[[package]]
name = "socks"
version = "0.3.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f0c3dbbd9ae980613c6dd8e28a9407b50509d3803b57624d5dfe8315218cd58b"
dependencies = [
 "byteorder",
 "libc",
 "winapi",
]

[[package]]
name = "stable_deref_trait"
version = "1.2.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6ce2be8dc25455e1f91df71bfa12ad37d7af1092ae736f3a6cd0e37bc7810596"

[[package]]
name = "syn"
version = "2.0.114"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d4d107df263a3013ef9b1879b0df87d706ff80f65a86ea879bd9c31f9b307c2a"
dependencies = [
 "proc-macro2",
 "quote",
 "unicode-ident",
]

[[package]]
name = "sync_wrapper"
version = "0.1.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2047c6ded9c721764247e62cd3b03c09ffc529b2ba5b10ec482ae507a4a70160"

[[package]]
name = "synstructure"
version = "0.13.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "728a70f3dbaf5bab7f0c4b1ac8d7ae5ea60a4b5549c8a5914361c99147a709d2"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "system-configuration"
version = "0.5.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ba3a3adc5c275d719af8cb4272ea1c4a6d668a777f37e115f6d11ddbc1c8e0e7"
dependencies = [
 "bitflags 1.3.2",
 "core-foundation",
 "system-configuration-sys",
]

[[package]]
name = "system-configuration-sys"
version = "0.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a75fb188eb626b924683e3b95e3a48e63551fcfb51949de2f06a9d91dbee93c9"
dependencies = [
 "core-foundation-sys",
 "libc",
]

[[package]]
name = "tempfile"
version = "3.24.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "655da9c7eb6305c55742045d5a8d2037996d61d8de95806335c7c86ce0f82e9c"
dependencies = [
 "fastrand",
 "getrandom",
 "once_cell",
 "rustix",
 "windows-sys 0.61.2",
]

[[package]]
name = "thiserror"
version = "1.0.69"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b6aaf5339b578ea85b50e080feb250a3e8ae8cfcdff9a461c9ec2904bc923f52"
dependencies = [
 "thiserror-impl 1.0.69",
]

[[package]]
name = "thiserror"
version = "2.0.17"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f63587ca0f12b72a0600bcba1d40081f830876000bb46dd2337a3051618f4fc8"
dependencies = [
 "thiserror-impl 2.0.17",
]

[[package]]
name = "thiserror-impl"
version = "1.0.69"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4fee6c4efc90059e10f81e6d42c60a18f76588c3d74cb83a0b242a2b6c7504c1"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "thiserror-impl"
version = "2.0.17"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3ff15c8ecd7de3849db632e14d18d2571fa09dfc5ed93479bc4485c7a517c913"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "thread_local"
version = "1.1.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f60246a4944f24f6e018aa17cdeffb7818b76356965d03b07d6a9886e8962185"
dependencies = [
 "cfg-if",
]

[[package]]
name = "tiff"
version = "0.10.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "af9605de7fee8d9551863fd692cce7637f548dbd9db9180fcc07ccc6d26c336f"
dependencies = [
 "fax",
 "flate2",
 "half",
 "quick-error",
 "weezl",
 "zune-jpeg 0.4.21",
]

[[package]]
name = "tinystr"
version = "0.8.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "42d3e9c45c09de15d06dd8acf5f4e0e399e85927b7f00711024eb7ae10fa4869"
dependencies = [
 "displaydoc",
 "zerovec",
]

[[package]]
name = "tokio"
version = "1.49.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "72a2903cd7736441aac9df9d7688bd0ce48edccaadf181c3b90be801e81d3d86"
dependencies = [
 "bytes",
 "libc",
 "mio",
 "parking_lot",
 "pin-project-lite",
 "signal-hook-registry",
 "socket2 0.6.1",
 "tokio-macros",
 "windows-sys 0.61.2",
]

[[package]]
name = "tokio-macros"
version = "2.6.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "af407857209536a95c8e56f8231ef2c2e2aff839b22e07a1ffcbc617e9db9fa5"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "tokio-native-tls"
version = "0.3.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bbae76ab933c85776efabc971569dd6119c580d8f5d448769dec1764bf796ef2"
dependencies = [
 "native-tls",
 "tokio",
]

[[package]]
name = "tokio-util"
version = "0.7.18"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9ae9cec805b01e8fc3fd2fe289f89149a9b66dd16786abd8b19cfa7b48cb0098"
dependencies = [
 "bytes",
 "futures-core",
 "futures-sink",
 "pin-project-lite",
 "tokio",
]

[[package]]
name = "tower-service"
version = "0.3.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8df9b6e13f2d32c91b9bd719c00d1958837bc7dec474d94952798cc8e69eeec3"

[[package]]
name = "tracing"
version = "0.1.44"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "63e71662fa4b2a2c3a26f570f037eb95bb1f85397f3cd8076caed2f026a6d100"
dependencies = [
 "pin-project-lite",
 "tracing-attributes",
 "tracing-core",
]

[[package]]
name = "tracing-attributes"
version = "0.1.31"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7490cfa5ec963746568740651ac6781f701c9c5ea257c58e057f3ba8cf69e8da"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "tracing-core"
version = "0.1.36"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "db97caf9d906fbde555dd62fa95ddba9eecfd14cb388e4f491a66d74cd5fb79a"
dependencies = [
 "once_cell",
 "valuable",
]

[[package]]
name = "tracing-log"
version = "0.2.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ee855f1f400bd0e5c02d150ae5de3840039a3f54b025156404e34c23c03f47c3"
dependencies = [
 "log",
 "once_cell",
 "tracing-core",
]

[[package]]
name = "tracing-subscriber"
version = "0.3.22"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2f30143827ddab0d256fd843b7a66d164e9f271cfa0dde49142c5ca0ca291f1e"
dependencies = [
 "matchers",
 "nu-ansi-term",
 "once_cell",
 "regex-automata",
 "sharded-slab",
 "smallvec",
 "thread_local",
 "tracing",
 "tracing-core",
 "tracing-log",
]

[[package]]
name = "try-lock"
version = "0.2.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e421abadd41a4225275504ea4d6566923418b7f05506fbc9c0fe86ba7396114b"

[[package]]
name = "unicode-ident"
version = "1.0.22"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9312f7c4f6ff9069b165498234ce8be658059c6728633667c526e27dc2cf1df5"

[[package]]
name = "unsafe-libyaml"
version = "0.2.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "673aac59facbab8a9007c7f6108d11f63b603f7cabff99fabf650fea5c32b861"

[[package]]
name = "ureq"
version = "3.1.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d39cb1dbab692d82a977c0392ffac19e188bd9186a9f32806f0aaa859d75585a"
dependencies = [
 "base64 0.22.1",
 "der",
 "log",
 "native-tls",
 "percent-encoding",
 "rustls-pki-types",
 "socks",
 "ureq-proto",
 "utf-8",
 "webpki-root-certs",
]

[[package]]
name = "ureq-proto"
version = "0.5.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d81f9efa9df032be5934a46a068815a10a042b494b6a58cb0a1a97bb5467ed6f"
dependencies = [
 "base64 0.22.1",
 "http 1.4.0",
 "httparse",
 "log",
]

[[package]]
name = "url"
version = "2.5.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ff67a8a4397373c3ef660812acab3268222035010ab8680ec4215f38ba3d0eed"
dependencies = [
 "form_urlencoded",
 "idna",
 "percent-encoding",
 "serde",
]

[[package]]
name = "utf-8"
version = "0.7.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "09cc8ee72d2a9becf2f2febe0205bbed8fc6615b7cb429ad062dc7b7ddd036a9"

[[package]]
name = "utf8_iter"
version = "1.0.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b6c140620e7ffbb22c2dee59cafe6084a59b5ffc27a8859a5f0d494b5d52b6be"

[[package]]
name = "uuid"
version = "1.19.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e2e054861b4bd027cd373e18e8d8d8e6548085000e41290d95ce0c373a654b4a"
dependencies = [
 "getrandom",
 "js-sys",
 "wasm-bindgen",
]

[[package]]
name = "v_frame"
version = "0.3.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "666b7727c8875d6ab5db9533418d7c764233ac9c0cff1d469aec8fa127597be2"
dependencies = [
 "aligned-vec",
 "num-traits",
 "wasm-bindgen",
]

[[package]]
name = "valuable"
version = "0.1.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ba73ea9cf16a25df0c8caa16c51acb937d5712a8429db78a3ee29d5dcacd3a65"

[[package]]
name = "vcpkg"
version = "0.2.15"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "accd4ea62f7bb7a82fe23066fb0957d48ef677f6eeb8215f372f52e48bb32426"

[[package]]
name = "walkdir"
version = "2.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "29790946404f91d9c5d06f9874efddea1dc06c5efe94541a7d6863108e3a5e4b"
dependencies = [
 "same-file",
 "winapi-util",
]

[[package]]
name = "want"
version = "0.3.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "bfa7760aed19e106de2c7c0b581b509f2f25d3dacaf737cb82ac61bc6d760b0e"
dependencies = [
 "try-lock",
]

[[package]]
name = "wasi"
version = "0.11.1+wasi-snapshot-preview1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ccf3ec651a847eb01de73ccad15eb7d99f80485de043efb2f370cd654f4ea44b"

[[package]]
name = "wasip2"
version = "1.0.1+wasi-0.2.4"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0562428422c63773dad2c345a1882263bbf4d65cf3f42e90921f787ef5ad58e7"
dependencies = [
 "wit-bindgen",
]

[[package]]
name = "wasm-bindgen"
version = "0.2.106"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0d759f433fa64a2d763d1340820e46e111a7a5ab75f993d1852d70b03dbb80fd"
dependencies = [
 "cfg-if",
 "once_cell",
 "rustversion",
 "wasm-bindgen-macro",
 "wasm-bindgen-shared",
]

[[package]]
name = "wasm-bindgen-futures"
version = "0.4.56"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "836d9622d604feee9e5de25ac10e3ea5f2d65b41eac0d9ce72eb5deae707ce7c"
dependencies = [
 "cfg-if",
 "js-sys",
 "once_cell",
 "wasm-bindgen",
 "web-sys",
]

[[package]]
name = "wasm-bindgen-macro"
version = "0.2.106"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "48cb0d2638f8baedbc542ed444afc0644a29166f1595371af4fecf8ce1e7eeb3"
dependencies = [
 "quote",
 "wasm-bindgen-macro-support",
]

[[package]]
name = "wasm-bindgen-macro-support"
version = "0.2.106"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cefb59d5cd5f92d9dcf80e4683949f15ca4b511f4ac0a6e14d4e1ac60c6ecd40"
dependencies = [
 "bumpalo",
 "proc-macro2",
 "quote",
 "syn",
 "wasm-bindgen-shared",
]

[[package]]
name = "wasm-bindgen-shared"
version = "0.2.106"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "cbc538057e648b67f72a982e708d485b2efa771e1ac05fec311f9f63e5800db4"
dependencies = [
 "unicode-ident",
]

[[package]]
name = "web-sys"
version = "0.3.83"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9b32828d774c412041098d182a8b38b16ea816958e07cf40eec2bc080ae137ac"
dependencies = [
 "js-sys",
 "wasm-bindgen",
]

[[package]]
name = "webpki-root-certs"
version = "1.0.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "36a29fc0408b113f68cf32637857ab740edfafdf460c326cd2afaa2d84cc05dc"
dependencies = [
 "rustls-pki-types",
]

[[package]]
name = "weezl"
version = "0.1.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a28ac98ddc8b9274cb41bb4d9d4d5c425b6020c50c46f25559911905610b4a88"

[[package]]
name = "winapi"
version = "0.3.9"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5c839a674fcd7a98952e593242ea400abe93992746761e38641405d28b00f419"
dependencies = [
 "winapi-i686-pc-windows-gnu",
 "winapi-x86_64-pc-windows-gnu",
]

[[package]]
name = "winapi-i686-pc-windows-gnu"
version = "0.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ac3b87c63620426dd9b991e5ce0329eff545bccbbb34f3be09ff6fb6ab51b7b6"

[[package]]
name = "winapi-util"
version = "0.1.11"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "c2a7b1c03c876122aa43f3020e6c3c3ee5c05081c9a00739faf7503aeba10d22"
dependencies = [
 "windows-sys 0.61.2",
]

[[package]]
name = "winapi-x86_64-pc-windows-gnu"
version = "0.4.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "712e227841d057c1ee1cd2fb22fa7e5a5461ae8e48fa2ca79ec42cfc1931183f"

[[package]]
name = "windows"
version = "0.56.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1de69df01bdf1ead2f4ac895dc77c9351aefff65b2f3db429a343f9cbf05e132"
dependencies = [
 "windows-core",
 "windows-targets 0.52.6",
]

[[package]]
name = "windows-core"
version = "0.56.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4698e52ed2d08f8658ab0c39512a7c00ee5fe2688c65f8c0a4f06750d729f2a6"
dependencies = [
 "windows-implement",
 "windows-interface",
 "windows-result",
 "windows-targets 0.52.6",
]

[[package]]
name = "windows-implement"
version = "0.56.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f6fc35f58ecd95a9b71c4f2329b911016e6bec66b3f2e6a4aad86bd2e99e2f9b"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "windows-interface"
version = "0.56.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "08990546bf4edef8f431fa6326e032865f27138718c587dc21bc0265bbcb57cc"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "windows-link"
version = "0.2.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f0805222e57f7521d6a62e36fa9163bc891acd422f971defe97d64e70d0a4fe5"

[[package]]
name = "windows-result"
version = "0.1.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "5e383302e8ec8515204254685643de10811af0ed97ea37210dc26fb0032647f8"
dependencies = [
 "windows-targets 0.52.6",
]

[[package]]
name = "windows-sys"
version = "0.48.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "677d2418bec65e3338edb076e806bc1ec15693c5d0104683f2efe857f61056a9"
dependencies = [
 "windows-targets 0.48.5",
]

[[package]]
name = "windows-sys"
version = "0.52.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "282be5f36a8ce781fad8c8ae18fa3f9beff57ec1b52cb3de0789201425d9a33d"
dependencies = [
 "windows-targets 0.52.6",
]

[[package]]
name = "windows-sys"
version = "0.60.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f2f500e4d28234f72040990ec9d39e3a6b950f9f22d3dba18416c35882612bcb"
dependencies = [
 "windows-targets 0.53.5",
]

[[package]]
name = "windows-sys"
version = "0.61.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ae137229bcbd6cdf0f7b80a31df61766145077ddf49416a728b02cb3921ff3fc"
dependencies = [
 "windows-link",
]

[[package]]
name = "windows-targets"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9a2fa6e2155d7247be68c096456083145c183cbbbc2764150dda45a87197940c"
dependencies = [
 "windows_aarch64_gnullvm 0.48.5",
 "windows_aarch64_msvc 0.48.5",
 "windows_i686_gnu 0.48.5",
 "windows_i686_msvc 0.48.5",
 "windows_x86_64_gnu 0.48.5",
 "windows_x86_64_gnullvm 0.48.5",
 "windows_x86_64_msvc 0.48.5",
]

[[package]]
name = "windows-targets"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9b724f72796e036ab90c1021d4780d4d3d648aca59e491e6b98e725b84e99973"
dependencies = [
 "windows_aarch64_gnullvm 0.52.6",
 "windows_aarch64_msvc 0.52.6",
 "windows_i686_gnu 0.52.6",
 "windows_i686_gnullvm 0.52.6",
 "windows_i686_msvc 0.52.6",
 "windows_x86_64_gnu 0.52.6",
 "windows_x86_64_gnullvm 0.52.6",
 "windows_x86_64_msvc 0.52.6",
]

[[package]]
name = "windows-targets"
version = "0.53.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "4945f9f551b88e0d65f3db0bc25c33b8acea4d9e41163edf90dcd0b19f9069f3"
dependencies = [
 "windows-link",
 "windows_aarch64_gnullvm 0.53.1",
 "windows_aarch64_msvc 0.53.1",
 "windows_i686_gnu 0.53.1",
 "windows_i686_gnullvm 0.53.1",
 "windows_i686_msvc 0.53.1",
 "windows_x86_64_gnu 0.53.1",
 "windows_x86_64_gnullvm 0.53.1",
 "windows_x86_64_msvc 0.53.1",
]

[[package]]
name = "windows_aarch64_gnullvm"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2b38e32f0abccf9987a4e3079dfb67dcd799fb61361e53e2882c3cbaf0d905d8"

[[package]]
name = "windows_aarch64_gnullvm"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "32a4622180e7a0ec044bb555404c800bc9fd9ec262ec147edd5989ccd0c02cd3"

[[package]]
name = "windows_aarch64_gnullvm"
version = "0.53.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a9d8416fa8b42f5c947f8482c43e7d89e73a173cead56d044f6a56104a6d1b53"

[[package]]
name = "windows_aarch64_msvc"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "dc35310971f3b2dbbf3f0690a219f40e2d9afcf64f9ab7cc1be722937c26b4bc"

[[package]]
name = "windows_aarch64_msvc"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "09ec2a7bb152e2252b53fa7803150007879548bc709c039df7627cabbd05d469"

[[package]]
name = "windows_aarch64_msvc"
version = "0.53.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b9d782e804c2f632e395708e99a94275910eb9100b2114651e04744e9b125006"

[[package]]
name = "windows_i686_gnu"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "a75915e7def60c94dcef72200b9a8e58e5091744960da64ec734a6c6e9b3743e"

[[package]]
name = "windows_i686_gnu"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8e9b5ad5ab802e97eb8e295ac6720e509ee4c243f69d781394014ebfe8bbfa0b"

[[package]]
name = "windows_i686_gnu"
version = "0.53.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "960e6da069d81e09becb0ca57a65220ddff016ff2d6af6a223cf372a506593a3"

[[package]]
name = "windows_i686_gnullvm"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0eee52d38c090b3caa76c563b86c3a4bd71ef1a819287c19d586d7334ae8ed66"

[[package]]
name = "windows_i686_gnullvm"
version = "0.53.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "fa7359d10048f68ab8b09fa71c3daccfb0e9b559aed648a8f95469c27057180c"

[[package]]
name = "windows_i686_msvc"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "8f55c233f70c4b27f66c523580f78f1004e8b5a8b659e05a4eb49d4166cca406"

[[package]]
name = "windows_i686_msvc"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "240948bc05c5e7c6dabba28bf89d89ffce3e303022809e73deaefe4f6ec56c66"

[[package]]
name = "windows_i686_msvc"
version = "0.53.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "1e7ac75179f18232fe9c285163565a57ef8d3c89254a30685b57d83a38d326c2"

[[package]]
name = "windows_x86_64_gnu"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "53d40abd2583d23e4718fddf1ebec84dbff8381c07cae67ff7768bbf19c6718e"

[[package]]
name = "windows_x86_64_gnu"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "147a5c80aabfbf0c7d901cb5895d1de30ef2907eb21fbbab29ca94c5b08b1a78"

[[package]]
name = "windows_x86_64_gnu"
version = "0.53.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9c3842cdd74a865a8066ab39c8a7a473c0778a3f29370b5fd6b4b9aa7df4a499"

[[package]]
name = "windows_x86_64_gnullvm"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0b7b52767868a23d5bab768e390dc5f5c55825b6d30b86c844ff2dc7414044cc"

[[package]]
name = "windows_x86_64_gnullvm"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "24d5b23dc417412679681396f2b49f3de8c1473deb516bd34410872eff51ed0d"

[[package]]
name = "windows_x86_64_gnullvm"
version = "0.53.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "0ffa179e2d07eee8ad8f57493436566c7cc30ac536a3379fdf008f47f6bb7ae1"

[[package]]
name = "windows_x86_64_msvc"
version = "0.48.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "ed94fce61571a4006852b7389a063ab983c02eb1bb37b47f8272ce92d06d9538"

[[package]]
name = "windows_x86_64_msvc"
version = "0.52.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "589f6da84c646204747d1270a2a5661ea66ed1cced2631d546fdfb155959f9ec"

[[package]]
name = "windows_x86_64_msvc"
version = "0.53.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d6bbff5f0aada427a1e5a6da5f1f98158182f26556f345ac9e04d36d0ebed650"

[[package]]
name = "winreg"
version = "0.50.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "524e57b2c537c0f9b1e69f1965311ec12182b4122e45035b1508cd24d2adadb1"
dependencies = [
 "cfg-if",
 "windows-sys 0.48.0",
]

[[package]]
name = "wit-bindgen"
version = "0.46.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "f17a85883d4e6d00e8a97c586de764dabcc06133f7f1d55dce5cdc070ad7fe59"

[[package]]
name = "writeable"
version = "0.6.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "9edde0db4769d2dc68579893f2306b26c6ecfbe0ef499b013d731b7b9247e0b9"

[[package]]
name = "y4m"
version = "0.8.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "7a5a4b21e1a62b67a2970e6831bc091d7b87e119e7f9791aef9702e3bef04448"

[[package]]
name = "yoke"
version = "0.8.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "72d6e5c6afb84d73944e5cedb052c4680d5657337201555f9f2a16b7406d4954"
dependencies = [
 "stable_deref_trait",
 "yoke-derive",
 "zerofrom",
]

[[package]]
name = "yoke-derive"
version = "0.8.1"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b659052874eb698efe5b9e8cf382204678a0086ebf46982b79d6ca3182927e5d"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
 "synstructure",
]

[[package]]
name = "zerocopy"
version = "0.8.33"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "668f5168d10b9ee831de31933dc111a459c97ec93225beb307aed970d1372dfd"
dependencies = [
 "zerocopy-derive",
]

[[package]]
name = "zerocopy-derive"
version = "0.8.33"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2c7962b26b0a8685668b671ee4b54d007a67d4eaf05fda79ac0ecf41e32270f1"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "zerofrom"
version = "0.1.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "50cc42e0333e05660c3587f3bf9d0478688e15d870fab3346451ce7f8c9fbea5"
dependencies = [
 "zerofrom-derive",
]

[[package]]
name = "zerofrom-derive"
version = "0.1.6"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "d71e5d6e06ab090c67b5e44993ec16b72dcbaabc526db883a360057678b48502"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
 "synstructure",
]

[[package]]
name = "zeroize"
version = "1.8.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "b97154e67e32c85465826e8bcc1c59429aaaf107c1e4a9e53c8d8ccd5eff88d0"

[[package]]
name = "zerotrie"
version = "0.2.3"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2a59c17a5562d507e4b54960e8569ebee33bee890c70aa3fe7b97e85a9fd7851"
dependencies = [
 "displaydoc",
 "yoke",
 "zerofrom",
]

[[package]]
name = "zerovec"
version = "0.11.5"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "6c28719294829477f525be0186d13efa9a3c602f7ec202ca9e353d310fb9a002"
dependencies = [
 "yoke",
 "zerofrom",
 "zerovec-derive",
]

[[package]]
name = "zerovec-derive"
version = "0.11.2"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "eadce39539ca5cb3985590102671f2567e659fca9666581ad3411d59207951f3"
dependencies = [
 "proc-macro2",
 "quote",
 "syn",
]

[[package]]
name = "zmij"
version = "1.0.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "2fc5a66a20078bf1251bde995aa2fdcc4b800c70b5d92dd2c62abc5c60f679f8"

[[package]]
name = "zune-core"
version = "0.4.12"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "3f423a2c17029964870cfaabb1f13dfab7d092a62a29a89264f4d36990ca414a"

[[package]]
name = "zune-core"
version = "0.5.0"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "111f7d9820f05fd715df3144e254d6fc02ee4088b0644c0ffd0efc9e6d9d2773"

[[package]]
name = "zune-inflate"
version = "0.2.54"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "73ab332fe2f6680068f3582b16a24f90ad7096d5d39b974d1c0aff0125116f02"
dependencies = [
 "simd-adler32",
]

[[package]]
name = "zune-jpeg"
version = "0.4.21"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "29ce2c8a9384ad323cf564b67da86e21d3cfdff87908bc1223ed5c99bc792713"
dependencies = [
 "zune-core 0.4.12",
]

[[package]]
name = "zune-jpeg"
version = "0.5.8"
source = "registry+https://github.com/rust-lang/crates.io-index"
checksum = "e35aee689668bf9bd6f6f3a6c60bb29ba1244b3b43adfd50edd554a371da37d5"
dependencies = [
 "zune-core 0.5.0",
]
=== ./Cargo.toml ===
[package]
name = "overtake-detection"
version = "0.1.0"
edition = "2021"

[dependencies]
uuid = { version = "1.0", features = ["v4"] }
chrono = { version = "0.4", features = ["serde"] }
serde_json = "1.0"
# ONNX Runtime with TensorRT support
ort = { version = "2.0.0-rc.11", features = ["cuda", "download-binaries"] }

# Tensor operations
ndarray = "0.15"

# Async runtime
tokio = { version = "1.35", features = ["full"] }

# Error handling
anyhow = "1.0"
thiserror = "1.0"

# Serialization
serde = { version = "1.0", features = ["derive"] }
serde_yaml = "0.9"

# Logging
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter"] }

opencv = { version = "0.91", features = ["rgb"] }

# File system
walkdir = "2.4"
base64 = "0.22"
image = "0.25"
reqwest = { version = "0.11", features = ["json"] }
[profile.release]
opt-level = 3
lto = true
codegen-units = 1

=== ./a.txt ===
use crate::types::Config;
use anyhow::Result;
use std::fs;

impl Config {
    pub fn load(path: &str) -> Result<Self> {
        let contents = fs::read_to_string(path)?;
        let config: Config = serde_yaml::from_str(&contents)?;
        Ok(config)
    }
}
use opencv::{core, imgproc, prelude::*};

pub fn visualize_lanes(frame: &Mat, lanes: &[Lane], position: &VehiclePosition) -> Result<Mat> {
    let mut debug_frame = frame.clone();

    // Draw detected lanes with different colors
    let colors = [
        core::Scalar::new(255.0, 0.0, 0.0, 0.0),   // Blue - Lane 0
        core::Scalar::new(0.0, 255.0, 0.0, 0.0),   // Green - Lane 1
        core::Scalar::new(0.0, 0.0, 255.0, 0.0),   // Red - Lane 2
        core::Scalar::new(255.0, 255.0, 0.0, 0.0), // Cyan - Lane 3
    ];

    for (i, lane) in lanes.iter().enumerate() {
        // Draw lane points
        for window in lane.points.windows(2) {
            let p1 = core::Point::new(window[0].x as i32, window[0].y as i32);
            let p2 = core::Point::new(window[1].x as i32, window[1].y as i32);
            imgproc::line(
                &mut debug_frame,
                p1,
                p2,
                colors[i % 4],
                3,
                imgproc::LINE_8,
                0,
            )?;
        }

        // Draw lane ID
        if let Some(first_point) = lane.points.first() {
            imgproc::put_text(
                &mut debug_frame,
                &format!("L{} ({:.2})", i, lane.confidence),
                core::Point::new(first_point.x as i32, first_point.y as i32 - 10),
                imgproc::FONT_HERSHEY_SIMPLEX,
                0.6,
                colors[i % 4],
                2,
                imgproc::LINE_8,
                false,
            )?;
        }
    }

    // Draw vehicle position indicator
    let vehicle_x = frame.cols() / 2;
    let vehicle_y = (frame.rows() as f32 * 0.85) as i32;

    imgproc::circle(
        &mut debug_frame,
        core::Point::new(vehicle_x, vehicle_y),
        10,
        core::Scalar::new(0.0, 255.0, 255.0, 0.0), // Yellow
        -1,
        imgproc::LINE_8,
        0,
    )?;

    // Draw current lane info
    let info = format!(
        "Lane: {} | Offset: {:.2} | Conf: {:.2}",
        position.lane_index, position.lateral_offset, position.confidence
    );
    imgproc::put_text(
        &mut debug_frame,
        &info,
        core::Point::new(10, 30),
        imgproc::FONT_HERSHEY_SIMPLEX,
        0.8,
        core::Scalar::new(0.0, 255.0, 0.0, 0.0),
        2,
        imgproc::LINE_8,
        false,
    )?;

    Ok(debug_frame)
}
// src/inference.rs

use crate::types::Config;
use anyhow::{Context, Result};
use ort::{
    execution_providers::CUDAExecutionProvider,
    session::{builder::GraphOptimizationLevel, Session},
};
use tracing::{debug, info};

pub struct InferenceEngine {
    session: Session,
    config: Config,
}

impl InferenceEngine {
    pub fn new(config: Config) -> Result<Self> {
        info!("Initializing inference engine");
        info!("Model path: {}", config.model.path);

        let mut session_builder = Session::builder()?;

        // CUDA execution provider
        info!("Enabling CUDA execution provider");
        session_builder =
            session_builder.with_execution_providers([CUDAExecutionProvider::default()
                .with_device_id(0)
                .build()])?;

        info!("Building ONNX Runtime session...");
        let session = session_builder
            .with_optimization_level(GraphOptimizationLevel::Level3)?
            .with_intra_threads(config.inference.num_threads)?
            .with_inter_threads(1)?
            .commit_from_file(&config.model.path)
            .context("Failed to load model")?;

        info!(" Inference engine initialized successfully");

        Ok(Self { session, config })
    }

    pub fn infer(&mut self, input: &[f32]) -> Result<Vec<f32>> {
        debug!("Running inference");

        // Create shape tuple
        let shape = [
            1,
            3,
            self.config.model.input_height,
            self.config.model.input_width,
        ];

        // Create input value from tuple (shape, data)
        let input_value =
            ort::value::Value::from_array((shape.as_slice(), input.to_vec().into_boxed_slice()))?;

        // Run inference
        let outputs = self.session.run(ort::inputs!["input" => input_value])?;

        // Extract output
        let output = &outputs[0];
        let (output_shape, data_slice) = output.try_extract_tensor::<f32>()?;

        // DEBUG: Print actual output shape
        info!("Model output shape: {:?}", output_shape);
        info!("Model output size: {}", data_slice.len());

        // Convert slice to Vec
        let output_data: Vec<f32> = data_slice.to_vec();

        Ok(output_data)
    }
}
use crate::types::{Config, Lane};
use anyhow::Result;
use tracing::info;

pub struct LaneDetectionResult {
    pub lanes: Vec<Lane>,
    pub timestamp: f64,
}

// CULane row anchors (normalized to 320 height)
const ROW_ANCHORS: [f32; 72] = [
    121.0, 131.0, 141.0, 150.0, 160.0, 170.0, 180.0, 189.0, 199.0, 209.0, 219.0, 228.0, 238.0,
    248.0, 258.0, 267.0, 277.0, 287.0, 297.0, 306.0, 316.0, 326.0, 336.0, 345.0, 355.0, 365.0,
    375.0, 384.0, 394.0, 404.0, 414.0, 423.0, 433.0, 443.0, 453.0, 462.0, 472.0, 482.0, 492.0,
    501.0, 511.0, 521.0, 531.0, 540.0, 550.0, 560.0, 570.0, 579.0, 589.0, 599.0, 609.0, 618.0,
    628.0, 638.0, 648.0, 657.0, 667.0, 677.0, 687.0, 696.0, 706.0, 716.0, 726.0, 735.0, 745.0,
    755.0, 765.0, 774.0, 784.0, 794.0, 804.0, 813.0,
];

pub fn parse_lanes(
    output: &[f32],
    frame_width: f32,
    frame_height: f32,
    config: &Config,
    timestamp: f64,
) -> Result<LaneDetectionResult> {
    // DEBUG: Check output values
    let max_val = output.iter().copied().fold(f32::NEG_INFINITY, f32::max);
    let min_val = output.iter().copied().fold(f32::INFINITY, f32::min);
    let avg_val = output.iter().sum::<f32>() / output.len() as f32;

    info!(
        "Output stats - min: {:.4}, max: {:.4}, avg: {:.4}",
        min_val, max_val, avg_val
    );

    // Model output shape: [1, griding_num, num_anchors, num_lanes]
    // = [1, 200, 72, 4]

    let griding_num = config.model.griding_num;
    let num_anchors = config.model.num_anchors;
    let num_lanes = config.model.num_lanes;

    info!(
        "Config - griding: {}, anchors: {}, lanes: {}",
        griding_num, num_anchors, num_lanes
    );

    let mut lanes = Vec::new();

    // Process each lane
    for lane_idx in 0..num_lanes {
        let mut points = Vec::new();
        let mut total_confidence = 0.0;
        let mut point_count = 0;

        // Process each anchor (row)
        for anchor_idx in 0..num_anchors {
            // Find the grid position with max probability
            let mut max_prob = f32::NEG_INFINITY;
            let mut max_grid_idx = 0;

            // Check each grid position
            for grid_idx in 0..griding_num {
                // Index calculation for shape [1, 200, 72, 4]
                // Skip batch dimension (0), so: [grid, anchor, lane]
                let idx = grid_idx * (num_anchors * num_lanes) + anchor_idx * num_lanes + lane_idx;

                let prob = output[idx];
                if prob > max_prob {
                    max_prob = prob;
                    max_grid_idx = grid_idx;
                }
            }

            // Use sigmoid for confidence (simpler than softmax)
            let confidence = 1.0 / (1.0 + (-max_prob).exp());

            // LOWERED THRESHOLD for debugging
            if confidence >= 0.1 && max_grid_idx < griding_num {
                // Convert grid position to pixel coordinates
                let x = (max_grid_idx as f32 / griding_num as f32) * frame_width;

                // Y coordinate from row anchor (scaled to frame height)
                let y = (ROW_ANCHORS[anchor_idx] / config.model.input_height as f32) * frame_height;

                points.push((x, y));
                total_confidence += confidence;
                point_count += 1;
            }
        }

        // LOWERED THRESHOLD: Only need 3+ points
        if points.len() >= 3 {
            let avg_confidence = if point_count > 0 {
                total_confidence / point_count as f32
            } else {
                0.0
            };

            info!(
                "Lane {} detected with {} points, confidence: {:.4}",
                lane_idx,
                points.len(),
                avg_confidence
            );

            lanes.push(Lane {
                points,
                confidence: avg_confidence,
            });
        }
    }

    info!("Total lanes detected: {}", lanes.len());

    Ok(LaneDetectionResult { lanes, timestamp })
}

pub fn find_vehicle_lane(lanes: &[Lane], frame_width: f32) -> Option<(usize, f32)> {
    if lanes.len() < 2 {
        return None;
    }

    let vehicle_x = frame_width / 2.0;

    // Get x positions of lanes at bottom of frame
    let mut lane_positions: Vec<(usize, f32)> = lanes
        .iter()
        .enumerate()
        .filter_map(|(idx, lane)| {
            lane.points.last().map(|p| (idx, p.0)) // p.0 is x coordinate
        })
        .collect();

    lane_positions.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap());

    // Find which lane pair the vehicle is between
    for i in 0..lane_positions.len() - 1 {
        let (_, left_x) = lane_positions[i];
        let (_, right_x) = lane_positions[i + 1];

        if left_x <= vehicle_x && vehicle_x <= right_x {
            let lane_width = right_x - left_x;
            let offset_from_left = vehicle_x - left_x;
            let normalized_offset = (offset_from_left / lane_width - 0.5) * 2.0; // [-1, 1]

            return Some((i, normalized_offset));
        }
    }

    None
}
// src/main.rs

mod config;
mod inference;
mod lane_detection;
mod overtake_detector;
mod preprocessing;
mod smoother;
mod types;
mod video_processor; //  NEW MODULE

use anyhow::Result;
use std::path::Path;
use tracing::{debug, error, info, warn};

#[tokio::main]
async fn main() -> Result<()> {
    // Initialize logging
    tracing_subscriber::fmt()
        .with_env_filter("overtake_detection=info,ort=warn")
        .init();

    info!(" Overtake Detection System Starting");

    // Load configuration
    let config = types::Config::load("config.yaml")?;
    info!(" Configuration loaded");
    info!(
        "  Smoother window: {} frames",
        config.detection.smoother_window_size
    );
    info!(
        "  Calibration frames: {}",
        config.detection.calibration_frames
    );
    info!("  Debounce frames: {}", config.detection.debounce_frames);
    info!("  Confirm frames: {}", config.detection.confirm_frames);

    // Initialize inference engine
    let mut inference_engine = inference::InferenceEngine::new(config.clone())?;
    info!(" Inference engine ready");

    // Initialize video processor
    let video_processor = video_processor::VideoProcessor::new(config.clone());

    // Find all video files
    let video_files = video_processor.find_video_files()?;

    if video_files.is_empty() {
        error!("No video files found in {}", config.video.input_dir);
        return Ok(());
    }

    // Process each video
    for (idx, video_path) in video_files.iter().enumerate() {
        info!("\n========================================");
        info!(
            "Processing video {}/{}: {}",
            idx + 1,
            video_files.len(),
            video_path.display()
        );
        info!("========================================\n");

        match process_video(video_path, &mut inference_engine, &video_processor, &config).await {
            Ok(stats) => {
                info!("\n Video processed successfully!");
                info!("  Total frames: {}", stats.total_frames);
                info!(
                    "  Frames with valid position: {} ({:.1}%)",
                    stats.frames_with_position,
                    (stats.frames_with_position as f32 / stats.total_frames as f32) * 100.0
                );
                info!("  Lane changes detected: {}", stats.lane_changes_detected);
                info!("  Overtakes detected: {}", stats.overtakes_detected);
                info!("  Processing time: {:.2}s", stats.duration_secs);
                info!("  Average FPS: {:.2}", stats.avg_fps);
            }
            Err(e) => {
                error!("Failed to process video: {}", e);
            }
        }
    }

    info!("\n All videos processed!");
    Ok(())
}

struct ProcessingStats {
    total_frames: i32,
    frames_with_position: i32,
    lane_changes_detected: usize,
    overtakes_detected: usize,
    duration_secs: f64,
    avg_fps: f64,
}

async fn process_video(
    video_path: &Path,
    inference_engine: &mut inference::InferenceEngine,
    video_processor: &video_processor::VideoProcessor,
    config: &types::Config,
) -> Result<ProcessingStats> {
    use std::time::Instant;

    let start_time = Instant::now();

    // Open video
    let mut reader = video_processor.open_video(video_path)?;

    // Create video writer for annotated output
    let mut writer =
        video_processor.create_writer(video_path, reader.width, reader.height, reader.fps)?;

    // Initialize components with smoother! 
    let mut smoother = smoother::LanePositionSmoother::new(config.detection.smoother_window_size);
    let mut overtake_detector = overtake_detector::OvertakeDetector::new(config.clone());

    // Results storage
    let mut overtakes = Vec::new();
    let mut lane_changes = Vec::new();
    let mut frame_count = 0;

    // Track stats for summary
    let mut frames_with_lanes = 0;
    let mut frames_with_valid_position = 0;
    let mut calibration_complete = false;

    info!(
        " Starting calibration phase ({} frames)...",
        config.detection.calibration_frames
    );

    // Process frames
    while let Some(frame) = reader.read_frame()? {
        frame_count += 1;

        // Show progress
        if frame_count % 30 == 0 {
            let progress_msg = if calibration_complete {
                format!(
                    "Progress: {:.1}% ({}/{}) - Valid pos: {}/{} ({:.1}%) - Lane changes: {} - Overtakes: {}",
                    reader.progress(),
                    reader.current_frame,
                    reader.total_frames,
                    frames_with_valid_position,
                    frame_count,
                    (frames_with_valid_position as f32 / frame_count as f32) * 100.0,
                    lane_changes.len(),
                    overtakes.len()
                )
            } else {
                format!(
                    " Calibrating: {}/{} frames",
                    frame_count, config.detection.calibration_frames
                )
            };
            info!("{}", progress_msg);
        }

        // Process frame with smoother 
        match process_frame(
            &frame,
            inference_engine,
            &mut smoother,
            &mut overtake_detector,
            config,
            frame_count,
            calibration_complete,
        )
        .await
        {
            Ok(result) => {
                // Update stats
                if !result.lanes.is_empty() {
                    frames_with_lanes += 1;
                }

                if result.had_valid_position {
                    frames_with_valid_position += 1;
                }

                // Check if calibration just completed
                if !calibration_complete && result.calibration_complete {
                    calibration_complete = true;
                    info!(
                        " Calibration complete! Baseline lane: {}",
                        result.baseline_lane.unwrap_or(-1)
                    );
                }

                // Save lane change event
                if let Some(lane_change) = result.lane_change {
                    lane_changes.push(lane_change.clone());
                    info!(
                        " Lane change #{}: {:?} (lane {}  {}) at {:.2}s",
                        lane_changes.len(),
                        lane_change.direction,
                        lane_change.from_lane,
                        lane_change.to_lane,
                        lane_change.timestamp
                    );
                }

                // Save overtake event
                if let Some(overtake) = result.overtake {
                    overtakes.push(overtake.clone());
                    info!(
                        " OVERTAKE #{} detected at {:.2}s",
                        overtakes.len(),
                        overtake.end_timestamp
                    );
                    info!(
                        "   Direction: {:?}  {:?}",
                        overtake.first_direction, overtake.second_direction
                    );
                    info!(
                        "   Lanes: {}  {}  {}",
                        overtake.start_lane,
                        if overtake.first_direction == types::Direction::Right {
                            overtake.start_lane + 1
                        } else {
                            overtake.start_lane - 1
                        },
                        overtake.end_lane
                    );
                    info!(
                        "   Duration: {:.2}s",
                        overtake.end_timestamp - overtake.start_timestamp
                    );
                    info!(
                        "   Complete: {} | Confidence: {:.2}",
                        overtake.is_complete, overtake.confidence
                    );
                }

                // Draw lanes on frame and write to output video
                if let Some(ref mut w) = writer {
                    if let Ok(annotated) = video_processor::draw_lanes_with_info(
                        &frame.data,
                        reader.width,
                        reader.height,
                        &result.lanes,
                        result.smoothed_position.as_ref(),
                        calibration_complete,
                    ) {
                        use opencv::videoio::VideoWriterTrait;
                        w.write(&annotated)?;
                    }
                }
            }
            Err(e) => {
                error!("Frame {} processing failed: {}", frame_count, e);
            }
        }
    }

    let duration = start_time.elapsed();
    let avg_fps = frame_count as f64 / duration.as_secs_f64();

    // Print detailed summary
    info!("\n Processing Summary:");
    info!(
        "  Frames with lanes: {}/{} ({:.1}%)",
        frames_with_lanes,
        frame_count,
        (frames_with_lanes as f32 / frame_count as f32) * 100.0
    );
    info!(
        "  Frames with valid position: {}/{} ({:.1}%)",
        frames_with_valid_position,
        frame_count,
        (frames_with_valid_position as f32 / frame_count as f32) * 100.0
    );
    info!("  Lane changes detected: {}", lane_changes.len());
    info!("  Overtakes detected: {}", overtakes.len());

    if !overtakes.is_empty() {
        let complete_overtakes = overtakes.iter().filter(|o| o.is_complete).count();
        info!("     Complete overtakes: {}", complete_overtakes);
        info!(
            "     Incomplete: {}",
            overtakes.len() - complete_overtakes
        );
    }

    // Save results to JSON
    save_results(video_path, &overtakes, &lane_changes, config)?;

    Ok(ProcessingStats {
        total_frames: frame_count,
        frames_with_position: frames_with_valid_position,
        lane_changes_detected: lane_changes.len(),
        overtakes_detected: overtakes.len(),
        duration_secs: duration.as_secs_f64(),
        avg_fps,
    })
}

struct FrameResult {
    lanes: Vec<types::Lane>,
    raw_position: Option<types::VehiclePosition>,
    smoothed_position: Option<types::VehiclePosition>,
    lane_change: Option<types::LaneChangeEvent>,
    overtake: Option<types::OvertakeEvent>,
    had_valid_position: bool,
    calibration_complete: bool,
    baseline_lane: Option<i32>,
}

async fn process_frame(
    frame: &types::Frame,
    inference_engine: &mut inference::InferenceEngine,
    smoother: &mut smoother::LanePositionSmoother,
    overtake_detector: &mut overtake_detector::OvertakeDetector,
    config: &types::Config,
    frame_count: i32,
    calibration_complete: bool,
) -> Result<FrameResult> {
    // 1. Preprocess
    let preprocessed = preprocessing::preprocess(
        &frame.data,
        frame.width,
        frame.height,
        config.model.input_width,
        config.model.input_height,
    )?;

    // 2. Run inference
    let output = inference_engine.infer(&preprocessed)?;

    // 3. Parse lanes
    let lane_detection = lane_detection::parse_lanes(
        &output,
        frame.width as f32,
        frame.height as f32,
        config,
        frame.timestamp,
    )?;

    // Filter lanes by confidence 
    let high_confidence_lanes: Vec<types::Lane> = lane_detection
        .lanes
        .into_iter()
        .filter(|lane| lane.confidence > config.detection.min_lane_confidence)
        .collect();

    // Log lane detection every 30 frames
    if frame_count % 30 == 0 {
        debug!(
            "Frame {}: {}/{} lanes above confidence threshold",
            frame_count,
            high_confidence_lanes.len(),
            lane_detection.lanes.len()
        );
    }

    // 4. Calculate raw vehicle position
    let raw_position = if let Some((lane_idx, lateral_offset, confidence)) =
        lane_detection::find_vehicle_lane_with_confidence(
            &high_confidence_lanes,
            frame.width as f32,
        ) {
        Some(types::VehiclePosition {
            lane_index: lane_idx as i32,
            lateral_offset,
            confidence,
            timestamp: frame.timestamp,
        })
    } else {
        None
    };

    // 5. Smooth position  (CRITICAL STEP!)
    let smoothed_position = if let Some(raw_pos) = raw_position {
        // Only process if confidence is high enough
        if raw_pos.confidence >= config.detection.min_position_confidence {
            Some(smoother.smooth(raw_pos))
        } else {
            if frame_count % 30 == 0 {
                debug!(
                    "Frame {}: Skipping low confidence position ({:.2})",
                    frame_count, raw_pos.confidence
                );
            }
            None
        }
    } else {
        None
    };

    // 6. Update overtake detector with smoothed position 
    let mut lane_change = None;
    let mut overtake = None;
    let mut new_calibration_complete = calibration_complete;
    let mut baseline_lane = None;

    if let Some(smooth_pos) = smoothed_position {
        // Update detector
        let result = overtake_detector.update_with_position(smooth_pos);

        // Check calibration status
        if !calibration_complete && overtake_detector.is_calibrated() {
            new_calibration_complete = true;
            baseline_lane = overtake_detector.get_baseline_lane();
        }

        // Extract events
        lane_change = result.lane_change;
        overtake = result.overtake;

        // Debug logging
        if frame_count % 30 == 0 {
            debug!(
                "Frame {}: Lane={}, Offset={:.2}, Conf={:.2}",
                frame_count,
                smooth_pos.lane_index,
                smooth_pos.lateral_offset,
                smooth_pos.confidence
            );
        }
    }

    Ok(FrameResult {
        lanes: high_confidence_lanes,
        raw_position,
        smoothed_position,
        lane_change,
        overtake,
        had_valid_position: smoothed_position.is_some(),
        calibration_complete: new_calibration_complete,
        baseline_lane,
    })
}

fn save_results(
    video_path: &Path,
    overtakes: &[types::OvertakeEvent],
    lane_changes: &[types::LaneChangeEvent],
    config: &types::Config,
) -> Result<()> {
    use serde_json;
    use std::fs::File;
    use std::io::Write;

    let video_name = video_path.file_stem().unwrap().to_str().unwrap();

    // Save overtakes
    let overtakes_path =
        Path::new(&config.video.output_dir).join(format!("{}_overtakes.json", video_name));
    let json = serde_json::to_string_pretty(overtakes)?;
    let mut file = File::create(&overtakes_path)?;
    file.write_all(json.as_bytes())?;
    info!(" Overtakes saved to: {}", overtakes_path.display());

    // Save lane changes
    let lane_changes_path =
        Path::new(&config.video.output_dir).join(format!("{}_lane_changes.json", video_name));
    let json = serde_json::to_string_pretty(lane_changes)?;
    let mut file = File::create(&lane_changes_path)?;
    file.write_all(json.as_bytes())?;
    info!(" Lane changes saved to: {}", lane_changes_path.display());

    // Save summary
    let summary = serde_json::json!({
        "video": video_name,
        "total_lane_changes": lane_changes.len(),
        "total_overtakes": overtakes.len(),
        "complete_overtakes": overtakes.iter().filter(|o| o.is_complete).count(),
        "overtakes": overtakes,
        "lane_changes": lane_changes,
    });

    let summary_path =
        Path::new(&config.video.output_dir).join(format!("{}_summary.json", video_name));
    let json = serde_json::to_string_pretty(&summary)?;
    let mut file = File::create(&summary_path)?;
    file.write_all(json.as_bytes())?;
    info!(" Summary saved to: {}", summary_path.display());

    Ok(())
}
use crate::types::{Config, Direction, LaneChangeEvent, OvertakeEvent};
use std::collections::VecDeque;
use tracing::info;

pub struct OvertakeDetector {
    config: Config,
    lane_history: VecDeque<(i32, f64)>,
    last_stable_lane: Option<i32>,
    last_change_time: Option<f64>,
    recent_changes: Vec<LaneChangeEvent>,
}

impl OvertakeDetector {
    pub fn new(config: Config) -> Self {
        Self {
            config,
            lane_history: VecDeque::with_capacity(30),
            last_stable_lane: None,
            last_change_time: None,
            recent_changes: Vec::new(),
        }
    }

    pub fn update(
        &mut self,
        current_lane: i32,
        _lateral_offset: f32,
        timestamp: f64,
    ) -> Option<OvertakeEvent> {
        // Add to history
        self.lane_history.push_back((current_lane, timestamp));
        if self.lane_history.len() > 30 {
            self.lane_history.pop_front();
        }

        // Get stable lane (mode of last 10 frames)
        let stable_lane = self.get_stable_lane();

        // Detect lane change
        if let Some(prev_stable) = self.last_stable_lane {
            if stable_lane != prev_stable {
                let event = LaneChangeEvent {
                    timestamp,
                    direction: if stable_lane > prev_stable {
                        Direction::Right
                    } else {
                        Direction::Left
                    },
                    from_lane: prev_stable,
                    to_lane: stable_lane,
                    confidence: 0.8, // You can calculate actual confidence
                };

                info!(
                    "Lane change detected: {:?} from {} to {}",
                    event.direction, event.from_lane, event.to_lane
                );

                // Check for overtake
                let overtake = self.check_overtake(&event);

                self.last_stable_lane = Some(stable_lane);
                self.last_change_time = Some(timestamp);

                return overtake;
            }
        } else {
            self.last_stable_lane = Some(stable_lane);
        }

        None
    }

    fn get_stable_lane(&self) -> i32 {
        if self.lane_history.is_empty() {
            return -1;
        }

        // Get mode of last 10 frames
        let recent: Vec<i32> = self
            .lane_history
            .iter()
            .rev()
            .take(10)
            .map(|(lane, _)| *lane)
            .collect();

        let mut counts = std::collections::HashMap::new();
        for &lane in &recent {
            *counts.entry(lane).or_insert(0) += 1;
        }

        counts
            .into_iter()
            .max_by_key(|(_, count)| *count)
            .map(|(lane, _)| lane)
            .unwrap_or(-1)
    }

    fn check_overtake(&mut self, current_event: &LaneChangeEvent) -> Option<OvertakeEvent> {
        // Add to recent changes
        self.recent_changes.push(current_event.clone());

        // Keep only events within time window
        self.recent_changes.retain(|e| {
            current_event.timestamp - e.timestamp < self.config.overtake.max_window_seconds
        });

        // Need at least 2 lane changes
        if self.recent_changes.len() < 2 {
            return None;
        }

        let prev = &self.recent_changes[self.recent_changes.len() - 2];
        let curr = current_event;

        let delta = curr.timestamp - prev.timestamp;

        // Check timing constraints
        if delta < self.config.overtake.min_interval_seconds
            || delta > self.config.overtake.max_window_seconds
        {
            return None;
        }

        // Check for opposite directions (overtake pattern)
        let is_complete = (prev.direction == Direction::Left && curr.direction == Direction::Right)
            || (prev.direction == Direction::Right && curr.direction == Direction::Left);

        if is_complete {
            info!(" OVERTAKE DETECTED!");
        }

        Some(OvertakeEvent {
            start_timestamp: prev.timestamp,
            end_timestamp: curr.timestamp,
            first_direction: prev.direction,
            second_direction: curr.direction,
            start_lane: prev.from_lane,
            end_lane: curr.to_lane,
            is_complete,
            confidence: (prev.confidence + curr.confidence) / 2.0,
        })
    }
}
// src/preprocessing.rs

use anyhow::Result;

/// Preprocess raw RGB image for model input
pub fn preprocess(
    src: &[u8],
    src_width: usize,
    src_height: usize,
    dst_width: usize,
    dst_height: usize,
) -> Result<Vec<f32>> {
    // Resize
    let resized = resize_bilinear(src, src_width, src_height, dst_width, dst_height);

    // Normalize and convert HWC -> CHW
    const MEAN: [f32; 3] = [0.485, 0.456, 0.406];
    const STD: [f32; 3] = [0.229, 0.224, 0.225];

    let mut output = vec![0.0f32; 3 * dst_height * dst_width];

    for c in 0..3 {
        for h in 0..dst_height {
            for w in 0..dst_width {
                let hwc_idx = (h * dst_width + w) * 3 + c;
                let chw_idx = c * dst_height * dst_width + h * dst_width + w;

                let pixel = resized[hwc_idx] as f32 / 255.0;
                output[chw_idx] = (pixel - MEAN[c]) / STD[c];
            }
        }
    }

    Ok(output)
}

/// Bilinear image resize
fn resize_bilinear(src: &[u8], src_w: usize, src_h: usize, dst_w: usize, dst_h: usize) -> Vec<u8> {
    let mut dst = vec![0u8; dst_h * dst_w * 3];

    let x_ratio = src_w as f32 / dst_w as f32;
    let y_ratio = src_h as f32 / dst_h as f32;

    for dy in 0..dst_h {
        for dx in 0..dst_w {
            let sx = dx as f32 * x_ratio;
            let sy = dy as f32 * y_ratio;

            let sx0 = sx.floor() as usize;
            let sy0 = sy.floor() as usize;
            let sx1 = (sx0 + 1).min(src_w - 1);
            let sy1 = (sy0 + 1).min(src_h - 1);

            let fx = sx - sx0 as f32;
            let fy = sy - sy0 as f32;

            for c in 0..3 {
                let p00 = src[(sy0 * src_w + sx0) * 3 + c] as f32;
                let p10 = src[(sy0 * src_w + sx1) * 3 + c] as f32;
                let p01 = src[(sy1 * src_w + sx0) * 3 + c] as f32;
                let p11 = src[(sy1 * src_w + sx1) * 3 + c] as f32;

                let val = p00 * (1.0 - fx) * (1.0 - fy)
                    + p10 * fx * (1.0 - fy)
                    + p01 * (1.0 - fx) * fy
                    + p11 * fx * fy;

                dst[(dy * dst_w + dx) * 3 + c] = val.round() as u8;
            }
        }
    }

    dst
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_preprocess() {
        let src = vec![128u8; 640 * 480 * 3];
        let result = preprocess(&src, 640, 480, 1600, 320);
        assert!(result.is_ok());
        assert_eq!(result.unwrap().len(), 3 * 320 * 1600);
    }

    #[test]
    fn test_resize() {
        let src = vec![255u8; 100 * 100 * 3];
        let dst = resize_bilinear(&src, 100, 100, 50, 50);
        assert_eq!(dst.len(), 50 * 50 * 3);
    }
}
// src/smoother.rs

use crate::types::VehiclePosition;
use std::collections::{HashMap, VecDeque};

/// Temporal smoother for vehicle position using a sliding window
pub struct LanePositionSmoother {
    history: VecDeque<VehiclePosition>,
    window_size: usize,
}

impl LanePositionSmoother {
    /// Create a new smoother with specified window size
    ///
    /// # Arguments
    /// * `window_size` - Number of frames to use for smoothing (e.g., 10 frames)
    pub fn new(window_size: usize) -> Self {
        Self {
            history: VecDeque::with_capacity(window_size),
            window_size,
        }
    }

    /// Smooth the current position using temporal window
    ///
    /// Uses different strategies for different components:
    /// - Lane index: Mode (most common value)
    /// - Lateral offset: Median (resistant to outliers)
    /// - Confidence: Average
    pub fn smooth(&mut self, position: VehiclePosition) -> VehiclePosition {
        self.history.push_back(position);

        // Maintain window size
        if self.history.len() > self.window_size {
            self.history.pop_front();
        }

        // Need at least 3 frames for meaningful smoothing
        if self.history.len() < 3 {
            return position;
        }

        VehiclePosition {
            lane_index: self.smooth_lane_index(),
            lateral_offset: self.smooth_lateral_offset(),
            confidence: self.smooth_confidence(),
            timestamp: position.timestamp, // Keep current timestamp
        }
    }

    /// Get the most common lane index (mode)
    fn smooth_lane_index(&self) -> i32 {
        let mut counts: HashMap<i32, usize> = HashMap::new();

        for pos in &self.history {
            *counts.entry(pos.lane_index).or_insert(0) += 1;
        }

        counts
            .into_iter()
            .max_by_key(|(_, count)| *count)
            .map(|(lane, _)| lane)
            .unwrap_or(-1)
    }

    /// Get median lateral offset (resistant to outliers)
    fn smooth_lateral_offset(&self) -> f32 {
        let mut offsets: Vec<f32> = self.history.iter().map(|p| p.lateral_offset).collect();
        offsets.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
        offsets[offsets.len() / 2]
    }

    /// Get average confidence
    fn smooth_confidence(&self) -> f32 {
        let sum: f32 = self.history.iter().map(|p| p.confidence).sum();
        sum / self.history.len() as f32
    }

    /// Reset the smoother (e.g., when video changes)
    pub fn reset(&mut self) {
        self.history.clear();
    }

    /// Get the number of frames currently in the history
    pub fn history_size(&self) -> usize {
        self.history.len()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_smoother_mode_for_lane_index() {
        let mut smoother = LanePositionSmoother::new(5);

        // Feed noisy lane detections: [1, 1, 2, 1, 1]
        let positions = vec![
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.0,
            },
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.033,
            },
            VehiclePosition {
                lane_index: 2, // noise
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.066,
            },
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.099,
            },
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.132,
            },
        ];

        for pos in positions {
            smoother.smooth(pos);
        }

        // Last smoothed position should have lane_index = 1 (mode)
        let last_pos = positions.last().unwrap();
        let smoothed = smoother.smooth(*last_pos);
        assert_eq!(smoothed.lane_index, 1);
    }

    #[test]
    fn test_smoother_median_for_offset() {
        let mut smoother = LanePositionSmoother::new(5);

        // Feed offsets with outlier: [-0.1, -0.05, 0.0, 0.05, 2.0 (outlier)]
        let offsets = vec![-0.1, -0.05, 0.0, 0.05, 2.0];

        for (i, offset) in offsets.iter().enumerate() {
            let pos = VehiclePosition {
                lane_index: 1,
                lateral_offset: *offset,
                confidence: 0.8,
                timestamp: i as f64 * 0.033,
            };
            smoother.smooth(pos);
        }

        let last_pos = VehiclePosition {
            lane_index: 1,
            lateral_offset: 2.0,
            confidence: 0.8,
            timestamp: 0.165,
        };
        let smoothed = smoother.smooth(last_pos);

        // Median should be 0.0 (middle value), not affected by 2.0 outlier
        assert_eq!(smoothed.lateral_offset, 0.0);
    }
}
use serde::{Deserialize, Serialize};

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Config {
    pub model: ModelConfig,
    pub inference: InferenceConfig,
    pub detection: DetectionConfig,
    pub overtake: OvertakeConfig,
    pub video: VideoConfig,
    pub logging: LoggingConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelConfig {
    pub path: String,
    pub input_width: usize,
    pub input_height: usize,
    pub num_anchors: usize,
    pub num_lanes: usize,
    pub griding_num: usize,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct InferenceConfig {
    pub use_tensorrt: bool,
    pub use_fp16: bool,
    pub enable_engine_cache: bool,
    pub engine_cache_path: String,
    pub num_threads: usize,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DetectionConfig {
    pub confidence_threshold: f32,
    pub min_points_per_lane: usize,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct OvertakeConfig {
    pub lane_change_offset_threshold: f32,
    pub debounce_frames: u32,
    pub confirm_frames: u32,
    pub max_window_seconds: f64,
    pub min_interval_seconds: f64,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VideoConfig {
    pub input_dir: String,
    pub output_dir: String,
    pub source_width: usize,
    pub source_height: usize,
    pub target_fps: u32,
    pub save_annotated: bool,
    pub save_events_only: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LoggingConfig {
    pub level: String,
}

#[derive(Debug, Clone)]
pub struct Frame {
    pub data: Vec<u8>,
    pub width: usize,
    pub height: usize,
    pub timestamp: f64,
}

#[derive(Debug, Clone)]
pub struct Lane {
    pub points: Vec<(f32, f32)>,
    pub confidence: f32,
}

#[derive(Debug, Clone)]
pub struct LaneDetection {
    pub lanes: Vec<Lane>,
    pub timestamp: f64,
}

#[derive(Debug, Clone)]
pub struct LaneChangeEvent {
    pub timestamp: f64,
    pub direction: Direction,
    pub from_lane: i32,
    pub to_lane: i32,
    pub confidence: f32,
}

// Make sure these have Serialize
#[derive(Debug, Clone, Copy, PartialEq, Serialize)]
pub enum Direction {
    None,
    Left,
    Right,
}

#[derive(Debug, Clone, Serialize)]
pub struct OvertakeEvent {
    pub start_timestamp: f64,
    pub end_timestamp: f64,
    pub first_direction: Direction,
    pub second_direction: Direction,
    pub start_lane: i32,
    pub end_lane: i32,
    pub is_complete: bool,
    pub confidence: f32,
}

// Add to src/types.rs

#[derive(Debug, Clone, Copy, serde::Serialize, serde::Deserialize)]
pub struct VehiclePosition {
    pub lane_index: i32,
    pub lateral_offset: f32,
    pub confidence: f32,
    pub timestamp: f64,
}

#[derive(Debug, Clone, Copy, PartialEq, serde::Serialize, serde::Deserialize)]
pub enum Direction {
    Left,
    Right,
}

#[derive(Debug, Clone, serde::Serialize, serde::Deserialize)]
pub struct LaneChangeEvent {
    pub timestamp: f64,
    pub direction: Direction,
    pub from_lane: i32,
    pub to_lane: i32,
    pub confidence: f32,
}
// src/video_processor.rs

use crate::types::Config;
use anyhow::Result;
use opencv::{
    core::{self, Mat},
    imgproc,
    prelude::*,
    videoio::{self, VideoCapture, VideoCaptureTraitConst, VideoWriter},
};
use std::path::{Path, PathBuf};
use tracing::info;
use walkdir::WalkDir;

pub struct VideoProcessor {
    config: Config,
}

impl VideoProcessor {
    pub fn new(config: Config) -> Self {
        Self { config }
    }

    pub fn find_video_files(&self) -> Result<Vec<PathBuf>> {
        let mut videos = Vec::new();

        let video_extensions = vec!["mp4", "avi", "mov", "mkv", "MP4", "AVI", "MOV", "MKV"];

        for entry in WalkDir::new(&self.config.video.input_dir)
            .follow_links(true)
            .into_iter()
            .filter_map(|e| e.ok())
        {
            let path = entry.path();
            if let Some(ext) = path.extension() {
                if video_extensions.contains(&ext.to_str().unwrap_or("")) {
                    videos.push(path.to_path_buf());
                }
            }
        }

        info!("Found {} video files", videos.len());
        Ok(videos)
    }

    pub fn open_video(&self, path: &Path) -> Result<VideoReader> {
        info!("Opening video: {}", path.display());

        let cap = VideoCapture::from_file(path.to_str().unwrap(), videoio::CAP_ANY)?;

        if !cap.is_opened()? {
            anyhow::bail!("Failed to open video file");
        }

        let fps = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FPS)?;
        let total_frames = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FRAME_COUNT)? as i32;
        let width = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FRAME_WIDTH)? as i32;
        let height = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FRAME_HEIGHT)? as i32;

        info!(
            "Video properties: {}x{} @ {:.1} FPS, {} frames",
            width, height, fps, total_frames
        );

        Ok(VideoReader {
            cap,
            fps,
            total_frames,
            current_frame: 0,
            width,
            height,
        })
    }

    pub fn create_writer(
        &self,
        input_path: &Path,
        width: i32,
        height: i32,
        fps: f64,
    ) -> Result<Option<VideoWriter>> {
        if !self.config.video.save_annotated {
            return Ok(None);
        }

        std::fs::create_dir_all(&self.config.video.output_dir)?;

        let input_name = input_path.file_stem().unwrap().to_str().unwrap();
        let output_path = PathBuf::from(&self.config.video.output_dir)
            .join(format!("{}_annotated.mp4", input_name));

        info!("Output video: {}", output_path.display());

        let fourcc = VideoWriter::fourcc('m', 'p', '4', 'v')?;
        let writer = VideoWriter::new(
            output_path.to_str().unwrap(),
            fourcc,
            fps,
            core::Size::new(width, height),
            true,
        )?;

        Ok(Some(writer))
    }
}

pub struct VideoReader {
    pub cap: VideoCapture,
    pub fps: f64,
    pub total_frames: i32,
    pub current_frame: i32,
    pub width: i32,
    pub height: i32,
}

impl VideoReader {
    pub fn read_frame(&mut self) -> Result<Option<crate::types::Frame>> {
        use opencv::videoio::VideoCaptureTrait;

        let mut mat = Mat::default();

        if !VideoCaptureTrait::read(&mut self.cap, &mut mat)? || mat.empty() {
            return Ok(None);
        }

        self.current_frame += 1;
        let timestamp = (self.current_frame as f64) / self.fps;

        let mut rgb_mat = Mat::default();
        imgproc::cvt_color(&mat, &mut rgb_mat, imgproc::COLOR_BGR2RGB, 0)?;

        let data = rgb_mat.data_bytes()?.to_vec();

        Ok(Some(crate::types::Frame {
            data,
            width: self.width as usize,
            height: self.height as usize,
            timestamp,
        }))
    }

    pub fn progress(&self) -> f32 {
        if self.total_frames == 0 {
            return 0.0;
        }
        (self.current_frame as f32 / self.total_frames as f32) * 100.0
    }
}

pub fn draw_lanes(
    frame: &[u8],
    _width: i32,
    height: i32,
    lanes: &[crate::types::Lane],
) -> Result<Mat> {
    let mat = Mat::from_slice(frame)?;
    let mat = mat.reshape(3, height)?;

    let mut bgr_mat = Mat::default();
    imgproc::cvt_color(&mat, &mut bgr_mat, imgproc::COLOR_RGB2BGR, 0)?;

    let mut output = bgr_mat.try_clone()?;

    let colors = vec![
        core::Scalar::new(0.0, 0.0, 255.0, 0.0),   // Red
        core::Scalar::new(0.0, 255.0, 0.0, 0.0),   // Green
        core::Scalar::new(255.0, 0.0, 0.0, 0.0),   // Blue
        core::Scalar::new(0.0, 255.0, 255.0, 0.0), // Yellow
    ];

    for (i, lane) in lanes.iter().enumerate() {
        let color = colors[i % colors.len()];

        for point in &lane.points {
            let pt = core::Point::new(point.0 as i32, point.1 as i32);
            imgproc::circle(&mut output, pt, 3, color, -1, imgproc::LINE_8, 0)?;
        }

        for window in lane.points.windows(2) {
            let pt1 = core::Point::new(window[0].0 as i32, window[0].1 as i32);
            let pt2 = core::Point::new(window[1].0 as i32, window[1].1 as i32);
            imgproc::line(&mut output, pt1, pt2, color, 2, imgproc::LINE_AA, 0)?;
        }
    }

    Ok(output)
}
=== ./combinad ===
=== ./src/main.rs ===
// src/main.rs

mod analysis;
mod frame_buffer;
mod inference;
mod lane_detection;
mod preprocessing;
mod types;
mod video_processor;

use analysis::LaneChangeAnalyzer;
use anyhow::Result;
use frame_buffer::{
    build_legality_request, print_legality_request, save_legality_request_to_file,
    send_to_legality_api, LaneChangeFrameBuffer,
};
use std::path::Path;
use tracing::{debug, error, info, warn};
use types::{DetectedLane, Frame, Lane, LaneChangeConfig, LaneChangeEvent};

/// Configuration for legality analysis
struct LegalityAnalysisConfig {
    /// Number of frames to extract and send for analysis
    num_frames_to_analyze: usize,
    /// Maximum frames to buffer during lane change
    max_buffer_frames: usize,
    /// Whether to save the request payload to a file
    save_to_file: bool,
    /// Whether to print the request to console
    print_to_console: bool,
    /// Whether to send to the API
    send_to_api: bool,
    /// API URL for legality analysis
    api_url: String,
}

impl Default for LegalityAnalysisConfig {
    fn default() -> Self {
        Self {
            num_frames_to_analyze: 7,
            max_buffer_frames: 90,
            save_to_file: false,
            print_to_console: true,
            send_to_api: true,
            api_url: "http://localhost:3000/api/analyze".to_string(),
        }
    }
}

#[tokio::main]
async fn main() -> Result<()> {
    tracing_subscriber::fmt()
        .with_env_filter("overtake_detection=info,ort=warn")
        .init();

    info!(" Lane Change Detection System Starting");

    let config = types::Config::load("config.yaml")?;
    info!(" Configuration loaded");

    // Log key detection parameters
    info!(
        "Detection thresholds: drift={:.2}, crossing={:.2}, confirm_frames={}",
        config.detection.drift_threshold,
        config.detection.crossing_threshold,
        config.detection.confirm_frames
    );

    let mut inference_engine = inference::InferenceEngine::new(config.clone())?;
    info!(" Inference engine ready");

    let video_processor = video_processor::VideoProcessor::new(config.clone());

    let video_files = video_processor.find_video_files()?;

    if video_files.is_empty() {
        error!("No video files found in {}", config.video.input_dir);
        return Ok(());
    }

    info!("Found {} video file(s) to process", video_files.len());

    // Legality analysis configuration
    let legality_config = LegalityAnalysisConfig {
        num_frames_to_analyze: 5,
        max_buffer_frames: 90,
        save_to_file: false,
        print_to_console: true,
        send_to_api: true,
        api_url: std::env::var("LEGALITY_API_URL")
            .unwrap_or_else(|_| "http://localhost:3000/api/analyze".to_string()),
    };

    info!(" Legality API URL: {}", legality_config.api_url);

    for (idx, video_path) in video_files.iter().enumerate() {
        info!("\n========================================");
        info!(
            "Processing video {}/{}: {}",
            idx + 1,
            video_files.len(),
            video_path.display()
        );
        info!("========================================\n");

        match process_video(
            video_path,
            &mut inference_engine,
            &video_processor,
            &config,
            &legality_config,
        )
        .await
        {
            Ok(stats) => {
                info!("\n Video processed successfully!");
                info!("  Total frames: {}", stats.total_frames);
                info!(
                    "  Valid position frames: {} ({:.1}%)",
                    stats.frames_with_position,
                    100.0 * stats.frames_with_position as f64 / stats.total_frames as f64
                );
                info!("  Lane changes detected: {}", stats.lane_changes_detected);
                info!("  Events sent to API: {}", stats.events_sent_to_api);
            }
            Err(e) => {
                error!("Failed to process video: {}", e);
            }
        }
    }

    Ok(())
}

struct ProcessingStats {
    total_frames: u64,
    frames_with_position: u64,
    lane_changes_detected: usize,
    events_sent_to_api: usize,
    duration_secs: f64,
    avg_fps: f64,
}

async fn process_video(
    video_path: &Path,
    inference_engine: &mut inference::InferenceEngine,
    video_processor: &video_processor::VideoProcessor,
    config: &types::Config,
    legality_config: &LegalityAnalysisConfig,
) -> Result<ProcessingStats> {
    use std::time::Instant;

    let start_time = Instant::now();

    let mut reader = video_processor.open_video(video_path)?;

    let mut writer =
        video_processor.create_writer(video_path, reader.width, reader.height, reader.fps)?;

    // *** USE CONFIG VALUES INSTEAD OF HARDCODED ***
    let lane_change_config = LaneChangeConfig::from_detection_config(&config.detection);

    info!(
        "Lane change config: drift={:.2}, crossing={:.2}, confirm={}, cooldown={}, hysteresis={:.2}",
        lane_change_config.drift_threshold,
        lane_change_config.crossing_threshold,
        lane_change_config.min_frames_confirm,
        lane_change_config.cooldown_frames,
        lane_change_config.hysteresis_factor
    );

    let mut analyzer = LaneChangeAnalyzer::new(lane_change_config);
    analyzer.set_source_id(video_path.to_string_lossy().to_string());

    let mut lane_changes: Vec<LaneChangeEvent> = Vec::new();
    let mut frame_count: u64 = 0;
    let mut frames_with_valid_position: u64 = 0;
    let mut events_sent_to_api: usize = 0;

    let mut cached_start_frame: Option<Frame> = None;
    let mut previous_state = "CENTERED".to_string();

    // Frame buffer for capturing lane change frames
    let mut frame_buffer = LaneChangeFrameBuffer::new(legality_config.max_buffer_frames);

    // Confidence threshold from config
    let lane_confidence_threshold = config.detection.min_lane_confidence;

    // En la funcin process_video, reemplaza todo el loop while:

    while let Some(frame) = reader.read_frame()? {
        frame_count += 1;
        let timestamp_ms = frame.timestamp_ms;

        if frame_count % 50 == 0 {
            info!(
            "Progress: {:.1}% ({}/{}) | State: {} | Lane changes: {} | Buffered: {} | Pre-buffered: {}",
            reader.progress(),
            reader.current_frame,
            reader.total_frames,
            analyzer.current_state(),
            lane_changes.len(),
            frame_buffer.frame_count(),
            frame_buffer.pre_buffer_count()
        );
        }

        match process_frame(
            &frame,
            inference_engine,
            config,
            config.detection.min_lane_confidence,
        )
        .await
        {
            Ok(detected_lanes) => {
                let analysis_lanes: Vec<Lane> = detected_lanes
                    .iter()
                    .enumerate()
                    .map(|(i, dl)| Lane::from_detected(i, dl))
                    .collect();

                //  IMPORTANTE: Agregar al pre-buffer ANTES de analizar (usa previous_state)
                if previous_state == "CENTERED" {
                    frame_buffer.add_to_pre_buffer(frame.clone());
                }

                // Check if lane change completed
                if let Some(mut event) = analyzer.analyze(
                    &analysis_lanes,
                    frame.width as u32,
                    frame.height as u32,
                    frame_count,
                    timestamp_ms,
                ) {
                    info!(
                        " LANE CHANGE DETECTED: {} at {:.2}s (frame {})",
                        event.direction_name(),
                        event.video_timestamp_ms / 1000.0,
                        event.end_frame_id
                    );

                    // Get captured frames (includes pre-buffer)
                    let captured_frames = frame_buffer.stop_capture();

                    info!(
                        " Captured {} frames total (includes pre-buffer context)",
                        captured_frames.len()
                    );

                    // Build and send legality request
                    if !captured_frames.is_empty() {
                        match build_legality_request(
                            &event,
                            &captured_frames,
                            legality_config.num_frames_to_analyze,
                        ) {
                            Ok(request) => {
                                if legality_config.print_to_console {
                                    print_legality_request(&request);
                                }

                                if legality_config.save_to_file {
                                    if let Err(e) = save_legality_request_to_file(
                                        &request,
                                        &config.video.output_dir,
                                    ) {
                                        warn!("Failed to save legality request: {}", e);
                                    }
                                }

                                if legality_config.send_to_api {
                                    match send_to_legality_api(&request, &legality_config.api_url)
                                        .await
                                    {
                                        Ok(response) => {
                                            info!(
                                                " Event {} sent to API: {} - {}",
                                                response.event_id,
                                                response.status,
                                                response.message
                                            );
                                            events_sent_to_api += 1;
                                        }
                                        Err(e) => {
                                            error!(" Failed to send event to API: {}", e);
                                        }
                                    }
                                }
                            }
                            Err(e) => {
                                warn!("Failed to build legality request: {}", e);
                            }
                        }
                    } else {
                        warn!("No frames captured for lane change event");
                    }

                    // Save evidence images (use first captured frame as start)
                    let video_stem = video_path.file_stem().unwrap().to_str().unwrap();
                    let start_filename =
                        format!("{}_event_{}_start.jpg", video_stem, event.event_id);
                    let end_filename = format!("{}_event_{}_end.jpg", video_stem, event.event_id);

                    let mut start_path_str = String::new();
                    let mut end_path_str = String::new();

                    // Use first captured frame (from pre-buffer) as start
                    if !captured_frames.is_empty() {
                        if let Ok(path) =
                            video_processor.save_frame_to_disk(&captured_frames[0], &start_filename)
                        {
                            start_path_str = path.to_string_lossy().to_string();
                        }
                    }

                    if let Ok(path) = video_processor.save_frame_to_disk(&frame, &end_filename) {
                        end_path_str = path.to_string_lossy().to_string();
                    }

                    event.evidence_images = Some(types::EvidencePaths {
                        start_image_path: start_path_str,
                        end_image_path: end_path_str,
                    });

                    lane_changes.push(event);
                }

                //  Obtener current_state DESPUS del anlisis
                let current_state = analyzer.current_state().to_string();

                // Start capturing when CENTERED -> DRIFTING
                if previous_state == "CENTERED" && current_state == "DRIFTING" {
                    frame_buffer.start_capture(frame_count);
                    debug!(
                        " Started capturing at frame {} (with pre-buffer)",
                        frame_count
                    );
                }

                // Continue capturing during lane change
                if frame_buffer.is_capturing() {
                    frame_buffer.add_frame(frame.clone());
                }

                // Cancel if returned to CENTERED without completing
                if current_state == "CENTERED" && frame_buffer.is_capturing() {
                    frame_buffer.cancel_capture();
                    debug!(" Lane change cancelled");
                }

                //  Actualizar previous_state al final
                previous_state = current_state;

                if frame_count % 50 == 0 {
                    if let Some(vs) = analyzer.last_vehicle_state() {
                        if vs.is_valid() {
                            let normalized = vs.normalized_offset().unwrap_or(0.0);
                            let width = vs.lane_width.unwrap_or(0.0);
                            if normalized.abs() > 0.1 {
                                info!(
                                "Frame {}: State={} | Offset: {:.1}px ({:.1}%) | Width: {:.0}px",
                                frame_count,
                                analyzer.current_state(),
                                vs.lateral_offset,
                                normalized * 100.0,
                                width
                            );
                            }
                        }
                    }
                }

                if analyzer
                    .last_vehicle_state()
                    .map_or(false, |s| s.is_valid())
                {
                    frames_with_valid_position += 1;
                }

                if let Some(ref mut w) = writer {
                    if let Ok(annotated) = video_processor::draw_lanes_with_state(
                        &frame.data,
                        reader.width,
                        reader.height,
                        &detected_lanes,
                        analyzer.current_state(),
                        analyzer.last_vehicle_state(),
                    ) {
                        use opencv::videoio::VideoWriterTrait;
                        w.write(&annotated)?;
                    }
                }
            }
            Err(e) => error!("Frame {} failed: {}", frame_count, e),
        }
    }

    let duration = start_time.elapsed();
    let avg_fps = frame_count as f64 / duration.as_secs_f64();

    info!("\n Final Report:");
    info!("  Total Lane Changes: {}", lane_changes.len());
    info!("  Events Sent to API: {}", events_sent_to_api);
    info!("  Processing Speed: {:.1} FPS", avg_fps);

    for (i, event) in lane_changes.iter().enumerate() {
        info!(
            "  {}. {} at {:.2}s (confidence: {:.2})",
            i + 1,
            event.direction_name(),
            event.video_timestamp_ms / 1000.0,
            event.confidence
        );
    }

    save_results(video_path, &lane_changes, config)?;

    Ok(ProcessingStats {
        total_frames: frame_count,
        frames_with_position: frames_with_valid_position,
        lane_changes_detected: lane_changes.len(),
        events_sent_to_api,
        duration_secs: duration.as_secs_f64(),
        avg_fps,
    })
}

async fn process_frame(
    frame: &Frame,
    inference_engine: &mut inference::InferenceEngine,
    config: &types::Config,
    confidence_threshold: f32,
) -> Result<Vec<DetectedLane>> {
    let preprocessed = preprocessing::preprocess(
        &frame.data,
        frame.width,
        frame.height,
        config.model.input_width,
        config.model.input_height,
    )?;

    let output = inference_engine.infer(&preprocessed)?;

    let lane_detection = lane_detection::parse_lanes(
        &output,
        frame.width as f32,
        frame.height as f32,
        config,
        frame.timestamp_ms,
    )?;

    // Use config threshold instead of hardcoded
    let high_confidence_lanes: Vec<DetectedLane> = lane_detection
        .lanes
        .into_iter()
        .filter(|lane| {
            lane.confidence > confidence_threshold
                && lane.points.len() >= config.detection.min_points_per_lane
        })
        .collect();

    Ok(high_confidence_lanes)
}

fn save_results(
    video_path: &Path,
    lane_changes: &[LaneChangeEvent],
    config: &types::Config,
) -> Result<()> {
    use std::fs::File;
    use std::io::Write;

    std::fs::create_dir_all(&config.video.output_dir)?;
    let video_name = video_path.file_stem().unwrap().to_str().unwrap();
    let jsonl_path =
        Path::new(&config.video.output_dir).join(format!("{}_lane_changes.jsonl", video_name));

    let mut file = File::create(&jsonl_path)?;
    for event in lane_changes {
        let json_line = serde_json::to_string(&event.to_json())?;
        writeln!(file, "{}", json_line)?;
    }
    info!(" Saved to: {}", jsonl_path.display());
    Ok(())
}
=== ./src/inference.rs ===
// src/inference.rs

use crate::types::Config;
use anyhow::{Context, Result};
use ort::{
    execution_providers::CUDAExecutionProvider,
    session::{builder::GraphOptimizationLevel, Session},
};
use tracing::{debug, info};

pub struct InferenceEngine {
    session: Session,
    config: Config,
}

impl InferenceEngine {
    pub fn new(config: Config) -> Result<Self> {
        info!("Initializing inference engine");
        info!("Model path: {}", config.model.path);

        let mut session_builder = Session::builder()?;

        // CUDA execution provider
        info!("Enabling CUDA execution provider");
        session_builder =
            session_builder.with_execution_providers([CUDAExecutionProvider::default()
                .with_device_id(0)
                .build()])?;

        info!("Building ONNX Runtime session...");
        let session = session_builder
            .with_optimization_level(GraphOptimizationLevel::Level3)?
            .with_intra_threads(config.inference.num_threads)?
            .with_inter_threads(1)?
            .commit_from_file(&config.model.path)
            .context("Failed to load model")?;

        info!(" Inference engine initialized successfully");

        Ok(Self { session, config })
    }

    pub fn infer(&mut self, input: &[f32]) -> Result<Vec<f32>> {
        debug!("Running inference");

        // Create shape tuple
        let shape = [
            1,
            3,
            self.config.model.input_height,
            self.config.model.input_width,
        ];

        // Create input value from tuple (shape, data)
        let input_value =
            ort::value::Value::from_array((shape.as_slice(), input.to_vec().into_boxed_slice()))?;

        // Run inference
        let outputs = self.session.run(ort::inputs!["input" => input_value])?;

        // Extract output
        let output = &outputs[0];
        let (output_shape, data_slice) = output.try_extract_tensor::<f32>()?;

        // Convert slice to Vec
        let output_data: Vec<f32> = data_slice.to_vec();

        Ok(output_data)
    }
}
=== ./src/smoother.rs ===
// src/smoother.rs

use crate::types::VehiclePosition;
use std::collections::{HashMap, VecDeque};

/// Temporal smoother for vehicle position using a sliding window
pub struct LanePositionSmoother {
    history: VecDeque<VehiclePosition>,
    window_size: usize,
}

impl LanePositionSmoother {
    /// Create a new smoother with specified window size
    ///
    /// # Arguments
    /// * `window_size` - Number of frames to use for smoothing (e.g., 10 frames)
    pub fn new(window_size: usize) -> Self {
        Self {
            history: VecDeque::with_capacity(window_size),
            window_size,
        }
    }

    /// Smooth the current position using temporal window
    ///
    /// Uses different strategies for different components:
    /// - Lane index: Mode (most common value)
    /// - Lateral offset: Median (resistant to outliers)
    /// - Confidence: Average
    pub fn smooth(&mut self, position: VehiclePosition) -> VehiclePosition {
        self.history.push_back(position);

        // Maintain window size
        if self.history.len() > self.window_size {
            self.history.pop_front();
        }

        // Need at least 3 frames for meaningful smoothing
        if self.history.len() < 3 {
            return position;
        }

        VehiclePosition {
            lane_index: self.smooth_lane_index(),
            lateral_offset: self.smooth_lateral_offset(),
            confidence: self.smooth_confidence(),
            timestamp: position.timestamp, // Keep current timestamp
        }
    }

    /// Get the most common lane index (mode)
    fn smooth_lane_index(&self) -> i32 {
        let mut counts: HashMap<i32, usize> = HashMap::new();

        for pos in &self.history {
            *counts.entry(pos.lane_index).or_insert(0) += 1;
        }

        counts
            .into_iter()
            .max_by_key(|(_, count)| *count)
            .map(|(lane, _)| lane)
            .unwrap_or(-1)
    }

    /// Get median lateral offset (resistant to outliers)
    fn smooth_lateral_offset(&self) -> f32 {
        let mut offsets: Vec<f32> = self.history.iter().map(|p| p.lateral_offset).collect();
        offsets.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
        offsets[offsets.len() / 2]
    }

    /// Get average confidence
    fn smooth_confidence(&self) -> f32 {
        let sum: f32 = self.history.iter().map(|p| p.confidence).sum();
        sum / self.history.len() as f32
    }

    /// Reset the smoother (e.g., when video changes)
    pub fn reset(&mut self) {
        self.history.clear();
    }

    /// Get the number of frames currently in the history
    pub fn history_size(&self) -> usize {
        self.history.len()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_smoother_mode_for_lane_index() {
        let mut smoother = LanePositionSmoother::new(5);

        // Feed noisy lane detections: [1, 1, 2, 1, 1]
        let positions = vec![
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.0,
            },
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.033,
            },
            VehiclePosition {
                lane_index: 2, // noise
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.066,
            },
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.099,
            },
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.132,
            },
        ];

        for pos in positions {
            smoother.smooth(pos);
        }

        // Last smoothed position should have lane_index = 1 (mode)
        let last_pos = positions.last().unwrap();
        let smoothed = smoother.smooth(*last_pos);
        assert_eq!(smoothed.lane_index, 1);
    }

    #[test]
    fn test_smoother_median_for_offset() {
        let mut smoother = LanePositionSmoother::new(5);

        // Feed offsets with outlier: [-0.1, -0.05, 0.0, 0.05, 2.0 (outlier)]
        let offsets = vec![-0.1, -0.05, 0.0, 0.05, 2.0];

        for (i, offset) in offsets.iter().enumerate() {
            let pos = VehiclePosition {
                lane_index: 1,
                lateral_offset: *offset,
                confidence: 0.8,
                timestamp: i as f64 * 0.033,
            };
            smoother.smooth(pos);
        }

        let last_pos = VehiclePosition {
            lane_index: 1,
            lateral_offset: 2.0,
            confidence: 0.8,
            timestamp: 0.165,
        };
        let smoothed = smoother.smooth(last_pos);

        // Median should be 0.0 (middle value), not affected by 2.0 outlier
        assert_eq!(smoothed.lateral_offset, 0.0);
    }
}
=== ./src/debug.rs ===
use opencv::{core, imgproc, prelude::*};

pub fn visualize_lanes(frame: &Mat, lanes: &[Lane], position: &VehiclePosition) -> Result<Mat> {
    let mut debug_frame = frame.clone();

    // Draw detected lanes with different colors
    let colors = [
        core::Scalar::new(255.0, 0.0, 0.0, 0.0),   // Blue - Lane 0
        core::Scalar::new(0.0, 255.0, 0.0, 0.0),   // Green - Lane 1
        core::Scalar::new(0.0, 0.0, 255.0, 0.0),   // Red - Lane 2
        core::Scalar::new(255.0, 255.0, 0.0, 0.0), // Cyan - Lane 3
    ];

    for (i, lane) in lanes.iter().enumerate() {
        // Draw lane points
        for window in lane.points.windows(2) {
            let p1 = core::Point::new(window[0].x as i32, window[0].y as i32);
            let p2 = core::Point::new(window[1].x as i32, window[1].y as i32);
            imgproc::line(
                &mut debug_frame,
                p1,
                p2,
                colors[i % 4],
                3,
                imgproc::LINE_8,
                0,
            )?;
        }

        // Draw lane ID
        if let Some(first_point) = lane.points.first() {
            imgproc::put_text(
                &mut debug_frame,
                &format!("L{} ({:.2})", i, lane.confidence),
                core::Point::new(first_point.x as i32, first_point.y as i32 - 10),
                imgproc::FONT_HERSHEY_SIMPLEX,
                0.6,
                colors[i % 4],
                2,
                imgproc::LINE_8,
                false,
            )?;
        }
    }

    // Draw vehicle position indicator
    let vehicle_x = frame.cols() / 2;
    let vehicle_y = (frame.rows() as f32 * 0.85) as i32;

    imgproc::circle(
        &mut debug_frame,
        core::Point::new(vehicle_x, vehicle_y),
        10,
        core::Scalar::new(0.0, 255.0, 255.0, 0.0), // Yellow
        -1,
        imgproc::LINE_8,
        0,
    )?;

    // Draw current lane info
    let info = format!(
        "Lane: {} | Offset: {:.2} | Conf: {:.2}",
        position.lane_index, position.lateral_offset, position.confidence
    );
    imgproc::put_text(
        &mut debug_frame,
        &info,
        core::Point::new(10, 30),
        imgproc::FONT_HERSHEY_SIMPLEX,
        0.8,
        core::Scalar::new(0.0, 255.0, 0.0, 0.0),
        2,
        imgproc::LINE_8,
        false,
    )?;

    Ok(debug_frame)
}
=== ./src/video_processor.rs ===
// src/video_processor.rs

use crate::types::{Config, DetectedLane, VehicleState};
use anyhow::Result;
use opencv::{
    core::{self, Mat, Vector},
    imgcodecs, imgproc,
    prelude::*,
    videoio::{self, VideoCapture, VideoCaptureTraitConst, VideoWriter},
};
use std::path::{Path, PathBuf};
use tracing::info;
use walkdir::WalkDir;

pub struct VideoProcessor {
    config: Config,
}

impl VideoProcessor {
    pub fn new(config: Config) -> Self {
        Self { config }
    }

    pub fn find_video_files(&self) -> Result<Vec<PathBuf>> {
        let mut videos = Vec::new();
        let video_extensions = vec!["mp4", "avi", "mov", "mkv", "MP4", "AVI", "MOV", "MKV"];

        for entry in WalkDir::new(&self.config.video.input_dir)
            .follow_links(true)
            .into_iter()
            .filter_map(|e| e.ok())
        {
            let path = entry.path();
            if let Some(ext) = path.extension() {
                if video_extensions.contains(&ext.to_str().unwrap_or("")) {
                    videos.push(path.to_path_buf());
                }
            }
        }
        info!("Found {} video files", videos.len());
        Ok(videos)
    }

    pub fn open_video(&self, path: &Path) -> Result<VideoReader> {
        info!("Opening video: {}", path.display());
        let cap = VideoCapture::from_file(path.to_str().unwrap(), videoio::CAP_ANY)?;

        if !cap.is_opened()? {
            anyhow::bail!("Failed to open video file");
        }

        let fps = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FPS)?;
        let total_frames = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FRAME_COUNT)? as i32;
        let width = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FRAME_WIDTH)? as i32;
        let height = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FRAME_HEIGHT)? as i32;

        Ok(VideoReader {
            cap,
            fps,
            total_frames,
            current_frame: 0,
            width,
            height,
        })
    }

    pub fn create_writer(
        &self,
        input_path: &Path,
        width: i32,
        height: i32,
        fps: f64,
    ) -> Result<Option<VideoWriter>> {
        if !self.config.video.save_annotated {
            return Ok(None);
        }
        std::fs::create_dir_all(&self.config.video.output_dir)?;
        let input_name = input_path.file_stem().unwrap().to_str().unwrap();
        let output_path = PathBuf::from(&self.config.video.output_dir)
            .join(format!("{}_annotated.mp4", input_name));

        let fourcc = VideoWriter::fourcc('m', 'p', '4', 'v')?;
        let writer = VideoWriter::new(
            output_path.to_str().unwrap(),
            fourcc,
            fps,
            core::Size::new(width, height),
            true,
        )?;
        Ok(Some(writer))
    }

    /// Save a specific frame as an image file
    pub fn save_frame_to_disk(
        &self,
        frame: &crate::types::Frame,
        filename: &str,
    ) -> Result<PathBuf> {
        let output_dir = Path::new(&self.config.video.output_dir).join("evidence");
        std::fs::create_dir_all(&output_dir)?;

        let file_path = output_dir.join(filename);

        // Frame data is RGB, OpenCV needs BGR
        let mat = Mat::from_slice(&frame.data)?;
        let mat = mat.reshape(3, frame.height as i32)?;

        let mut bgr_mat = Mat::default();
        imgproc::cvt_color(&mat, &mut bgr_mat, imgproc::COLOR_RGB2BGR, 0)?;

        // Use imgcodecs::imwrite
        let params = Vector::new();
        imgcodecs::imwrite(file_path.to_str().unwrap(), &bgr_mat, &params)?;

        Ok(file_path)
    }
}

pub struct VideoReader {
    pub cap: VideoCapture,
    pub fps: f64,
    pub total_frames: i32,
    pub current_frame: i32,
    pub width: i32,
    pub height: i32,
}

impl VideoReader {
    pub fn read_frame(&mut self) -> Result<Option<crate::types::Frame>> {
        use opencv::videoio::VideoCaptureTrait;
        let mut mat = Mat::default();
        if !VideoCaptureTrait::read(&mut self.cap, &mut mat)? || mat.empty() {
            return Ok(None);
        }
        self.current_frame += 1;
        let timestamp_ms = (self.current_frame as f64 / self.fps) * 1000.0;

        let mut rgb_mat = Mat::default();
        imgproc::cvt_color(&mat, &mut rgb_mat, imgproc::COLOR_BGR2RGB, 0)?;
        let data = rgb_mat.data_bytes()?.to_vec();

        Ok(Some(crate::types::Frame {
            data,
            width: self.width as usize,
            height: self.height as usize,
            timestamp_ms,
        }))
    }

    pub fn progress(&self) -> f32 {
        if self.total_frames == 0 {
            return 0.0;
        }
        (self.current_frame as f32 / self.total_frames as f32) * 100.0
    }
}

pub fn draw_lanes_with_state(
    frame: &[u8],
    width: i32,
    height: i32,
    lanes: &[DetectedLane],
    state: &str,
    vehicle_state: Option<&VehicleState>,
) -> Result<Mat> {
    let mat = Mat::from_slice(frame)?;
    let mat = mat.reshape(3, height)?;
    let mut bgr_mat = Mat::default();
    imgproc::cvt_color(&mat, &mut bgr_mat, imgproc::COLOR_RGB2BGR, 0)?;
    let mut output = bgr_mat.try_clone()?;

    let colors = vec![
        core::Scalar::new(0.0, 0.0, 255.0, 0.0),
        core::Scalar::new(0.0, 255.0, 0.0, 0.0),
        core::Scalar::new(255.0, 0.0, 0.0, 0.0),
        core::Scalar::new(0.0, 255.0, 255.0, 0.0),
    ];

    for (i, lane) in lanes.iter().enumerate() {
        let color = colors[i % colors.len()];
        for point in &lane.points {
            let pt = core::Point::new(point.0 as i32, point.1 as i32);
            imgproc::circle(&mut output, pt, 3, color, -1, imgproc::LINE_8, 0)?;
        }
    }

    let vehicle_x = width / 2;
    let vehicle_y = (height as f32 * 0.85) as i32;
    imgproc::circle(
        &mut output,
        core::Point::new(vehicle_x, vehicle_y),
        10,
        core::Scalar::new(0.0, 255.0, 255.0, 0.0),
        -1,
        imgproc::LINE_8,
        0,
    )?;

    imgproc::put_text(
        &mut output,
        &format!("State: {}", state),
        core::Point::new(15, 32),
        imgproc::FONT_HERSHEY_SIMPLEX,
        0.8,
        core::Scalar::new(0.0, 255.0, 0.0, 0.0),
        2,
        imgproc::LINE_8,
        false,
    )?;

    if let Some(vs) = vehicle_state {
        if vs.is_valid() {
            let normalized = vs.normalized_offset().unwrap_or(0.0);
            let info = format!(
                "Offset: {:.1}px ({:+.1}%)",
                vs.lateral_offset,
                normalized * 100.0
            );
            imgproc::put_text(
                &mut output,
                &info,
                core::Point::new(200, 32),
                imgproc::FONT_HERSHEY_SIMPLEX,
                0.5,
                core::Scalar::new(255.0, 255.0, 255.0, 0.0),
                1,
                imgproc::LINE_8,
                false,
            )?;
        }
    }

    Ok(output)
}
=== ./src/lane_detection.rs ===
// src/lane_detection.rs

use crate::types::{Config, DetectedLane};
use anyhow::Result;
use tracing::debug;

pub struct LaneDetectionResult {
    pub lanes: Vec<DetectedLane>,
    pub timestamp_ms: f64,
}

/// Softmax along first axis
fn softmax_axis0(data: &[f32], dim0: usize, dim1: usize, dim2: usize) -> Vec<f32> {
    let mut result = vec![0.0f32; data.len()];

    for j in 0..dim1 {
        for k in 0..dim2 {
            // Find max for numerical stability
            let mut max_val = f32::NEG_INFINITY;
            for i in 0..dim0 {
                let idx = i * (dim1 * dim2) + j * dim2 + k;
                if data[idx] > max_val {
                    max_val = data[idx];
                }
            }

            // Compute exp and sum
            let mut sum = 0.0f32;
            for i in 0..dim0 {
                let idx = i * (dim1 * dim2) + j * dim2 + k;
                let exp_val = (data[idx] - max_val).exp();
                result[idx] = exp_val;
                sum += exp_val;
            }

            // Normalize
            for i in 0..dim0 {
                let idx = i * (dim1 * dim2) + j * dim2 + k;
                result[idx] /= sum;
            }
        }
    }

    result
}

pub fn parse_lanes(
    output: &[f32],
    frame_width: f32,
    frame_height: f32,
    config: &Config,
    timestamp_ms: f64,
) -> Result<LaneDetectionResult> {
    let griding_num = config.model.griding_num; // 200
    let num_anchors = config.model.num_anchors; // 72
    let num_lanes = config.model.num_lanes; // 4

    // Expected size for loc_row tensor [200, 72, 4]
    let loc_row_size = griding_num * num_anchors * num_lanes;

    if output.len() < loc_row_size {
        anyhow::bail!(
            "Output size mismatch: expected {}, got {}",
            loc_row_size,
            output.len()
        );
    }

    // Constants matching Python
    const ROW_ANCHOR_START: f32 = 160.0;
    const ROW_ANCHOR_END: f32 = 710.0;
    const ORIGINAL_HEIGHT: f32 = 720.0;

    // Apply softmax along grid dimension (like Python)
    let loc_row_prob = softmax_axis0(output, griding_num, num_anchors, num_lanes);

    let mut lanes = Vec::new();

    for lane_idx in 0..num_lanes {
        let mut points: Vec<(f32, f32)> = Vec::new();
        let mut total_confidence = 0.0;
        let mut valid_points = 0;

        for anchor_idx in 0..num_anchors {
            // Find argmax along grid dimension (after softmax)
            let mut max_prob = f32::NEG_INFINITY;
            let mut max_grid_idx = 0;

            for grid_idx in 0..griding_num {
                let idx = grid_idx * (num_anchors * num_lanes) + anchor_idx * num_lanes + lane_idx;
                let prob = loc_row_prob[idx];
                if prob > max_prob {
                    max_prob = prob;
                    max_grid_idx = grid_idx;
                }
            }

            // Skip grid_idx == 0 (no lane class) - matches Python
            if max_grid_idx == 0 {
                continue;
            }

            // Only include points with reasonable confidence
            if max_prob < 0.1 {
                continue;
            }

            // Calculate X coordinate - matches Python exactly
            // Python: x_norm = (grid_idx - 1) / (num_grid_cells - 1)
            let x_norm = (max_grid_idx as f32 - 1.0) / (griding_num as f32 - 1.0);
            let x = x_norm * frame_width;

            // Calculate Y coordinate - matches Python exactly
            // Python: np.linspace(160, 710, 72)
            let y_norm = ROW_ANCHOR_START
                + (ROW_ANCHOR_END - ROW_ANCHOR_START)
                    * (anchor_idx as f32 / (num_anchors as f32 - 1.0));
            let y = (y_norm / ORIGINAL_HEIGHT) * frame_height;

            points.push((x, y));
            total_confidence += max_prob;
            valid_points += 1;
        }

        // Require minimum points per lane
        if points.len() >= config.detection.min_points_per_lane {
            let avg_confidence = if valid_points > 0 {
                total_confidence / valid_points as f32
            } else {
                0.0
            };

            // Sort points by Y (bottom to top for consistency)
            points.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));

            lanes.push(DetectedLane {
                points,
                confidence: avg_confidence,
            });
        }
    }

    debug!("Detected {} lanes", lanes.len());

    Ok(LaneDetectionResult {
        lanes,
        timestamp_ms,
    })
}
=== ./src/analysis/velocity_tracker.rs ===
// src/analysis/velocity_tracker.rs

use std::collections::VecDeque;

pub struct LateralVelocityTracker {
    offset_history: VecDeque<(f32, f64)>, // (offset_px, timestamp_ms)
    history_size: usize,
}

impl LateralVelocityTracker {
    pub fn new() -> Self {
        Self {
            offset_history: VecDeque::with_capacity(20),
            history_size: 20,
        }
    }

    pub fn get_velocity(&mut self, offset_px: f32, timestamp_ms: f64) -> f32 {
        self.offset_history.push_back((offset_px, timestamp_ms));

        if self.offset_history.len() > self.history_size {
            self.offset_history.pop_front();
        }

        if self.offset_history.len() < 5 {
            return 0.0;
        }

        // Calculate velocity over the entire history window
        let first = self.offset_history.front().unwrap();
        let last = self.offset_history.back().unwrap();

        let delta_offset = last.0 - first.0;
        let delta_time = (last.1 - first.1) / 1000.0; // Convert to seconds

        if delta_time > 0.01 {
            // Avoid division by near-zero
            let velocity = delta_offset / delta_time as f32; // pixels per second
            velocity
        } else {
            0.0
        }
    }

    #[allow(dead_code)]
    pub fn is_moving_laterally(&self, min_velocity_px_per_sec: f32) -> bool {
        if self.offset_history.len() < 5 {
            return false;
        }

        let first = self.offset_history.front().unwrap();
        let last = self.offset_history.back().unwrap();

        let delta_offset = (last.0 - first.0).abs();
        let delta_time = (last.1 - first.1) / 1000.0;

        if delta_time > 0.01 {
            let velocity = delta_offset / delta_time as f32;
            velocity > min_velocity_px_per_sec
        } else {
            false
        }
    }

    pub fn reset(&mut self) {
        self.offset_history.clear();
    }
}
=== ./src/analysis/state_machine.rs ===
// src/analysis/state_machine.rs
//
// LANE CHANGE DETECTION v3.4 - BALANCED VALIDATION
//

use super::boundary_detector::CrossingType;
use super::curve_detector::CurveDetector;
use super::velocity_tracker::LateralVelocityTracker;
use crate::types::{Direction, LaneChangeConfig, LaneChangeEvent, LaneChangeState, VehicleState};
use std::collections::VecDeque;
use tracing::{debug, info, warn};

// ============================================================================
// VELOCITY THRESHOLDS
// ============================================================================
const MIN_VELOCITY_FAST: f32 = 120.0;
const MIN_VELOCITY_MEDIUM: f32 = 60.0;
const MIN_VELOCITY_SLOW: f32 = 20.0;
const VELOCITY_SPIKE_THRESHOLD: f32 = 200.0;

// ============================================================================
// ANALYSIS WINDOWS
// ============================================================================
const ANALYSIS_WINDOW_MS: f64 = 4000.0;
const TRAJECTORY_WINDOW_SIZE: usize = 90;

// ============================================================================
// DEVIATION THRESHOLDS
// ============================================================================
const DEVIATION_DRIFT_START: f32 = 0.22;
const DEVIATION_CROSSING: f32 = 0.30;
const DEVIATION_LANE_CENTER: f32 = 0.55;
const DEVIATION_SIGNIFICANT: f32 = 0.45;

// ============================================================================
// STATE MACHINE BEHAVIOR
// ============================================================================
const HYSTERESIS_EXIT: f32 = 0.5;
const DIRECTION_CONSISTENCY_THRESHOLD: f32 = 0.65;
const POST_CHANGE_GRACE_FRAMES: u32 = 90;
const MAX_DRIFTING_MS: f64 = 10000.0;

// ============================================================================
// KALMAN FILTER
// ============================================================================
const KALMAN_PROCESS_NOISE: f32 = 0.001;
const KALMAN_MEASUREMENT_NOISE: f32 = 0.01;

// ============================================================================
// ADAPTIVE BASELINE
// ============================================================================
const EWMA_ALPHA_STABLE: f32 = 0.003;
const EWMA_ALPHA_ADAPTING: f32 = 0.015;
const EWMA_MIN_SAMPLES: u32 = 30;
const STABILITY_VARIANCE_THRESHOLD: f32 = 0.005;
const INSTABILITY_VARIANCE_THRESHOLD: f32 = 0.05;
const BASELINE_MAX_DRIFT: f32 = 0.25;
const BASELINE_SANITY_CHECK: f32 = 0.35; // Increased to allow more baseline variation

// ============================================================================
// CURVE DETECTION
// ============================================================================
const CURVE_COMPENSATION_FACTOR: f32 = 1.0;
const CURVE_CURVATURE_THRESHOLD: f32 = 0.015;

// ============================================================================
// VALIDATION THRESHOLDS - BALANCED
// ============================================================================
const VERY_HIGH_OFFSET_THRESHOLD: f32 = 0.55; // 55% = very confident, minimal checks
const HIGH_OFFSET_THRESHOLD: f32 = 0.45; // 45% = confident, need some duration
const MEDIUM_OFFSET_THRESHOLD: f32 = 0.35; // 35% = need duration + trajectory
const LOW_OFFSET_THRESHOLD: f32 = 0.25; // 25% = strict validation

// Duration thresholds - RELAXED
const MIN_DURATION_VERY_HIGH: f64 = 800.0; // 0.8s for very high offset
const MIN_DURATION_HIGH: f64 = 1000.0; // 1.2s for high offset
const MIN_DURATION_MEDIUM: f64 = 1500.0; // 2.0s for medium offset
const MIN_DURATION_LOW: f64 = 2500.0; // 3.0s for low offset

const MIN_NET_DISPLACEMENT: f32 = 0.15;

// ============================================================================
// TRAJECTORY ANALYSIS - MORE PERMISSIVE
// ============================================================================
const RETURN_TO_CENTER_THRESHOLD: f32 = 0.35;
const MIN_EXCURSION_FOR_OVERTAKE: f32 = 0.30;
const TRAJECTORY_SMOOTHNESS_THRESHOLD: f32 = 0.25;
const MIN_TRAJECTORY_POINTS: usize = 8;

const POSITION_CHANGE_THRESHOLD: f32 = 0.15;

// ============================================================================
// KALMAN FILTER
// ============================================================================

#[derive(Clone)]
struct SimpleKalmanFilter {
    x: f32,
    p: f32,
    q: f32,
    r: f32,
    initialized: bool,
}

impl SimpleKalmanFilter {
    fn new() -> Self {
        Self {
            x: 0.0,
            p: 1.0,
            q: KALMAN_PROCESS_NOISE,
            r: KALMAN_MEASUREMENT_NOISE,
            initialized: false,
        }
    }

    fn update(&mut self, measurement: f32) -> f32 {
        if !self.initialized {
            self.x = measurement;
            self.p = self.r;
            self.initialized = true;
            return measurement;
        }
        let p_pred = self.p + self.q;
        let k = p_pred / (p_pred + self.r);
        self.x = self.x + k * (measurement - self.x);
        self.p = (1.0 - k) * p_pred;
        self.x
    }

    fn reset(&mut self) {
        self.x = 0.0;
        self.p = 1.0;
        self.initialized = false;
    }
}

// ============================================================================
// ADAPTIVE BASELINE
// ============================================================================

#[derive(Clone)]
struct AdaptiveBaseline {
    value: f32,
    initial_value: f32,
    variance: f32,
    sample_count: u32,
    is_valid: bool,
    recent_samples: VecDeque<f32>,
    is_adapting: bool,
    stable_frames: u32,
    is_frozen: bool,
    frozen_value: f32,
    has_initial: bool,
}

impl AdaptiveBaseline {
    fn new() -> Self {
        Self {
            value: 0.0,
            initial_value: 0.0,
            variance: 1.0,
            sample_count: 0,
            is_valid: false,
            recent_samples: VecDeque::with_capacity(30),
            is_adapting: true,
            stable_frames: 0,
            is_frozen: false,
            frozen_value: 0.0,
            has_initial: false,
        }
    }

    fn freeze(&mut self) {
        if !self.is_frozen {
            self.is_frozen = true;
            self.frozen_value = self.value;
            info!(" Baseline frozen at {:.1}%", self.frozen_value * 100.0);
        }
    }

    fn unfreeze(&mut self) {
        if self.is_frozen {
            self.is_frozen = false;
            debug!(" Baseline unfrozen");
        }
    }

    fn effective_value(&self) -> f32 {
        if self.is_frozen {
            self.frozen_value
        } else {
            self.value
        }
    }

    fn is_sane(&self) -> bool {
        self.value.abs() < BASELINE_SANITY_CHECK
    }

    fn update(&mut self, measurement: f32) -> f32 {
        self.sample_count += 1;

        self.recent_samples.push_back(measurement);
        if self.recent_samples.len() > 30 {
            self.recent_samples.pop_front();
        }

        if self.recent_samples.len() >= 10 {
            let samples: Vec<f32> = self.recent_samples.iter().copied().collect();
            let mean: f32 = samples.iter().sum::<f32>() / samples.len() as f32;
            self.variance =
                samples.iter().map(|x| (x - mean).powi(2)).sum::<f32>() / samples.len() as f32;
        }

        if self.is_frozen {
            return self.frozen_value;
        }

        let deviation_from_baseline = (measurement - self.value).abs();

        if self.variance < STABILITY_VARIANCE_THRESHOLD {
            self.stable_frames += 1;
            if self.stable_frames > 30 {
                self.is_adapting = false;
            }
        } else {
            self.stable_frames = 0;
            if deviation_from_baseline > 0.15 {
                self.is_adapting = true;
            }
        }

        let alpha = if self.is_adapting || !self.is_valid {
            EWMA_ALPHA_ADAPTING
        } else {
            EWMA_ALPHA_STABLE
        };

        if self.sample_count == 1 {
            self.value = measurement;
        } else {
            let new_value = alpha * measurement + (1.0 - alpha) * self.value;

            if self.has_initial {
                let drift = (new_value - self.initial_value).abs();
                if drift <= BASELINE_MAX_DRIFT {
                    self.value = new_value;
                }
            } else {
                self.value = new_value;
            }
        }

        if !self.has_initial
            && self.sample_count >= EWMA_MIN_SAMPLES
            && self.variance < INSTABILITY_VARIANCE_THRESHOLD
        {
            self.initial_value = self.value;
            self.has_initial = true;
            self.is_valid = true;
        }

        if self.sample_count >= EWMA_MIN_SAMPLES && self.variance < INSTABILITY_VARIANCE_THRESHOLD {
            self.is_valid = true;
        }

        self.value
    }

    fn reset(&mut self) {
        self.value = 0.0;
        self.initial_value = 0.0;
        self.variance = 1.0;
        self.sample_count = 0;
        self.is_valid = false;
        self.recent_samples.clear();
        self.is_adapting = true;
        self.stable_frames = 0;
        self.is_frozen = false;
        self.frozen_value = 0.0;
        self.has_initial = false;
    }
}

// ============================================================================
// TRAJECTORY ANALYZER - MORE PERMISSIVE
// ============================================================================

#[derive(Clone)]
struct TrajectoryAnalyzer {
    positions: VecDeque<f32>,
    timestamps: VecDeque<f64>,
    velocities: VecDeque<f32>,
}

#[derive(Default, Debug, Clone)]
struct OvertakeAnalysis {
    excursion_sufficient: bool,
    returned_to_start: bool,
    is_smooth: bool,
    has_reversal: bool,
    shape_score: f32,
    smoothness: f32,
    is_valid_overtake: bool,
}

impl TrajectoryAnalyzer {
    fn new() -> Self {
        Self {
            positions: VecDeque::with_capacity(TRAJECTORY_WINDOW_SIZE),
            timestamps: VecDeque::with_capacity(TRAJECTORY_WINDOW_SIZE),
            velocities: VecDeque::with_capacity(TRAJECTORY_WINDOW_SIZE),
        }
    }

    fn add_sample(&mut self, position: f32, timestamp: f64, velocity: f32) {
        self.positions.push_back(position);
        self.timestamps.push_back(timestamp);
        self.velocities.push_back(velocity);

        if self.positions.len() > TRAJECTORY_WINDOW_SIZE {
            self.positions.pop_front();
            self.timestamps.pop_front();
            self.velocities.pop_front();
        }
    }

    fn analyze_overtake_pattern(
        &self,
        start_pos: f32,
        current_pos: f32,
        max_excursion: f32,
    ) -> OvertakeAnalysis {
        let mut analysis = OvertakeAnalysis::default();

        // Be permissive if not enough data - assume valid
        if self.positions.len() < MIN_TRAJECTORY_POINTS {
            analysis.excursion_sufficient = max_excursion >= MIN_EXCURSION_FOR_OVERTAKE;
            analysis.shape_score = 0.6;
            analysis.is_valid_overtake = analysis.excursion_sufficient;
            return analysis;
        }

        analysis.excursion_sufficient = max_excursion >= MIN_EXCURSION_FOR_OVERTAKE;

        let return_distance = (current_pos - start_pos).abs();
        analysis.returned_to_start = return_distance < RETURN_TO_CENTER_THRESHOLD;

        analysis.smoothness = self.calculate_smoothness();
        analysis.is_smooth = analysis.smoothness < TRAJECTORY_SMOOTHNESS_THRESHOLD;

        analysis.has_reversal = self.detect_direction_reversal();
        analysis.shape_score = self.calculate_shape_score(start_pos, max_excursion);

        // More permissive: valid if excursion OR good shape OR has reversal
        analysis.is_valid_overtake = analysis.excursion_sufficient
            || analysis.shape_score >= 0.5
            || (analysis.has_reversal && max_excursion >= 0.25);

        analysis
    }

    fn calculate_smoothness(&self) -> f32 {
        if self.positions.len() < 3 {
            return 0.0; // Assume smooth if no data
        }

        let positions: Vec<f32> = self.positions.iter().copied().collect();
        let mut jitter_sum = 0.0;
        let mut count = 0;

        for i in 2..positions.len() {
            let accel = positions[i] - 2.0 * positions[i - 1] + positions[i - 2];
            jitter_sum += accel.abs();
            count += 1;
        }

        if count > 0 {
            jitter_sum / count as f32
        } else {
            0.0
        }
    }

    fn detect_direction_reversal(&self) -> bool {
        if self.velocities.len() < 8 {
            return true; // Assume reversal if not enough data
        }

        let velocities: Vec<f32> = self.velocities.iter().copied().collect();
        let mut sign_changes = 0;
        let mut last_sign: Option<bool> = None;

        for v in &velocities {
            if v.abs() > 15.0 {
                let current_sign = *v > 0.0;
                if let Some(last) = last_sign {
                    if current_sign != last {
                        sign_changes += 1;
                    }
                }
                last_sign = Some(current_sign);
            }
        }

        sign_changes >= 1
    }

    fn calculate_shape_score(&self, start_pos: f32, max_excursion: f32) -> f32 {
        if self.positions.len() < MIN_TRAJECTORY_POINTS {
            return 0.6; // Default acceptable score
        }

        let positions: Vec<f32> = self.positions.iter().copied().collect();
        let n = positions.len();

        // Find peak
        let mut peak_idx = 0;
        let mut peak_deviation = 0.0;
        for (i, &pos) in positions.iter().enumerate() {
            let deviation = (pos - start_pos).abs();
            if deviation > peak_deviation {
                peak_deviation = deviation;
                peak_idx = i;
            }
        }

        // Score based on peak position
        let peak_position_score = {
            let relative_pos = peak_idx as f32 / n as f32;
            if relative_pos >= 0.2 && relative_pos <= 0.8 {
                1.0
            } else if relative_pos >= 0.1 && relative_pos <= 0.9 {
                0.7
            } else {
                0.4
            }
        };

        // Score based on return
        let return_score = {
            let end_pos = positions[n - 1];
            let return_distance = (end_pos - start_pos).abs();
            if return_distance < 0.20 {
                1.0
            } else if return_distance < 0.35 {
                0.7
            } else if return_distance < 0.50 {
                0.5
            } else {
                0.3
            }
        };

        // Score based on magnitude
        let magnitude_score = if max_excursion >= 0.55 {
            1.0
        } else if max_excursion >= 0.45 {
            0.9
        } else if max_excursion >= 0.35 {
            0.7
        } else if max_excursion >= 0.25 {
            0.5
        } else {
            0.3
        };

        (peak_position_score * 0.25 + return_score * 0.35 + magnitude_score * 0.40)
    }

    fn clear(&mut self) {
        self.positions.clear();
        self.timestamps.clear();
        self.velocities.clear();
    }
}

// ============================================================================
// DATA STRUCTURES
// ============================================================================

#[derive(Clone, Copy, Debug)]
struct OffsetSample {
    normalized_offset: f32,
    deviation: f32,
    timestamp_ms: f64,
    lateral_velocity: f32,
    direction: Direction,
}

#[derive(Debug, Default)]
struct WindowMetrics {
    total_displacement: f32,
    max_deviation: f32,
    avg_velocity: f32,
    peak_velocity: f32,
    direction_consistency: f32,
    time_span_ms: f64,
    is_intentional_change: bool,
    is_sustained_movement: bool,
}

#[derive(Debug, Clone, Copy, PartialEq)]
enum DetectionPath {
    BoundaryCrossing,
    HighVelocity,
    MediumDeviation,
    GradualChange,
    LargeDeviation,
    VelocitySpike,
}

// ============================================================================
// CONFIDENCE CALCULATOR
// ============================================================================

struct ConfidenceCalculator;

impl ConfidenceCalculator {
    fn calculate(
        max_offset: f32,
        duration_ms: f64,
        trajectory_analysis: &OvertakeAnalysis,
        detection_path: Option<DetectionPath>,
    ) -> f32 {
        let offset_confidence = Self::offset_to_confidence(max_offset);
        let duration_confidence = Self::duration_to_confidence(duration_ms);
        let trajectory_confidence = trajectory_analysis.shape_score;

        let path_bonus = match detection_path {
            Some(DetectionPath::BoundaryCrossing) => 0.05,
            Some(DetectionPath::HighVelocity) => 0.03,
            _ => 0.0,
        };

        let base_confidence = offset_confidence * 0.45
            + duration_confidence * 0.25
            + trajectory_confidence * 0.20
            + path_bonus
            + 0.05;

        base_confidence.max(0.4).min(0.98)
    }

    fn offset_to_confidence(max_offset: f32) -> f32 {
        if max_offset >= 0.60 {
            0.95
        } else if max_offset >= 0.50 {
            0.85
        } else if max_offset >= 0.40 {
            0.75
        } else if max_offset >= 0.30 {
            0.60
        } else {
            0.45
        }
    }

    fn duration_to_confidence(duration_ms: f64) -> f32 {
        if duration_ms >= 2000.0 && duration_ms <= 6000.0 {
            0.90
        } else if duration_ms >= 1000.0 && duration_ms <= 8000.0 {
            0.75
        } else if duration_ms >= 500.0 && duration_ms <= 10000.0 {
            0.55
        } else {
            0.35
        }
    }
}

// ============================================================================
// MAIN STATE MACHINE
// ============================================================================

pub struct LaneChangeStateMachine {
    config: LaneChangeConfig,
    source_id: String,

    state: LaneChangeState,
    frames_in_state: u32,
    pending_state: Option<LaneChangeState>,
    pending_frames: u32,

    change_direction: Direction,
    change_start_frame: Option<u64>,
    change_start_time: Option<f64>,
    change_detection_path: Option<DetectionPath>,
    max_offset_in_change: f32,
    initial_position_frozen: Option<f32>,

    cooldown_remaining: u32,
    total_frames_processed: u64,
    post_lane_change_grace: u32,

    position_filter: SimpleKalmanFilter,
    adaptive_baseline: AdaptiveBaseline,

    offset_history: Vec<f32>,
    velocity_history: VecDeque<f32>,
    offset_samples: VecDeque<OffsetSample>,
    direction_samples: VecDeque<Direction>,
    recent_deviations: Vec<f32>,

    stable_deviation_frames: u32,
    last_deviation: f32,

    peak_deviation_in_window: f32,
    peak_velocity_in_window: f32,
    peak_direction: Direction,

    curve_detector: CurveDetector,
    velocity_tracker: LateralVelocityTracker,
    trajectory_analyzer: TrajectoryAnalyzer,

    is_in_curve: bool,
    curve_compensation_factor: f32,

    pending_change_direction: Direction,
    pending_max_offset: f32,
}

impl LaneChangeStateMachine {
    pub fn new(config: LaneChangeConfig) -> Self {
        Self {
            config,
            source_id: String::new(),
            state: LaneChangeState::Centered,
            frames_in_state: 0,
            pending_state: None,
            pending_frames: 0,
            change_direction: Direction::Unknown,
            change_start_frame: None,
            change_start_time: None,
            change_detection_path: None,
            max_offset_in_change: 0.0,
            initial_position_frozen: None,
            cooldown_remaining: 0,
            total_frames_processed: 0,
            post_lane_change_grace: 0,
            position_filter: SimpleKalmanFilter::new(),
            adaptive_baseline: AdaptiveBaseline::new(),
            offset_history: Vec::with_capacity(90),
            velocity_history: VecDeque::with_capacity(30),
            offset_samples: VecDeque::with_capacity(150),
            direction_samples: VecDeque::with_capacity(30),
            recent_deviations: Vec::with_capacity(30),
            stable_deviation_frames: 0,
            last_deviation: 0.0,
            peak_deviation_in_window: 0.0,
            peak_velocity_in_window: 0.0,
            peak_direction: Direction::Unknown,
            curve_detector: CurveDetector::new(),
            velocity_tracker: LateralVelocityTracker::new(),
            trajectory_analyzer: TrajectoryAnalyzer::new(),
            is_in_curve: false,
            curve_compensation_factor: 1.0,
            pending_change_direction: Direction::Unknown,
            pending_max_offset: 0.0,
        }
    }

    pub fn current_state(&self) -> &str {
        self.state.as_str()
    }

    pub fn update_curve_detector(&mut self, lanes: &[crate::types::Lane]) -> bool {
        self.is_in_curve = self.curve_detector.is_in_curve(lanes);
        self.curve_compensation_factor = CURVE_COMPENSATION_FACTOR;
        self.is_in_curve
    }

    pub fn update(
        &mut self,
        vehicle_state: &VehicleState,
        frame_id: u64,
        timestamp_ms: f64,
        crossing_type: CrossingType,
    ) -> Option<LaneChangeEvent> {
        self.total_frames_processed += 1;

        if self.total_frames_processed < self.config.skip_initial_frames {
            return None;
        }

        if self.cooldown_remaining > 0 {
            self.cooldown_remaining -= 1;
            if self.cooldown_remaining == 0 {
                self.state = LaneChangeState::Centered;
                self.frames_in_state = 0;
            }
            return None;
        }

        if self.post_lane_change_grace > 0 {
            self.post_lane_change_grace -= 1;
        }

        if let Some(event) = self.handle_timeouts(frame_id, timestamp_ms) {
            return Some(event);
        }

        if !vehicle_state.is_valid() {
            return None;
        }

        let lane_width = vehicle_state.lane_width.unwrap();
        let raw_offset = vehicle_state.lateral_offset / lane_width;
        let normalized_offset = self.position_filter.update(raw_offset);

        let lateral_velocity = self
            .velocity_tracker
            .get_velocity(vehicle_state.lateral_offset, timestamp_ms);

        self.update_histories(normalized_offset, lateral_velocity);

        if self.post_lane_change_grace > 0 {
            self.adaptive_baseline.update(normalized_offset);
            return None;
        }

        self.adaptive_baseline.update(normalized_offset);

        if !self.adaptive_baseline.is_valid {
            return None;
        }

        if self.adaptive_baseline.sample_count == EWMA_MIN_SAMPLES {
            info!(
                " Adaptive baseline ready: {:.1}% at frame {} ({:.1}s)",
                self.adaptive_baseline.value * 100.0,
                frame_id,
                timestamp_ms / 1000.0
            );
        }

        let baseline = self.adaptive_baseline.effective_value();
        let signed_deviation = normalized_offset - baseline;
        let deviation = signed_deviation.abs();
        let current_direction = Direction::from_offset(signed_deviation);

        self.trajectory_analyzer
            .add_sample(normalized_offset, timestamp_ms, lateral_velocity);
        self.track_max_offset(deviation);
        self.update_samples(
            normalized_offset,
            deviation,
            timestamp_ms,
            lateral_velocity,
            current_direction,
        );

        let window_metrics = self.calculate_window_metrics(timestamp_ms, lane_width);

        let target_state = self.determine_target_state(
            deviation,
            crossing_type,
            lateral_velocity,
            current_direction,
            &window_metrics,
        );

        debug!(
            "F{}: off={:.1}%, base={:.1}%{}, dev={:.1}%, max={:.1}%, state={:?}{:?}",
            frame_id,
            normalized_offset * 100.0,
            baseline * 100.0,
            if self.adaptive_baseline.is_frozen {
                ""
            } else {
                ""
            },
            deviation * 100.0,
            self.max_offset_in_change * 100.0,
            self.state,
            target_state
        );

        self.check_transition(
            target_state,
            current_direction,
            frame_id,
            timestamp_ms,
            deviation,
            normalized_offset,
        )
    }

    fn handle_timeouts(&mut self, frame_id: u64, timestamp_ms: f64) -> Option<LaneChangeEvent> {
        if self.state == LaneChangeState::Drifting {
            if let Some(start_time) = self.change_start_time {
                let elapsed = timestamp_ms - start_time;

                if elapsed > MAX_DRIFTING_MS {
                    if self.max_offset_in_change >= MEDIUM_OFFSET_THRESHOLD {
                        info!(
                            " Long DRIFTING ({:.0}ms) with offset ({:.1}%) - auto-completing",
                            elapsed,
                            self.max_offset_in_change * 100.0
                        );
                        return self.force_complete(frame_id, timestamp_ms);
                    } else {
                        warn!(" Timeout with low offset - cancelling");
                        self.adaptive_baseline.unfreeze();
                        self.reset_lane_change();
                        self.cooldown_remaining = 30;
                        return None;
                    }
                }

                if elapsed > self.config.max_duration_ms {
                    if self.max_offset_in_change >= MEDIUM_OFFSET_THRESHOLD {
                        return self.force_complete(frame_id, timestamp_ms);
                    }
                    warn!(
                        " Timeout after {:.0}ms with max={:.1}%",
                        elapsed,
                        self.max_offset_in_change * 100.0
                    );
                    self.adaptive_baseline.unfreeze();
                    self.reset_lane_change();
                    self.cooldown_remaining = 30;
                }
            }
        }

        if self.state == LaneChangeState::Crossing {
            if let Some(start_time) = self.change_start_time {
                let elapsed = timestamp_ms - start_time;
                if elapsed > self.config.max_duration_ms {
                    return self.force_complete(frame_id, timestamp_ms);
                }
            }
        }

        None
    }

    fn update_histories(&mut self, normalized_offset: f32, lateral_velocity: f32) {
        self.velocity_history.push_back(lateral_velocity);
        if self.velocity_history.len() > 30 {
            self.velocity_history.pop_front();
        }

        self.offset_history.push(normalized_offset);
        if self.offset_history.len() > 90 {
            self.offset_history.remove(0);
        }
    }

    fn track_max_offset(&mut self, deviation: f32) {
        if self.pending_state == Some(LaneChangeState::Drifting)
            || self.state == LaneChangeState::Drifting
            || self.state == LaneChangeState::Crossing
        {
            if deviation > self.max_offset_in_change {
                self.max_offset_in_change = deviation;
            }
            if deviation > self.pending_max_offset {
                self.pending_max_offset = deviation;
            }
        }
    }

    fn update_samples(
        &mut self,
        normalized_offset: f32,
        deviation: f32,
        timestamp_ms: f64,
        lateral_velocity: f32,
        current_direction: Direction,
    ) {
        self.recent_deviations.push(deviation);
        if self.recent_deviations.len() > 30 {
            self.recent_deviations.remove(0);
        }

        let sample = OffsetSample {
            normalized_offset,
            deviation,
            timestamp_ms,
            lateral_velocity,
            direction: current_direction,
        };
        self.offset_samples.push_back(sample);

        while let Some(oldest) = self.offset_samples.front() {
            if timestamp_ms - oldest.timestamp_ms > ANALYSIS_WINDOW_MS {
                self.offset_samples.pop_front();
            } else {
                break;
            }
        }

        self.direction_samples.push_back(current_direction);
        if self.direction_samples.len() > 30 {
            self.direction_samples.pop_front();
        }

        if deviation > self.peak_deviation_in_window {
            self.peak_deviation_in_window = deviation;
            self.peak_direction = current_direction;
        }
        if lateral_velocity.abs() > self.peak_velocity_in_window {
            self.peak_velocity_in_window = lateral_velocity.abs();
        }
    }

    fn force_complete(&mut self, frame_id: u64, timestamp_ms: f64) -> Option<LaneChangeEvent> {
        let start_frame = self.change_start_frame.unwrap_or(frame_id);
        let start_time = self.change_start_time.unwrap_or(timestamp_ms);
        let duration_ms = Some(timestamp_ms - start_time);
        let duration = duration_ms.unwrap_or(0.0);

        let final_position = self.offset_history.last().copied().unwrap_or(0.0);
        let net_displacement = self
            .initial_position_frozen
            .map(|initial| (final_position - initial).abs())
            .unwrap_or(0.0);

        let trajectory_analysis = self.trajectory_analyzer.analyze_overtake_pattern(
            self.initial_position_frozen.unwrap_or(0.0),
            final_position,
            self.max_offset_in_change,
        );

        if !self.validate_lane_change(duration, net_displacement, &trajectory_analysis) {
            warn!(
                " Force complete rejected: max={:.1}%, dur={:.0}ms",
                self.max_offset_in_change * 100.0,
                duration
            );
            self.adaptive_baseline.unfreeze();
            self.reset_lane_change();
            self.cooldown_remaining = 60;
            return None;
        }

        let confidence = ConfidenceCalculator::calculate(
            self.max_offset_in_change,
            duration,
            &trajectory_analysis,
            self.change_detection_path,
        );

        let mut event = LaneChangeEvent::new(
            start_time,
            start_frame,
            frame_id,
            self.change_direction,
            confidence,
        );
        event.duration_ms = duration_ms;
        event.source_id = self.source_id.clone();

        info!(
            " FORCE CONFIRMED: {} at {:.2}s, dur={:.0}ms, max={:.1}%, conf={:.2}",
            event.direction_name(),
            start_time / 1000.0,
            duration,
            self.max_offset_in_change * 100.0,
            confidence
        );

        self.finalize_lane_change();
        Some(event)
    }

    /// BALANCED validation - offset compensates for duration
    fn validate_lane_change(
        &self,
        duration: f64,
        net_displacement: f32,
        trajectory_analysis: &OvertakeAnalysis,
    ) -> bool {
        // ================================================================
        // RULE 0: ABSOLUTE MINIMUM DURATION (safety net)
        // No lane change can be less than 800ms regardless of offset
        // ================================================================
        const ABSOLUTE_MIN_DURATION: f64 = 800.0;

        if duration < ABSOLUTE_MIN_DURATION {
            warn!(
                " Rejected: duration {:.0}ms < {:.0}ms absolute minimum",
                duration, ABSOLUTE_MIN_DURATION
            );
            return false;
        }

        // ================================================================
        // RULE 1: Baseline sanity check
        // ================================================================
        if !self.adaptive_baseline.is_sane()
            && self.max_offset_in_change < VERY_HIGH_OFFSET_THRESHOLD
        {
            warn!(
                " Rejected: baseline at {:.1}% and offset only {:.1}%",
                self.adaptive_baseline.frozen_value * 100.0,
                self.max_offset_in_change * 100.0
            );
            return false;
        }

        // ================================================================
        // RULE 2: Minimum offset required
        // ================================================================
        if self.max_offset_in_change < LOW_OFFSET_THRESHOLD {
            warn!(
                " Rejected: max offset {:.1}% < {:.1}% minimum",
                self.max_offset_in_change * 100.0,
                LOW_OFFSET_THRESHOLD * 100.0
            );
            return false;
        }

        // ================================================================
        // RULE 3: Very high offset (>=55%) - need minimum duration only
        // ================================================================
        if self.max_offset_in_change >= VERY_HIGH_OFFSET_THRESHOLD {
            info!(
                " Valid: very high offset {:.1}% with dur={:.0}ms",
                self.max_offset_in_change * 100.0,
                duration
            );
            return true;
        }

        // ================================================================
        // RULE 4: High offset (>=45%) - need reasonable duration
        // ================================================================
        if self.max_offset_in_change >= HIGH_OFFSET_THRESHOLD {
            if duration >= MIN_DURATION_HIGH {
                info!(
                    " Valid: high offset {:.1}% with dur={:.0}ms",
                    self.max_offset_in_change * 100.0,
                    duration
                );
                return true;
            }
            // High offset but short duration - need good trajectory
            if trajectory_analysis.is_valid_overtake && trajectory_analysis.shape_score >= 0.6 {
                info!(
                " Valid: high offset {:.1}%, short dur but excellent trajectory (score={:.2})",
                self.max_offset_in_change * 100.0,
                trajectory_analysis.shape_score
            );
                return true;
            }
            warn!(
                " Rejected: high offset {:.1}% but dur={:.0}ms < {:.0}ms and traj_score={:.2}",
                self.max_offset_in_change * 100.0,
                duration,
                MIN_DURATION_HIGH,
                trajectory_analysis.shape_score
            );
            return false;
        }

        // ================================================================
        // RULE 5: Medium offset (>=35%) - need duration AND (trajectory OR displacement)
        // ================================================================
        if self.max_offset_in_change >= MEDIUM_OFFSET_THRESHOLD {
            let has_duration = duration >= MIN_DURATION_MEDIUM;
            let has_trajectory =
                trajectory_analysis.is_valid_overtake && trajectory_analysis.shape_score >= 0.5;
            let has_displacement = net_displacement >= MIN_NET_DISPLACEMENT;

            // Must have duration, plus at least one other condition
            if has_duration && (has_trajectory || has_displacement) {
                info!(
                    " Valid: medium offset {:.1}%, dur= + traj={} disp={}",
                    self.max_offset_in_change * 100.0,
                    if has_trajectory { "" } else { "" },
                    if has_displacement { "" } else { "" }
                );
                return true;
            }

            warn!(
                " Rejected: medium offset {:.1}%, dur={} (need ) + traj={} disp={}",
                self.max_offset_in_change * 100.0,
                if has_duration { "" } else { "" },
                if has_trajectory { "" } else { "" },
                if has_displacement { "" } else { "" }
            );
            return false;
        }

        // ================================================================
        // RULE 6: Lower offset (25-35%) - need ALL conditions
        // ================================================================
        let has_duration = duration >= MIN_DURATION_LOW;
        let has_trajectory = trajectory_analysis.is_valid_overtake;
        let has_displacement = net_displacement >= MIN_NET_DISPLACEMENT;

        if has_duration && has_trajectory && has_displacement {
            info!(
                " Valid: lower offset {:.1}%, all conditions met",
                self.max_offset_in_change * 100.0
            );
            return true;
        }

        warn!(
            " Rejected: offset {:.1}%, dur={} traj={} disp={} (need ALL)",
            self.max_offset_in_change * 100.0,
            if has_duration { "" } else { "" },
            if has_trajectory { "" } else { "" },
            if has_displacement { "" } else { "" }
        );
        false
    }

    fn get_recent_position_change(&self) -> f32 {
        if self.offset_history.len() < 10 {
            return 0.0;
        }

        let recent = &self.offset_history[self.offset_history.len() - 10..];
        let first = recent[0];
        let last = recent[recent.len() - 1];

        let max = recent.iter().fold(f32::MIN, |a, &b| a.max(b));
        let min = recent.iter().fold(f32::MAX, |a, &b| a.min(b));
        let swing = max - min;

        (last - first).abs().max(swing)
    }

    fn calculate_window_metrics(&self, _current_time_ms: f64, lane_width: f32) -> WindowMetrics {
        let mut metrics = WindowMetrics::default();

        if self.offset_samples.len() < 10 {
            return metrics;
        }

        let first = self.offset_samples.front().unwrap();
        let last = self.offset_samples.back().unwrap();

        metrics.time_span_ms = last.timestamp_ms - first.timestamp_ms;
        if metrics.time_span_ms < 300.0 {
            return metrics;
        }

        metrics.total_displacement = (last.deviation - first.deviation).abs();
        metrics.max_deviation = self
            .offset_samples
            .iter()
            .map(|s| s.deviation)
            .fold(0.0f32, |a, b| a.max(b));

        let velocities: Vec<f32> = self
            .offset_samples
            .iter()
            .map(|s| s.lateral_velocity)
            .collect();
        metrics.avg_velocity = velocities.iter().sum::<f32>() / velocities.len() as f32;
        metrics.peak_velocity = velocities
            .iter()
            .map(|v| v.abs())
            .fold(0.0f32, |a, b| a.max(b));

        if !self.direction_samples.is_empty() {
            let target_dir = self.peak_direction;
            let consistent = self
                .direction_samples
                .iter()
                .filter(|&&d| d == target_dir)
                .count();
            metrics.direction_consistency = consistent as f32 / self.direction_samples.len() as f32;
        }

        metrics.is_sustained_movement = metrics.direction_consistency
            >= DIRECTION_CONSISTENCY_THRESHOLD
            && metrics.time_span_ms >= 1000.0;
        metrics.is_intentional_change = metrics.max_deviation >= DEVIATION_DRIFT_START
            && metrics.is_sustained_movement
            && (metrics.avg_velocity.abs() > MIN_VELOCITY_SLOW || metrics.time_span_ms >= 2000.0);

        metrics
    }

    fn determine_target_state(
        &mut self,
        deviation: f32,
        crossing_type: CrossingType,
        lateral_velocity: f32,
        current_direction: Direction,
        metrics: &WindowMetrics,
    ) -> LaneChangeState {
        let drift_threshold = self.config.drift_threshold;
        let crossing_threshold = self.config.crossing_threshold;

        let vel_fast = MIN_VELOCITY_FAST;
        let vel_medium = MIN_VELOCITY_MEDIUM;

        match self.state {
            LaneChangeState::Centered => {
                // Skip if baseline is way off (likely already in another lane)
                if !self.adaptive_baseline.is_sane() {
                    return LaneChangeState::Centered;
                }

                // PATH 1: BOUNDARY CROSSING
                if crossing_type != CrossingType::None && lateral_velocity.abs() > vel_fast {
                    if self.is_deviation_sustained(drift_threshold * 0.9) {
                        self.change_detection_path = Some(DetectionPath::BoundaryCrossing);
                        info!(
                            " [BOUNDARY] {:?}, vel={:.1}px/s",
                            crossing_type, lateral_velocity
                        );
                        return LaneChangeState::Drifting;
                    }
                }

                // PATH 2: HIGH VELOCITY + DEVIATION
                if lateral_velocity.abs() > vel_fast && deviation >= drift_threshold {
                    if self.is_velocity_sustained(vel_medium) {
                        self.change_detection_path = Some(DetectionPath::HighVelocity);
                        info!(
                            " [HIGH-VEL] vel={:.1}px/s, dev={:.1}%",
                            lateral_velocity,
                            deviation * 100.0
                        );
                        return LaneChangeState::Drifting;
                    }
                }

                // PATH 3: VELOCITY SPIKE
                if lateral_velocity.abs() > VELOCITY_SPIKE_THRESHOLD && deviation >= drift_threshold
                {
                    if self.is_velocity_sustained(vel_fast) {
                        let position_change = self.get_recent_position_change();
                        if position_change >= POSITION_CHANGE_THRESHOLD {
                            self.change_detection_path = Some(DetectionPath::VelocitySpike);
                            info!(
                                " [VELOCITY-SPIKE] vel={:.1}px/s, pos_change={:.1}%",
                                lateral_velocity,
                                position_change * 100.0
                            );
                            return LaneChangeState::Drifting;
                        }
                    }
                }

                // PATH 4: MEDIUM SPEED + HIGH DEVIATION
                if deviation >= drift_threshold + 0.10 && lateral_velocity.abs() > vel_medium {
                    if self.is_deviation_sustained(drift_threshold) {
                        self.change_detection_path = Some(DetectionPath::MediumDeviation);
                        info!(
                            " [MEDIUM] dev={:.1}%, vel={:.1}px/s",
                            deviation * 100.0,
                            lateral_velocity
                        );
                        return LaneChangeState::Drifting;
                    }
                }

                // PATH 5: GRADUAL CHANGE
                if metrics.is_intentional_change && metrics.max_deviation >= DEVIATION_SIGNIFICANT {
                    if self.is_deviation_sustained_long(DEVIATION_DRIFT_START) {
                        self.change_detection_path = Some(DetectionPath::GradualChange);
                        info!(
                            " [GRADUAL] max={:.1}%, span={:.1}s",
                            metrics.max_deviation * 100.0,
                            metrics.time_span_ms / 1000.0
                        );
                        return LaneChangeState::Drifting;
                    }
                }

                // PATH 6: LARGE DEVIATION
                if deviation >= DEVIATION_LANE_CENTER {
                    if self.is_deviation_sustained(drift_threshold) {
                        self.change_detection_path = Some(DetectionPath::LargeDeviation);
                        info!(" [LARGE] dev={:.1}%", deviation * 100.0);
                        return LaneChangeState::Drifting;
                    }
                }

                LaneChangeState::Centered
            }

            LaneChangeState::Drifting => {
                if deviation >= crossing_threshold {
                    return LaneChangeState::Crossing;
                }

                if self.max_offset_in_change >= crossing_threshold {
                    return LaneChangeState::Crossing;
                }

                if self.frames_in_state > 45 && self.max_offset_in_change >= MEDIUM_OFFSET_THRESHOLD
                {
                    if self.is_deviation_stable() {
                        info!(
                            " DRIFTING stabilized with max={:.1}%",
                            self.max_offset_in_change * 100.0
                        );
                        return LaneChangeState::Completed;
                    }
                }

                let cancel_threshold = drift_threshold * HYSTERESIS_EXIT;
                if deviation < cancel_threshold && self.max_offset_in_change < LOW_OFFSET_THRESHOLD
                {
                    warn!(
                        " Cancelled: max={:.1}% < {:.1}%",
                        self.max_offset_in_change * 100.0,
                        LOW_OFFSET_THRESHOLD * 100.0
                    );
                    return LaneChangeState::Centered;
                }

                LaneChangeState::Drifting
            }

            LaneChangeState::Crossing => {
                let deviation_change = (deviation - self.last_deviation).abs();
                if deviation_change < 0.03 {
                    self.stable_deviation_frames += 1;
                } else {
                    self.stable_deviation_frames = 0;
                }
                self.last_deviation = deviation;

                if self.is_deviation_stable() && deviation < 0.40 {
                    return LaneChangeState::Completed;
                }

                let return_threshold = drift_threshold * HYSTERESIS_EXIT;
                if deviation < return_threshold {
                    return LaneChangeState::Completed;
                }

                if self.stable_deviation_frames >= 25 && deviation < 0.50 {
                    return LaneChangeState::Completed;
                }

                if self.max_offset_in_change >= crossing_threshold
                    && current_direction != self.change_direction
                    && current_direction != Direction::Unknown
                {
                    let reversal_count = self
                        .direction_samples
                        .iter()
                        .rev()
                        .take(10)
                        .filter(|&&d| d != self.change_direction && d != Direction::Unknown)
                        .count();
                    if reversal_count >= 6 {
                        return LaneChangeState::Completed;
                    }
                }

                LaneChangeState::Crossing
            }

            LaneChangeState::Completed => LaneChangeState::Centered,
        }
    }

    fn is_deviation_sustained(&self, threshold: f32) -> bool {
        if self.offset_history.len() < 8 {
            return false;
        }
        let baseline = self.adaptive_baseline.effective_value();
        self.offset_history
            .iter()
            .rev()
            .take(6)
            .filter(|o| (*o - baseline).abs() >= threshold)
            .count()
            >= 4
    }

    fn is_deviation_sustained_long(&self, threshold: f32) -> bool {
        if self.offset_history.len() < 20 {
            return false;
        }
        let baseline = self.adaptive_baseline.effective_value();
        self.offset_history
            .iter()
            .rev()
            .take(15)
            .filter(|o| (*o - baseline).abs() >= threshold)
            .count()
            >= 10
    }

    fn is_velocity_sustained(&self, threshold: f32) -> bool {
        if self.velocity_history.len() < 5 {
            return false;
        }
        self.velocity_history
            .iter()
            .rev()
            .take(5)
            .filter(|v| v.abs() >= threshold)
            .count()
            >= 3
    }

    fn is_deviation_stable(&self) -> bool {
        if self.recent_deviations.len() < 12 {
            return false;
        }
        let recent = &self.recent_deviations[self.recent_deviations.len() - 12..];
        let max = recent.iter().fold(f32::MIN, |a, &b| a.max(b));
        let min = recent.iter().fold(f32::MAX, |a, &b| a.min(b));
        if max - min > 0.12 {
            return false;
        }
        recent
            .windows(2)
            .filter(|w| (w[1] - w[0]).abs() > 0.04)
            .count()
            <= 4
    }

    fn reset_lane_change(&mut self) {
        self.state = LaneChangeState::Centered;
        self.frames_in_state = 0;
        self.pending_state = None;
        self.pending_frames = 0;
        self.change_direction = Direction::Unknown;
        self.change_start_frame = None;
        self.change_start_time = None;
        self.change_detection_path = None;
        self.max_offset_in_change = 0.0;
        self.initial_position_frozen = None;
        self.stable_deviation_frames = 0;
        self.last_deviation = 0.0;
        self.recent_deviations.clear();
        self.peak_deviation_in_window = 0.0;
        self.peak_velocity_in_window = 0.0;
        self.peak_direction = Direction::Unknown;
        self.pending_change_direction = Direction::Unknown;
        self.pending_max_offset = 0.0;
        self.trajectory_analyzer.clear();
    }

    fn finalize_lane_change(&mut self) {
        self.adaptive_baseline.reset();
        self.position_filter.reset();
        self.post_lane_change_grace = POST_CHANGE_GRACE_FRAMES;
        self.offset_samples.clear();
        self.cooldown_remaining = self.config.cooldown_frames;
        info!(" Baseline reset - will adapt to new position");
        self.reset_lane_change();
    }

    fn check_transition(
        &mut self,
        target_state: LaneChangeState,
        direction: Direction,
        frame_id: u64,
        timestamp_ms: f64,
        current_deviation: f32,
        normalized_offset: f32,
    ) -> Option<LaneChangeEvent> {
        if target_state == self.state {
            self.pending_state = None;
            self.pending_frames = 0;
            self.frames_in_state += 1;
            return None;
        }

        if target_state == LaneChangeState::Drifting && self.state == LaneChangeState::Centered {
            if self.pending_state != Some(LaneChangeState::Drifting) {
                self.adaptive_baseline.freeze();
                self.initial_position_frozen = Some(normalized_offset);
                self.pending_change_direction = direction;
                self.pending_max_offset = current_deviation;
                info!(
                    " Baseline frozen at {:.1}%, initial position: {:.1}%",
                    self.adaptive_baseline.effective_value() * 100.0,
                    normalized_offset * 100.0
                );
            }
        }

        if self.pending_state == Some(target_state) {
            self.pending_frames += 1;
        } else {
            self.pending_state = Some(target_state);
            self.pending_frames = 1;
        }

        if target_state != LaneChangeState::Drifting
            && self.adaptive_baseline.is_frozen
            && self.state == LaneChangeState::Centered
            && self.pending_frames < self.config.min_frames_confirm
        {
            self.adaptive_baseline.unfreeze();
            self.initial_position_frozen = None;
            self.pending_max_offset = 0.0;
        }

        if self.pending_frames < self.config.min_frames_confirm {
            return None;
        }

        self.execute_transition(
            target_state,
            direction,
            frame_id,
            timestamp_ms,
            normalized_offset,
        )
    }

    fn execute_transition(
        &mut self,
        target_state: LaneChangeState,
        direction: Direction,
        frame_id: u64,
        timestamp_ms: f64,
        final_position: f32,
    ) -> Option<LaneChangeEvent> {
        let from_state = self.state;

        info!(
            "State: {:?}  {:?} at frame {} ({:.2}s)",
            from_state,
            target_state,
            frame_id,
            timestamp_ms / 1000.0
        );

        if target_state == LaneChangeState::Drifting && from_state == LaneChangeState::Centered {
            self.change_direction = if self.pending_change_direction != Direction::Unknown {
                self.pending_change_direction
            } else {
                direction
            };
            self.change_start_frame = Some(frame_id);
            self.change_start_time = Some(timestamp_ms);
            self.max_offset_in_change = self.pending_max_offset;
            self.stable_deviation_frames = 0;
            self.last_deviation = 0.0;

            if !self.adaptive_baseline.is_frozen {
                self.adaptive_baseline.freeze();
                self.initial_position_frozen = Some(final_position);
            }

            info!(
                " Lane change started: {} at {:.2}s via {:?} (max: {:.1}%)",
                self.change_direction.as_str(),
                timestamp_ms / 1000.0,
                self.change_detection_path,
                self.max_offset_in_change * 100.0
            );
        }

        if target_state == LaneChangeState::Centered && from_state == LaneChangeState::Drifting {
            info!(" Cancelled");
            self.adaptive_baseline.unfreeze();
            self.reset_lane_change();
            self.cooldown_remaining = 30;
            return None;
        }

        let duration_ms = if target_state == LaneChangeState::Completed {
            self.change_start_time.map(|start| timestamp_ms - start)
        } else {
            None
        };

        self.state = target_state;
        self.frames_in_state = 0;
        self.pending_state = None;
        self.pending_frames = 0;

        if target_state == LaneChangeState::Completed {
            let duration = duration_ms.unwrap_or(0.0);

            let net_displacement = if let Some(initial_pos) = self.initial_position_frozen {
                (final_position - initial_pos).abs()
            } else {
                0.0
            };

            let trajectory_analysis = self.trajectory_analyzer.analyze_overtake_pattern(
                self.initial_position_frozen.unwrap_or(0.0),
                final_position,
                self.max_offset_in_change,
            );

            debug!(
                " Trajectory: excursion={}, returned={}, shape={:.2}",
                trajectory_analysis.excursion_sufficient,
                trajectory_analysis.returned_to_start,
                trajectory_analysis.shape_score
            );

            if !self.validate_lane_change(duration, net_displacement, &trajectory_analysis) {
                self.adaptive_baseline.unfreeze();
                self.reset_lane_change();
                self.cooldown_remaining = 60;
                return None;
            }

            let confidence = ConfidenceCalculator::calculate(
                self.max_offset_in_change,
                duration,
                &trajectory_analysis,
                self.change_detection_path,
            );

            let start_frame = self.change_start_frame.unwrap_or(frame_id);
            let start_time = self.change_start_time.unwrap_or(timestamp_ms);

            let mut event = LaneChangeEvent::new(
                start_time,
                start_frame,
                frame_id,
                self.change_direction,
                confidence,
            );
            event.duration_ms = duration_ms;
            event.source_id = self.source_id.clone();

            event.metadata.insert(
                "max_offset_normalized".to_string(),
                serde_json::json!(self.max_offset_in_change),
            );
            if let Some(initial) = self.initial_position_frozen {
                event
                    .metadata
                    .insert("initial_position".to_string(), serde_json::json!(initial));
                event.metadata.insert(
                    "final_position".to_string(),
                    serde_json::json!(final_position),
                );
                event.metadata.insert(
                    "net_displacement".to_string(),
                    serde_json::json!(net_displacement),
                );
            }
            if let Some(path) = self.change_detection_path {
                event.metadata.insert(
                    "detection_path".to_string(),
                    serde_json::json!(format!("{:?}", path)),
                );
            }

            info!(
                " CONFIRMED: {} at {:.2}s, dur={:.0}ms, max={:.1}%, conf={:.2}",
                event.direction_name(),
                start_time / 1000.0,
                duration,
                self.max_offset_in_change * 100.0,
                confidence
            );

            self.finalize_lane_change();
            return Some(event);
        }

        None
    }

    pub fn reset(&mut self) {
        self.reset_lane_change();
        self.adaptive_baseline.unfreeze();
        self.cooldown_remaining = 0;
        self.total_frames_processed = 0;
        self.post_lane_change_grace = 0;
        self.position_filter.reset();
        self.adaptive_baseline.reset();
        self.offset_history.clear();
        self.velocity_history.clear();
        self.curve_detector.reset();
        self.velocity_tracker.reset();
        self.offset_samples.clear();
        self.direction_samples.clear();
        self.trajectory_analyzer.clear();
        self.is_in_curve = false;
        self.curve_compensation_factor = 1.0;
    }

    pub fn set_source_id(&mut self, source_id: String) {
        self.source_id = source_id;
    }
}
=== ./src/analysis/lane_analyzer.rs ===
// src/analysis/lane_analyzer.rs

use crate::analysis::boundary_detector::{CrossingType, LaneBoundaryCrossingDetector};
use crate::analysis::position_estimator::{PositionEstimator, PositionSmoother};
use crate::analysis::state_machine::LaneChangeStateMachine;
use crate::types::{Lane, LaneChangeConfig, LaneChangeEvent, VehicleState};

pub struct LaneChangeAnalyzer {
    position_estimator: PositionEstimator,
    smoother: PositionSmoother,
    state_machine: LaneChangeStateMachine,
    boundary_detector: LaneBoundaryCrossingDetector,
    config: LaneChangeConfig,
    last_state: Option<VehicleState>,
    frame_count: u64,
    valid_estimates: u64,
}

impl LaneChangeAnalyzer {
    pub fn new(config: LaneChangeConfig) -> Self {
        let position_estimator = PositionEstimator::new(config.reference_y_ratio);
        let smoother = PositionSmoother::new(config.smoothing_alpha);
        let state_machine = LaneChangeStateMachine::new(config.clone());
        let boundary_detector = LaneBoundaryCrossingDetector::new();

        Self {
            position_estimator,
            smoother,
            state_machine,
            boundary_detector,
            config,
            last_state: None,
            frame_count: 0,
            valid_estimates: 0,
        }
    }

    pub fn analyze(
        &mut self,
        lanes: &[Lane],
        frame_width: u32,
        frame_height: u32,
        frame_id: u64,
        timestamp_ms: f64,
    ) -> Option<LaneChangeEvent> {
        self.frame_count += 1;

        // Update curve detector with current lanes
        let _is_in_curve = self.state_machine.update_curve_detector(lanes);

        // Get raw position estimate
        let mut raw_state = self
            .position_estimator
            .estimate(lanes, frame_width, frame_height);
        raw_state.frame_id = frame_id;
        raw_state.timestamp_ms = timestamp_ms;

        // Apply smoothing
        let smoothed_state = self.smoother.smooth(raw_state);

        if smoothed_state.is_valid() {
            self.valid_estimates += 1;
        }

        // Detect lane boundary crossing
        let (left_x, right_x) = self.get_lane_boundaries(lanes, frame_height);
        let vehicle_x = frame_width as f32 / 2.0;

        let crossing_type = self
            .boundary_detector
            .detect_crossing(left_x, right_x, vehicle_x);

        self.last_state = Some(smoothed_state);

        // Update state machine with crossing info
        self.state_machine
            .update(&smoothed_state, frame_id, timestamp_ms, crossing_type)
    }

    fn get_lane_boundaries(&self, lanes: &[Lane], frame_height: u32) -> (Option<f32>, Option<f32>) {
        let reference_y = frame_height as f32 * self.config.reference_y_ratio;

        // Find left and right ego lanes
        let mut left_x = None;
        let mut right_x = None;

        let vehicle_x = 640.0; // Approximate center, adjust if needed

        for lane in lanes {
            if let Some(x) = lane.get_x_at_y(reference_y) {
                if x < vehicle_x && (left_x.is_none() || x > left_x.unwrap()) {
                    left_x = Some(x);
                } else if x > vehicle_x && (right_x.is_none() || x < right_x.unwrap()) {
                    right_x = Some(x);
                }
            }
        }

        (left_x, right_x)
    }

    pub fn current_state(&self) -> &str {
        self.state_machine.current_state()
    }

    pub fn last_vehicle_state(&self) -> Option<&VehicleState> {
        self.last_state.as_ref()
    }

    pub fn reset(&mut self) {
        self.state_machine.reset();
        self.smoother.reset();
        self.position_estimator.reset();
        self.boundary_detector.reset();
        self.last_state = None;
        self.frame_count = 0;
        self.valid_estimates = 0;
    }

    pub fn set_source_id(&mut self, source_id: String) {
        self.state_machine.set_source_id(source_id);
    }

    pub fn config(&self) -> &LaneChangeConfig {
        &self.config
    }

    pub fn get_stats(&self) -> (u64, u64, f32) {
        let valid_ratio = if self.frame_count > 0 {
            self.valid_estimates as f32 / self.frame_count as f32
        } else {
            0.0
        };
        (self.frame_count, self.valid_estimates, valid_ratio)
    }
}
=== ./src/analysis/position_estimator.rs ===
// src/analysis/position_estimator.rs

use crate::types::{Lane, VehicleState};
use std::collections::VecDeque;
use tracing::debug;

pub struct PositionEstimator {
    pub reference_y_ratio: f32,
    pub min_lane_width: f32,
    pub max_lane_width: f32,
    pub default_lane_width: f32,
    lane_width_history: VecDeque<f32>,
    offset_history: VecDeque<f32>,
    history_size: usize,
    last_valid_width: Option<f32>,
}

impl PositionEstimator {
    pub fn new(reference_y_ratio: f32) -> Self {
        Self {
            reference_y_ratio,
            min_lane_width: 100.0,
            max_lane_width: 900.0,
            default_lane_width: 550.0,
            lane_width_history: VecDeque::with_capacity(15),
            offset_history: VecDeque::with_capacity(15),
            history_size: 15,
            last_valid_width: None,
        }
    }

    fn get_stable_lane_width(&mut self, measured: f32) -> f32 {
        if measured >= self.min_lane_width && measured <= self.max_lane_width {
            self.lane_width_history.push_back(measured);
            if self.lane_width_history.len() > self.history_size {
                self.lane_width_history.pop_front();
            }
            self.last_valid_width = Some(measured);
        }

        if self.lane_width_history.len() < 3 {
            return self.last_valid_width.unwrap_or(self.default_lane_width);
        }

        let mut sorted: Vec<f32> = self.lane_width_history.iter().copied().collect();
        sorted.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
        sorted[sorted.len() / 2]
    }

    fn update_offset_history(&mut self, offset: f32) {
        self.offset_history.push_back(offset);
        if self.offset_history.len() > self.history_size {
            self.offset_history.pop_front();
        }
    }

    pub fn estimate(
        &mut self,
        lanes: &[Lane],
        frame_width: u32,
        frame_height: u32,
    ) -> VehicleState {
        let vehicle_x = frame_width as f32 / 2.0;
        let reference_y = frame_height as f32 * self.reference_y_ratio;

        let confident_lanes: Vec<&Lane> = lanes
            .iter()
            .filter(|l| l.confidence > 0.2 && l.points.len() >= 3)
            .collect();

        let left_lane = self.find_ego_lane(&confident_lanes, vehicle_x, true);
        let right_lane = self.find_ego_lane(&confident_lanes, vehicle_x, false);

        let left_x = left_lane.and_then(|l| l.get_x_at_y(reference_y));
        let right_x = right_lane.and_then(|l| l.get_x_at_y(reference_y));

        let both_lanes_detected = left_x.is_some() && right_x.is_some();

        let detection_confidence = match (&left_lane, &right_lane) {
            (Some(l), Some(r)) => (l.confidence + r.confidence) / 2.0,
            (Some(l), None) => l.confidence * 0.6,
            (None, Some(r)) => r.confidence * 0.6,
            (None, None) => 0.0,
        };

        let mut lane_width: Option<f32> = None;
        let mut lateral_offset = 0.0f32;
        let mut raw_offset = 0.0f32;

        match (left_x, right_x) {
            (Some(lx), Some(rx)) => {
                let measured_width = rx - lx;
                let stable_width = self.get_stable_lane_width(measured_width);
                lane_width = Some(stable_width);

                let lane_center = (lx + rx) / 2.0;
                raw_offset = vehicle_x - lane_center;
                lateral_offset = raw_offset;

                self.update_offset_history(lateral_offset);
            }
            (Some(lx), None) => {
                let stable_width = self.get_stable_lane_width(self.default_lane_width);
                let estimated_center = lx + (stable_width / 2.0);
                raw_offset = vehicle_x - estimated_center;
                lateral_offset = raw_offset;
                lane_width = Some(stable_width);
                self.update_offset_history(lateral_offset);
            }
            (None, Some(rx)) => {
                let stable_width = self.get_stable_lane_width(self.default_lane_width);
                let estimated_center = rx - (stable_width / 2.0);
                raw_offset = vehicle_x - estimated_center;
                lateral_offset = raw_offset;
                lane_width = Some(stable_width);
                self.update_offset_history(lateral_offset);
            }
            (None, None) => {
                if let Some(width) = self.last_valid_width {
                    lane_width = Some(width);
                }
                if let Some(&last_offset) = self.offset_history.back() {
                    lateral_offset = last_offset;
                }
            }
        }

        VehicleState {
            lateral_offset,
            lane_width,
            heading_offset: 0.0,
            frame_id: 0,
            timestamp_ms: 0.0,
            raw_offset,
            detection_confidence,
            both_lanes_detected,
        }
    }

    fn find_ego_lane<'a>(
        &self,
        lanes: &[&'a Lane],
        vehicle_x: f32,
        is_left: bool,
    ) -> Option<&'a Lane> {
        let mut candidates: Vec<(&Lane, f32)> = Vec::new();

        for lane in lanes {
            if lane.points.len() < 2 {
                continue;
            }

            if let Some(p) = lane.bottom_point() {
                if is_left && p.x < vehicle_x {
                    candidates.push((lane, vehicle_x - p.x));
                } else if !is_left && p.x > vehicle_x {
                    candidates.push((lane, p.x - vehicle_x));
                }
            }
        }

        candidates.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap_or(std::cmp::Ordering::Equal));
        candidates.first().map(|(lane, _)| *lane)
    }

    pub fn reset(&mut self) {
        self.lane_width_history.clear();
        self.offset_history.clear();
        self.last_valid_width = None;
    }
}

pub struct PositionSmoother {
    alpha: f32,
    smoothed_offset: Option<f32>,
    smoothed_width: Option<f32>,
}

impl PositionSmoother {
    pub fn new(alpha: f32) -> Self {
        Self {
            alpha: alpha.clamp(0.1, 0.5),
            smoothed_offset: None,
            smoothed_width: None,
        }
    }

    pub fn smooth(&mut self, state: VehicleState) -> VehicleState {
        let smoothed_offset = match self.smoothed_offset {
            None => {
                self.smoothed_offset = Some(state.lateral_offset);
                state.lateral_offset
            }
            Some(prev) => {
                let new_val = self.alpha * state.lateral_offset + (1.0 - self.alpha) * prev;
                self.smoothed_offset = Some(new_val);
                new_val
            }
        };

        let smoothed_width = if let Some(width) = state.lane_width {
            match self.smoothed_width {
                None => {
                    self.smoothed_width = Some(width);
                    Some(width)
                }
                Some(prev) => {
                    let new_val = 0.1 * width + 0.9 * prev;
                    self.smoothed_width = Some(new_val);
                    Some(new_val)
                }
            }
        } else {
            self.smoothed_width
        };

        VehicleState {
            lateral_offset: smoothed_offset,
            lane_width: smoothed_width,
            heading_offset: state.heading_offset,
            frame_id: state.frame_id,
            timestamp_ms: state.timestamp_ms,
            raw_offset: state.raw_offset,
            detection_confidence: state.detection_confidence,
            both_lanes_detected: state.both_lanes_detected,
        }
    }

    pub fn reset(&mut self) {
        self.smoothed_offset = None;
        self.smoothed_width = None;
    }
}
=== ./src/analysis/boundary_detector.rs ===
// src/analysis/boundary_detector.rs

use std::collections::VecDeque;
use tracing::debug;

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum CrossingType {
    None,
    CrossedLeft,
    CrossedRight,
}

pub struct LaneBoundaryCrossingDetector {
    left_lane_x_history: VecDeque<f32>,
    right_lane_x_history: VecDeque<f32>,
    vehicle_x_history: VecDeque<f32>,
    history_size: usize,
    crossing_margin: f32,
}

impl LaneBoundaryCrossingDetector {
    pub fn new() -> Self {
        Self {
            left_lane_x_history: VecDeque::with_capacity(15),
            right_lane_x_history: VecDeque::with_capacity(15),
            vehicle_x_history: VecDeque::with_capacity(15),
            history_size: 15,
            crossing_margin: 20.0, // pixels - margin for noise tolerance
        }
    }

    pub fn detect_crossing(
        &mut self,
        left_x: Option<f32>,
        right_x: Option<f32>,
        vehicle_x: f32,
    ) -> CrossingType {
        // Need history to detect crossing
        if self.left_lane_x_history.is_empty() {
            self.update_history(left_x, right_x, vehicle_x);
            return CrossingType::None;
        }

        match (left_x, right_x) {
            (Some(lx), Some(rx)) => {
                // Get previous positions
                let prev_left = self.left_lane_x_history.back().copied();
                let prev_right = self.right_lane_x_history.back().copied();
                let prev_vehicle = self.vehicle_x_history.back().copied();

                if let (Some(prev_lx), Some(prev_rx), Some(prev_vx)) =
                    (prev_left, prev_right, prev_vehicle)
                {
                    // Check if vehicle WAS inside lane boundaries
                    let was_inside = prev_vx > (prev_lx + self.crossing_margin)
                        && prev_vx < (prev_rx - self.crossing_margin);

                    // Check if vehicle IS STILL inside lane boundaries
                    let is_inside = vehicle_x > (lx + self.crossing_margin)
                        && vehicle_x < (rx - self.crossing_margin);

                    // Crossing detected if vehicle went from inside to outside
                    if was_inside && !is_inside {
                        let crossing_type = if vehicle_x <= lx + self.crossing_margin {
                            CrossingType::CrossedLeft
                        } else if vehicle_x >= rx - self.crossing_margin {
                            CrossingType::CrossedRight
                        } else {
                            CrossingType::None
                        };

                        if crossing_type != CrossingType::None {
                            debug!(
                                " Boundary crossing detected: {:?} | Vehicle: {:.1} | Left: {:.1} | Right: {:.1}",
                                crossing_type, vehicle_x, lx, rx
                            );
                        }

                        self.update_history(left_x, right_x, vehicle_x);
                        return crossing_type;
                    }
                }

                self.update_history(left_x, right_x, vehicle_x);
                CrossingType::None
            }
            _ => {
                // Can't detect crossing without both lane boundaries
                self.update_history(left_x, right_x, vehicle_x);
                CrossingType::None
            }
        }
    }

    fn update_history(&mut self, left_x: Option<f32>, right_x: Option<f32>, vehicle_x: f32) {
        if let Some(lx) = left_x {
            self.left_lane_x_history.push_back(lx);
            if self.left_lane_x_history.len() > self.history_size {
                self.left_lane_x_history.pop_front();
            }
        }

        if let Some(rx) = right_x {
            self.right_lane_x_history.push_back(rx);
            if self.right_lane_x_history.len() > self.history_size {
                self.right_lane_x_history.pop_front();
            }
        }

        self.vehicle_x_history.push_back(vehicle_x);
        if self.vehicle_x_history.len() > self.history_size {
            self.vehicle_x_history.pop_front();
        }
    }

    pub fn reset(&mut self) {
        self.left_lane_x_history.clear();
        self.right_lane_x_history.clear();
        self.vehicle_x_history.clear();
    }
}
=== ./src/analysis/curve_detector.rs ===
// src/analysis/curve_detector.rs

use crate::types::Lane;
use std::collections::VecDeque;
use tracing::debug;

pub struct CurveDetector {
    lane_angle_history: VecDeque<f32>,
    history_size: usize,
    curve_threshold: f32,
}

impl CurveDetector {
    pub fn new() -> Self {
        Self {
            lane_angle_history: VecDeque::with_capacity(30),
            history_size: 30,
            curve_threshold: 5.0, // degrees
        }
    }

    pub fn is_in_curve(&mut self, lanes: &[Lane]) -> bool {
        let angle = self.calculate_lane_angle(lanes);

        self.lane_angle_history.push_back(angle);
        if self.lane_angle_history.len() > self.history_size {
            self.lane_angle_history.pop_front();
        }

        if self.lane_angle_history.len() < 10 {
            return false;
        }

        // Calculate average absolute angle
        let avg_angle: f32 = self.lane_angle_history.iter().map(|a| a.abs()).sum::<f32>()
            / self.lane_angle_history.len() as f32;

        let is_curve = avg_angle > self.curve_threshold;

        if is_curve {
            debug!(
                " Curve detected: avg angle = {:.1} (threshold: {:.1})",
                avg_angle, self.curve_threshold
            );
        }

        is_curve
    }

    fn calculate_lane_angle(&self, lanes: &[Lane]) -> f32 {
        // Find the most confident lane with enough points
        let best_lane = lanes.iter().filter(|l| l.points.len() >= 5).max_by(|a, b| {
            a.confidence
                .partial_cmp(&b.confidence)
                .unwrap_or(std::cmp::Ordering::Equal)
        });

        if let Some(lane) = best_lane {
            // Calculate angle between bottom and top points
            if lane.points.len() >= 2 {
                let bottom = &lane.points[0];
                let top = &lane.points[lane.points.len() - 1];

                let dx = top.x - bottom.x;
                let dy = top.y - bottom.y;

                if dy.abs() > 10.0 {
                    // Prevent division by near-zero
                    let angle_rad = (dx / dy).atan();
                    let angle_deg = angle_rad.to_degrees();
                    return angle_deg;
                }
            }
        }

        0.0 // No curve detected
    }

    pub fn reset(&mut self) {
        self.lane_angle_history.clear();
    }
}
=== ./src/frame_buffer.rs ===
// src/frame_buffer.rs

use crate::types::{Frame, LaneChangeEvent};
use base64::{engine::general_purpose::STANDARD, Engine as _};
use serde::{Deserialize, Serialize};
use std::collections::VecDeque;
use std::path::Path;
use tracing::{error, info};

/// Buffer to capture frames during a lane change event with pre-buffering
pub struct LaneChangeFrameBuffer {
    frames: Vec<Frame>,
    max_frames: usize,
    is_capturing: bool,
    capture_start_frame_id: Option<u64>,
    /// Pre-buffer: keeps last N frames before lane change starts
    pre_buffer: VecDeque<Frame>,
    pre_buffer_size: usize,
}

impl LaneChangeFrameBuffer {
    pub fn new(max_frames: usize) -> Self {
        // Pre-buffer holds frames BEFORE lane change starts (e.g., 20 frames)
        let pre_buffer_size = 20;

        Self {
            frames: Vec::with_capacity(max_frames),
            max_frames,
            is_capturing: false,
            capture_start_frame_id: None,
            pre_buffer: VecDeque::with_capacity(pre_buffer_size),
            pre_buffer_size,
        }
    }

    /// Add frame to pre-buffer (called continuously while in CENTERED state)
    pub fn add_to_pre_buffer(&mut self, frame: Frame) {
        self.pre_buffer.push_back(frame);
        if self.pre_buffer.len() > self.pre_buffer_size {
            self.pre_buffer.pop_front();
        }
    }

    pub fn start_capture(&mut self, frame_id: u64) {
        self.frames.clear();
        self.is_capturing = true;
        self.capture_start_frame_id = Some(frame_id);

        // Transfer pre-buffer frames to main buffer
        let pre_buffer_count = self.pre_buffer.len();
        for frame in self.pre_buffer.drain(..) {
            if self.frames.len() < self.max_frames {
                self.frames.push(frame);
            }
        }

        info!(
            " Started capturing at frame {} (included {} pre-buffered frames)",
            frame_id, pre_buffer_count
        );
    }

    pub fn add_frame(&mut self, frame: Frame) {
        if self.is_capturing && self.frames.len() < self.max_frames {
            self.frames.push(frame);
        }
    }

    pub fn stop_capture(&mut self) -> Vec<Frame> {
        self.is_capturing = false;
        self.capture_start_frame_id = None;
        let frames = std::mem::take(&mut self.frames);
        info!(" Stopped capturing. Total frames: {}", frames.len());
        frames
    }

    pub fn is_capturing(&self) -> bool {
        self.is_capturing
    }

    pub fn frame_count(&self) -> usize {
        self.frames.len()
    }

    pub fn cancel_capture(&mut self) {
        self.frames.clear();
        self.is_capturing = false;
        self.capture_start_frame_id = None;
    }

    pub fn pre_buffer_count(&self) -> usize {
        self.pre_buffer.len()
    }
}

// ============================================================================
// ENHANCED API STRUCTURES WITH DETECTION METADATA
// ============================================================================

/// Detection quality metadata to help AI make better decisions
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DetectionMetadata {
    /// Confidence of the lane change detection (0.0-1.0)
    pub detection_confidence: f32,
    /// Maximum lateral offset reached during maneuver (normalized, 0.0-1.0)
    pub max_offset_normalized: f32,
    /// Average lane detection confidence across frames (0.0-1.0)
    pub avg_lane_confidence: f32,
    /// Percentage of frames where both lanes were detected (0.0-1.0)
    pub both_lanes_ratio: f32,
    /// Video resolution (e.g., "1280x720")
    pub video_resolution: String,
    /// Frames per second
    pub fps: f32,
    /// Country/region for traffic rules (e.g., "PE" for Peru)
    pub region: String,
    /// Average lane width in pixels during the maneuver
    pub avg_lane_width_px: Option<f32>,
}

/// Enhanced payload for the legality analysis API
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LaneChangeLegalityRequest {
    pub event_id: String,
    pub direction: String,
    pub start_frame_id: u64,
    pub end_frame_id: u64,
    pub video_timestamp_ms: f64,
    pub duration_ms: Option<f64>,
    pub source_id: String,
    pub frames: Vec<FrameData>,
    /// NEW: Detection quality metadata
    pub detection_metadata: DetectionMetadata,
}

/// Enhanced frame data with per-frame metadata
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FrameData {
    pub frame_index: usize,
    pub timestamp_ms: f64,
    pub width: usize,
    pub height: usize,
    pub base64_image: String,
    /// NEW: Lane detection confidence for this frame (if available)
    #[serde(skip_serializing_if = "Option::is_none")]
    pub lane_confidence: Option<f32>,
    /// NEW: Lateral offset as percentage of lane width (if available)
    #[serde(skip_serializing_if = "Option::is_none")]
    pub offset_percentage: Option<f32>,
}

/// Response from the legality API
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LaneChangeLegalityResponse {
    pub event_id: String,
    pub status: String,
    pub message: String,
}

// ============================================================================
// HELPER FUNCTIONS
// ============================================================================

/// Extract key frames emphasizing CONTEXT and PROGRESSION
pub fn extract_key_frames_for_lane_change(frames: &[Frame], count: usize) -> Vec<&Frame> {
    if frames.is_empty() || count == 0 {
        return vec![];
    }

    if frames.len() <= count {
        return frames.iter().collect();
    }

    let mut selected_indices = Vec::with_capacity(count);

    // Strategy: Include frames from BEFORE, DURING, and AFTER the maneuver
    // This gives the AI context about what was "normal" before the change

    match count {
        5 => {
            // Frame 0: Start (should be from pre-buffer, BEFORE maneuver)
            // Frame 1: Early (25%)
            // Frame 2: Middle (50%)
            // Frame 3: Late (75%)
            // Frame 4: End (100%)
            selected_indices.push(0);
            selected_indices.push(frames.len() / 4);
            selected_indices.push(frames.len() / 2);
            selected_indices.push((frames.len() * 3) / 4);
            selected_indices.push(frames.len() - 1);
        }
        7 => {
            // More granular: every ~16%
            selected_indices.push(0); // 0%
            selected_indices.push(frames.len() / 6); // 16%
            selected_indices.push(frames.len() / 3); // 33%
            selected_indices.push(frames.len() / 2); // 50%
            selected_indices.push((frames.len() * 2) / 3); // 66%
            selected_indices.push((frames.len() * 5) / 6); // 83%
            selected_indices.push(frames.len() - 1); // 100%
        }
        _ => {
            // Evenly distributed
            let step = (frames.len() - 1) as f32 / (count - 1) as f32;
            for i in 0..count {
                let index = (i as f32 * step).round() as usize;
                selected_indices.push(index.min(frames.len() - 1));
            }
        }
    }

    selected_indices.into_iter().map(|i| &frames[i]).collect()
}

/// Convert frame to base64 JPEG with quality optimization
pub fn frame_to_base64(frame: &Frame) -> Result<String, anyhow::Error> {
    use image::{codecs::jpeg::JpegEncoder, ImageBuffer, Rgb};
    use std::io::Cursor;

    let img: ImageBuffer<Rgb<u8>, Vec<u8>> =
        ImageBuffer::from_raw(frame.width as u32, frame.height as u32, frame.data.clone())
            .ok_or_else(|| anyhow::anyhow!("Failed to create image buffer"))?;

    let mut buffer = Cursor::new(Vec::new());

    // Use explicit JPEG encoder with quality setting
    let mut encoder = JpegEncoder::new_with_quality(&mut buffer, 85);
    encoder.encode(
        img.as_raw(),
        img.width(),
        img.height(),
        image::ExtendedColorType::Rgb8,
    )?;

    Ok(STANDARD.encode(buffer.into_inner()))
}

/// Build the API request payload with enhanced metadata
pub fn build_legality_request(
    event: &LaneChangeEvent,
    captured_frames: &[Frame],
    num_frames_to_send: usize,
) -> Result<LaneChangeLegalityRequest, anyhow::Error> {
    let key_frames = extract_key_frames_for_lane_change(captured_frames, num_frames_to_send);

    if key_frames.is_empty() {
        anyhow::bail!("No frames to send");
    }

    let mut frame_data_list = Vec::with_capacity(key_frames.len());

    // Log which frames were selected
    let selected_indices: Vec<usize> = key_frames
        .iter()
        .filter_map(|kf| captured_frames.iter().position(|f| std::ptr::eq(*kf, f)))
        .collect();

    info!(
        " Selected {} frames from {} total: indices {:?}",
        key_frames.len(),
        captured_frames.len(),
        selected_indices
    );

    // Process each frame
    for (i, frame) in key_frames.iter().enumerate() {
        let base64_image = frame_to_base64(frame)?;

        let lane_confidence = None;
        let offset_percentage = None;

        frame_data_list.push(FrameData {
            frame_index: i,
            timestamp_ms: frame.timestamp_ms,
            width: frame.width,
            height: frame.height,
            base64_image,
            lane_confidence,
            offset_percentage,
        });
    }

    // Calculate video metadata
    let video_resolution = format!(
        "{}x{}",
        key_frames.first().unwrap().width,
        key_frames.first().unwrap().height
    );

    // Calculate FPS from frame timestamps
    let fps = if key_frames.len() >= 2 {
        let time_span =
            key_frames.last().unwrap().timestamp_ms - key_frames.first().unwrap().timestamp_ms;
        if time_span > 0.0 {
            ((key_frames.len() - 1) as f64 / (time_span / 1000.0)) as f32
        } else {
            25.0
        }
    } else {
        25.0
    };

    let max_offset_normalized = event
        .metadata
        .get("max_offset_normalized")
        .and_then(|v| v.as_f64())
        .map(|v| v as f32)
        .unwrap_or(0.5);

    let both_lanes_ratio = event
        .metadata
        .get("both_lanes_ratio")
        .and_then(|v| v.as_f64())
        .map(|v| v as f32)
        .unwrap_or(0.7);

    let avg_lane_confidence = event
        .metadata
        .get("avg_lane_confidence")
        .and_then(|v| v.as_f64())
        .map(|v| v as f32)
        .unwrap_or(0.6);

    let avg_lane_width_px = event
        .metadata
        .get("avg_lane_width_px")
        .and_then(|v| v.as_f64())
        .map(|v| v as f32);

    let metadata = DetectionMetadata {
        detection_confidence: event.confidence,
        max_offset_normalized,
        avg_lane_confidence,
        both_lanes_ratio,
        video_resolution,
        fps,
        region: "PE".to_string(),
        avg_lane_width_px,
    };

    info!(
        " Detection quality: conf={:.1}%, max_offset={:.1}%, lanes={:.0}%",
        metadata.detection_confidence * 100.0,
        metadata.max_offset_normalized * 100.0,
        metadata.both_lanes_ratio * 100.0
    );

    Ok(LaneChangeLegalityRequest {
        event_id: event.event_id.clone(),
        direction: event.direction_name().to_string(),
        start_frame_id: event.start_frame_id,
        end_frame_id: event.end_frame_id,
        video_timestamp_ms: event.video_timestamp_ms,
        duration_ms: event.duration_ms,
        source_id: event.source_id.clone(),
        frames: frame_data_list,
        detection_metadata: metadata,
    })
}

/// Send the request to the legality analysis API
pub async fn send_to_legality_api(
    request: &LaneChangeLegalityRequest,
    api_url: &str,
) -> Result<LaneChangeLegalityResponse, anyhow::Error> {
    let client = reqwest::Client::builder()
        .timeout(std::time::Duration::from_secs(60))
        .build()?;

    info!(
        " Sending event {} to legality API at {}",
        request.event_id, api_url
    );

    let response = client.post(api_url).json(request).send().await;

    match response {
        Ok(resp) => {
            let status = resp.status();

            if !status.is_success() {
                let body = resp.text().await.unwrap_or_default();
                anyhow::bail!("API error {}: {}", status, body);
            }

            let result = resp.json::<LaneChangeLegalityResponse>().await?;

            info!(
                " API response for {}: {} - {}",
                result.event_id, result.status, result.message
            );

            Ok(result)
        }
        Err(e) => {
            error!(" Failed to connect to API: {}", e);
            anyhow::bail!("Failed to connect to API: {}", e)
        }
    }
}

/// Print the request payload to console with enhanced metadata
pub fn print_legality_request(request: &LaneChangeLegalityRequest) {
    println!("\n============================================================");
    println!(" LANE CHANGE LEGALITY CHECK REQUEST");
    println!("============================================================");
    println!("Event ID: {}", request.event_id);
    println!("Direction: {}", request.direction);
    println!(
        "Frames: {} -> {}",
        request.start_frame_id, request.end_frame_id
    );
    println!("Timestamp: {:.2}s", request.video_timestamp_ms / 1000.0);
    if let Some(duration) = request.duration_ms {
        println!("Duration: {:.0}ms", duration);
    }
    println!("Source: {}", request.source_id);

    println!("\n Detection Quality:");
    println!(
        "   Confidence:       {:.0}%",
        request.detection_metadata.detection_confidence * 100.0
    );
    println!(
        "   Max offset:       {:.0}%",
        request.detection_metadata.max_offset_normalized * 100.0
    );
    println!(
        "   Lane confidence:  {:.0}%",
        request.detection_metadata.avg_lane_confidence * 100.0
    );
    println!(
        "   Both lanes ratio: {:.0}%",
        request.detection_metadata.both_lanes_ratio * 100.0
    );
    println!(
        "   Resolution:       {}",
        request.detection_metadata.video_resolution
    );
    println!(
        "   FPS:              {:.1}",
        request.detection_metadata.fps
    );
    if let Some(width) = request.detection_metadata.avg_lane_width_px {
        println!("   Avg lane width:   {:.0}px", width);
    }

    println!("\n Frames for analysis: {}", request.frames.len());
    for frame_data in &request.frames {
        print!(
            "  Frame {}: {}x{} @ {:.2}s | base64: {} chars",
            frame_data.frame_index,
            frame_data.width,
            frame_data.height,
            frame_data.timestamp_ms / 1000.0,
            frame_data.base64_image.len()
        );
        if let Some(conf) = frame_data.lane_confidence {
            print!(" | lane_conf: {:.0}%", conf * 100.0);
        }
        if let Some(offset) = frame_data.offset_percentage {
            print!(" | offset: {:.0}%", offset * 100.0);
        }
        println!();
    }
    println!("============================================================\n");
}

/// Save the request to a JSON file
pub fn save_legality_request_to_file(
    request: &LaneChangeLegalityRequest,
    output_dir: &str,
) -> Result<std::path::PathBuf, anyhow::Error> {
    let dir = Path::new(output_dir).join("legality_requests");
    std::fs::create_dir_all(&dir)?;

    let filename = format!("{}_legality_request.json", request.event_id);
    let filepath = dir.join(&filename);

    let json = serde_json::to_string_pretty(request)?;
    std::fs::write(&filepath, json)?;

    info!(" Saved legality request to: {}", filepath.display());
    Ok(filepath)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_extract_key_frames_for_lane_change() {
        let frames: Vec<Frame> = (0..10)
            .map(|i| Frame {
                data: vec![],
                width: 1280,
                height: 720,
                timestamp_ms: i as f64 * 100.0,
            })
            .collect();
        let key_frames = extract_key_frames_for_lane_change(&frames, 5);
        assert_eq!(key_frames.len(), 5);

        assert_eq!(key_frames[0].timestamp_ms, 0.0);
        assert_eq!(key_frames[4].timestamp_ms, 900.0);
    }
}
=== ./src/types.rs ===
// src/types.rs

use serde::{Deserialize, Serialize};
use std::collections::HashMap;

// ============================================================================
// Configuration Structs
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Config {
    pub model: ModelConfig,
    pub inference: InferenceConfig,
    pub detection: DetectionConfig,
    pub video: VideoConfig,
    pub logging: LoggingConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelConfig {
    pub path: String,
    pub input_width: usize,
    pub input_height: usize,
    pub num_anchors: usize,
    pub num_lanes: usize,
    pub griding_num: usize,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct InferenceConfig {
    pub use_tensorrt: bool,
    pub use_fp16: bool,
    pub enable_engine_cache: bool,
    pub engine_cache_path: String,
    pub num_threads: usize,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DetectionConfig {
    pub confidence_threshold: f32,
    pub min_points_per_lane: usize,
    pub smoother_window_size: usize,
    pub calibration_frames: usize,
    pub debounce_frames: u32,
    pub confirm_frames: u32,
    pub min_lane_confidence: f32,
    pub min_position_confidence: f32,
    #[serde(default = "default_drift_threshold")]
    pub drift_threshold: f32,
    #[serde(default = "default_crossing_threshold")]
    pub crossing_threshold: f32,
    #[serde(default = "default_cooldown_frames")]
    pub cooldown_frames: u32,
    #[serde(default = "default_min_duration")]
    pub min_lane_change_duration_ms: f64,
    #[serde(default = "default_max_duration")]
    pub max_lane_change_duration_ms: f64,
    #[serde(default = "default_skip_initial")]
    pub skip_initial_frames: u64,
    #[serde(default = "default_require_both_lanes")]
    pub require_both_lanes: bool,
}

fn default_drift_threshold() -> f32 {
    0.30
}
fn default_crossing_threshold() -> f32 {
    0.55
}
fn default_cooldown_frames() -> u32 {
    90
}
fn default_min_duration() -> f64 {
    1500.0
}
fn default_max_duration() -> f64 {
    5000.0
}
fn default_skip_initial() -> u64 {
    150
}
fn default_require_both_lanes() -> bool {
    true
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VideoConfig {
    pub input_dir: String,
    pub output_dir: String,
    pub source_width: usize,
    pub source_height: usize,
    pub target_fps: u32,
    pub save_annotated: bool,
    pub save_events_only: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LoggingConfig {
    pub level: String,
}

impl Config {
    pub fn load(path: &str) -> anyhow::Result<Self> {
        let contents = std::fs::read_to_string(path)?;
        let config: Config = serde_yaml::from_str(&contents)?;
        Ok(config)
    }
}

// ============================================================================
// Frame Type
// ============================================================================

#[derive(Debug, Clone)]
pub struct Frame {
    pub data: Vec<u8>,
    pub width: usize,
    pub height: usize,
    pub timestamp_ms: f64,
}

// ============================================================================
// Lane Detection Types
// ============================================================================

#[derive(Debug, Clone)]
pub struct DetectedLane {
    pub points: Vec<(f32, f32)>,
    pub confidence: f32,
}

// ============================================================================
// Analysis Types
// ============================================================================

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub enum LaneChangeState {
    Centered,
    Drifting,
    Crossing,
    Completed,
}

impl LaneChangeState {
    pub fn as_str(&self) -> &'static str {
        match self {
            LaneChangeState::Centered => "CENTERED",
            LaneChangeState::Drifting => "DRIFTING",
            LaneChangeState::Crossing => "CROSSING",
            LaneChangeState::Completed => "COMPLETED",
        }
    }
}

impl std::fmt::Display for LaneChangeState {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", self.as_str())
    }
}

#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub struct Point {
    pub x: f32,
    pub y: f32,
}

impl Point {
    pub fn new(x: f32, y: f32) -> Self {
        Self { x, y }
    }

    pub fn distance_to(&self, other: &Point) -> f32 {
        ((self.x - other.x).powi(2) + (self.y - other.y).powi(2)).sqrt()
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum LanePosition {
    LeftFar,
    LeftNear,
    RightNear,
    RightFar,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Lane {
    pub lane_id: usize,
    pub points: Vec<Point>,
    pub confidence: f32,
    pub position: Option<LanePosition>,
}

impl Lane {
    pub fn from_detected(lane_id: usize, detected: &DetectedLane) -> Self {
        Self {
            lane_id,
            points: detected
                .points
                .iter()
                .map(|p| Point::new(p.0, p.1))
                .collect(),
            confidence: detected.confidence,
            position: None,
        }
    }

    pub fn get_x_at_y(&self, target_y: f32) -> Option<f32> {
        if self.points.len() < 2 {
            return None;
        }

        let mut sorted_points = self.points.clone();
        sorted_points.sort_by(|a, b| a.y.partial_cmp(&b.y).unwrap_or(std::cmp::Ordering::Equal));

        for i in 0..sorted_points.len() - 1 {
            let p1 = &sorted_points[i];
            let p2 = &sorted_points[i + 1];

            if p1.y <= target_y && target_y <= p2.y {
                if (p2.y - p1.y).abs() < 1e-6 {
                    return Some(p1.x);
                }
                let ratio = (target_y - p1.y) / (p2.y - p1.y);
                return Some(p1.x + ratio * (p2.x - p1.x));
            }
        }
        None
    }

    pub fn avg_x(&self) -> f32 {
        if self.points.is_empty() {
            return 0.0;
        }
        self.points.iter().map(|p| p.x).sum::<f32>() / self.points.len() as f32
    }

    pub fn bottom_point(&self) -> Option<&Point> {
        self.points
            .iter()
            .max_by(|a, b| a.y.partial_cmp(&b.y).unwrap_or(std::cmp::Ordering::Equal))
    }
}

// ============================================================================
// Vehicle State
// ============================================================================

#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub struct VehicleState {
    pub lateral_offset: f32,
    pub lane_width: Option<f32>,
    pub heading_offset: f32,
    pub frame_id: u64,
    pub timestamp_ms: f64,
    pub raw_offset: f32,
    pub detection_confidence: f32,
    pub both_lanes_detected: bool,
}

impl VehicleState {
    pub fn invalid() -> Self {
        Self {
            lateral_offset: 0.0,
            lane_width: None,
            heading_offset: 0.0,
            frame_id: 0,
            timestamp_ms: 0.0,
            raw_offset: 0.0,
            detection_confidence: 0.0,
            both_lanes_detected: false,
        }
    }

    pub fn normalized_offset(&self) -> Option<f32> {
        match self.lane_width {
            Some(width) if width > 1.0 => Some(self.lateral_offset / width),
            _ => None,
        }
    }

    pub fn is_valid(&self) -> bool {
        self.lane_width.map_or(false, |w| w > 50.0)
    }
}

// ============================================================================
// Direction
// ============================================================================

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum Direction {
    Left = -1,
    Unknown = 0,
    Right = 1,
}

impl Direction {
    pub fn from_offset(offset: f32) -> Self {
        if offset > 0.0 {
            Direction::Right
        } else if offset < 0.0 {
            Direction::Left
        } else {
            Direction::Unknown
        }
    }

    pub fn as_str(&self) -> &'static str {
        match self {
            Direction::Left => "LEFT",
            Direction::Right => "RIGHT",
            Direction::Unknown => "UNKNOWN",
        }
    }

    pub fn as_i32(&self) -> i32 {
        match self {
            Direction::Left => -1,
            Direction::Right => 1,
            Direction::Unknown => 0,
        }
    }
}

impl std::fmt::Display for Direction {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", self.as_str())
    }
}

// ============================================================================
// Evidence Paths
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EvidencePaths {
    pub start_image_path: String,
    pub end_image_path: String,
}

// ============================================================================
// Lane Change Event
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LaneChangeEvent {
    pub event_id: String,
    pub timestamp: String,
    pub video_timestamp_ms: f64,
    pub start_frame_id: u64,
    pub end_frame_id: u64,
    pub direction: Direction,
    pub confidence: f32,
    pub duration_ms: Option<f64>,
    pub source_id: String,
    pub evidence_images: Option<EvidencePaths>,
    pub metadata: HashMap<String, serde_json::Value>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub legality: Option<LegalityInfo>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LegalityInfo {
    pub is_legal: bool,
    pub lane_line_type: String,
    pub confidence: f32,
    pub analysis_details: Option<String>,
}

impl LaneChangeEvent {
    pub fn new(
        video_timestamp_ms: f64,
        start_frame_id: u64,
        end_frame_id: u64,
        direction: Direction,
        confidence: f32,
    ) -> Self {
        Self {
            event_id: uuid::Uuid::new_v4().to_string(),
            timestamp: chrono::Utc::now().to_rfc3339(),
            video_timestamp_ms,
            start_frame_id,
            end_frame_id,
            direction,
            confidence,
            duration_ms: None,
            source_id: String::new(),
            evidence_images: None,
            metadata: HashMap::new(),
            legality: None,
        }
    }

    pub fn direction_name(&self) -> &'static str {
        self.direction.as_str()
    }

    pub fn to_json(&self) -> serde_json::Value {
        serde_json::json!({
            "event_id": self.event_id,
            "type": "lane_change",
            "direction": self.direction_name(),
            "timestamp_ms": self.video_timestamp_ms,
            "frames": {
                "start": self.start_frame_id,
                "end": self.end_frame_id
            },
            "evidence": self.evidence_images,
            "duration_ms": self.duration_ms,
            "source_id": self.source_id,
            "metadata": self.metadata,
            "legality": self.legality,
        })
    }
}

// ============================================================================
// Lane Change Config
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LaneChangeConfig {
    pub drift_threshold: f32,
    pub crossing_threshold: f32,
    pub min_frames_confirm: u32,
    pub cooldown_frames: u32,
    pub smoothing_alpha: f32,
    pub reference_y_ratio: f32,
    pub hysteresis_factor: f32,
    pub min_duration_ms: f64,
    pub max_duration_ms: f64,
    pub skip_initial_frames: u64,
    pub require_both_lanes: bool,
}

impl Default for LaneChangeConfig {
    fn default() -> Self {
        Self {
            drift_threshold: 0.30,
            crossing_threshold: 0.55,
            min_frames_confirm: 12,
            cooldown_frames: 90,
            smoothing_alpha: 0.3,
            reference_y_ratio: 0.8,
            hysteresis_factor: 0.5,
            min_duration_ms: 1500.0,
            max_duration_ms: 5000.0,
            skip_initial_frames: 150,
            require_both_lanes: true,
        }
    }
}

impl LaneChangeConfig {
    pub fn from_detection_config(detection: &DetectionConfig) -> Self {
        Self {
            drift_threshold: detection.drift_threshold,
            crossing_threshold: detection.crossing_threshold,
            min_frames_confirm: detection.confirm_frames,
            cooldown_frames: detection.cooldown_frames,
            smoothing_alpha: 0.3,
            reference_y_ratio: 0.8,
            hysteresis_factor: 0.5,
            min_duration_ms: detection.min_lane_change_duration_ms,
            max_duration_ms: detection.max_lane_change_duration_ms,
            skip_initial_frames: detection.skip_initial_frames,
            require_both_lanes: detection.require_both_lanes,
        }
    }
}
=== ./src/preprocessing.rs ===
// src/preprocessing.rs

use anyhow::Result;

/// Preprocess raw RGB image for model input
pub fn preprocess(
    src: &[u8],
    src_width: usize,
    src_height: usize,
    dst_width: usize,
    dst_height: usize,
) -> Result<Vec<f32>> {
    // Resize
    let resized = resize_bilinear(src, src_width, src_height, dst_width, dst_height);

    // Normalize and convert HWC -> CHW
    const MEAN: [f32; 3] = [0.485, 0.456, 0.406];
    const STD: [f32; 3] = [0.229, 0.224, 0.225];

    let mut output = vec![0.0f32; 3 * dst_height * dst_width];

    for c in 0..3 {
        for h in 0..dst_height {
            for w in 0..dst_width {
                let hwc_idx = (h * dst_width + w) * 3 + c;
                let chw_idx = c * dst_height * dst_width + h * dst_width + w;

                let pixel = resized[hwc_idx] as f32 / 255.0;
                output[chw_idx] = (pixel - MEAN[c]) / STD[c];
            }
        }
    }

    Ok(output)
}

/// Bilinear image resize
fn resize_bilinear(src: &[u8], src_w: usize, src_h: usize, dst_w: usize, dst_h: usize) -> Vec<u8> {
    let mut dst = vec![0u8; dst_h * dst_w * 3];

    let x_ratio = src_w as f32 / dst_w as f32;
    let y_ratio = src_h as f32 / dst_h as f32;

    for dy in 0..dst_h {
        for dx in 0..dst_w {
            let sx = dx as f32 * x_ratio;
            let sy = dy as f32 * y_ratio;

            let sx0 = sx.floor() as usize;
            let sy0 = sy.floor() as usize;
            let sx1 = (sx0 + 1).min(src_w - 1);
            let sy1 = (sy0 + 1).min(src_h - 1);

            let fx = sx - sx0 as f32;
            let fy = sy - sy0 as f32;

            for c in 0..3 {
                let p00 = src[(sy0 * src_w + sx0) * 3 + c] as f32;
                let p10 = src[(sy0 * src_w + sx1) * 3 + c] as f32;
                let p01 = src[(sy1 * src_w + sx0) * 3 + c] as f32;
                let p11 = src[(sy1 * src_w + sx1) * 3 + c] as f32;

                let val = p00 * (1.0 - fx) * (1.0 - fy)
                    + p10 * fx * (1.0 - fy)
                    + p01 * (1.0 - fx) * fy
                    + p11 * fx * fy;

                dst[(dy * dst_w + dx) * 3 + c] = val.round() as u8;
            }
        }
    }

    dst
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_preprocess() {
        let src = vec![128u8; 640 * 480 * 3];
        let result = preprocess(&src, 640, 480, 1600, 320);
        assert!(result.is_ok());
        assert_eq!(result.unwrap().len(), 3 * 320 * 1600);
    }

    #[test]
    fn test_resize() {
        let src = vec![255u8; 100 * 100 * 3];
        let dst = resize_bilinear(&src, 100, 100, 50, 50);
        assert_eq!(dst.len(), 50 * 50 * 3);
    }
}
=== ./src/config.rs ===
use crate::types::Config;
use anyhow::Result;
use std::fs;

impl Config {
    pub fn load(path: &str) -> Result<Self> {
        let contents = fs::read_to_string(path)?;
        let config: Config = serde_yaml::from_str(&contents)?;
        Ok(config)
    }
}
=== ./README.md ===
# overtake-detection
=== ./combined.txt ===
//
// EVERYTHING BELOW THIS POINT WAS AUTO-GENERATED DURING COMPILATION. DO NOT MODIFY.
//
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The Continuous Integration platform detected during compilation."#]
#[allow(dead_code)]
pub static CI_PLATFORM: Option<&str> = None;
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The full version."#]
#[allow(dead_code)]
pub static PKG_VERSION: &str = "0.8.1";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The major version."#]
#[allow(dead_code)]
pub static PKG_VERSION_MAJOR: &str = "0";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The minor version."#]
#[allow(dead_code)]
pub static PKG_VERSION_MINOR: &str = "8";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The patch version."#]
#[allow(dead_code)]
pub static PKG_VERSION_PATCH: &str = "1";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The pre-release version."#]
#[allow(dead_code)]
pub static PKG_VERSION_PRE: &str = "";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"A colon-separated list of authors."#]
#[allow(dead_code)]
pub static PKG_AUTHORS: &str = "Thomas Daede <tdaede@xiph.org>";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The name of the package."#]
#[allow(dead_code)]
pub static PKG_NAME: &str = "rav1e";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The description."#]
#[allow(dead_code)]
pub static PKG_DESCRIPTION: &str = "The fastest and safest AV1 encoder";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The homepage."#]
#[allow(dead_code)]
pub static PKG_HOMEPAGE: &str = "";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The license."#]
#[allow(dead_code)]
pub static PKG_LICENSE: &str = "BSD-2-Clause";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The source repository as advertised in Cargo.toml."#]
#[allow(dead_code)]
pub static PKG_REPOSITORY: &str = "https://github.com/xiph/rav1e/";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The target triple that was being compiled for."#]
#[allow(dead_code)]
pub static TARGET: &str = "aarch64-apple-darwin";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The host triple of the rust compiler."#]
#[allow(dead_code)]
pub static HOST: &str = "aarch64-apple-darwin";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"`release` for release builds, `debug` for other builds."#]
#[allow(dead_code)]
pub static PROFILE: &str = "debug";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The compiler that cargo resolved to use."#]
#[allow(dead_code)]
pub static RUSTC: &str = "/Users/abraxas/.rustup/toolchains/stable-aarch64-apple-darwin/bin/rustc";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The documentation generator that cargo resolved to use."#]
#[allow(dead_code)]
pub static RUSTDOC: &str = "/Users/abraxas/.rustup/toolchains/stable-aarch64-apple-darwin/bin/rustdoc";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"Value of OPT_LEVEL for the profile used during compilation."#]
#[allow(dead_code)]
pub static OPT_LEVEL: &str = "0";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The parallelism that was specified during compilation."#]
#[allow(dead_code)]
pub static NUM_JOBS: u32 = 12;
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"Value of DEBUG for the profile used during compilation."#]
#[allow(dead_code)]
pub static DEBUG: bool = true;
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The features that were enabled during compilation."#]
#[allow(dead_code)]
pub static FEATURES: [&str; 1] = ["THREADING"];
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The features as a comma-separated string."#]
#[allow(dead_code)]
pub static FEATURES_STR: &str = "THREADING";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The features as above, as lowercase strings."#]
#[allow(dead_code)]
pub static FEATURES_LOWERCASE: [&str; 1] = ["threading"];
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The feature-string as above, from lowercase strings."#]
#[allow(dead_code)]
pub static FEATURES_LOWERCASE_STR: &str = "threading";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The output of `/Users/abraxas/.rustup/toolchains/stable-aarch64-apple-darwin/bin/rustc -V`"#]
#[allow(dead_code)]
pub static RUSTC_VERSION: &str = "rustc 1.92.0 (ded5c06cf 2025-12-08)";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The output of `/Users/abraxas/.rustup/toolchains/stable-aarch64-apple-darwin/bin/rustdoc -V`; empty string if `/Users/abraxas/.rustup/toolchains/stable-aarch64-apple-darwin/bin/rustdoc -V` failed to execute"#]
#[allow(dead_code)]
pub static RUSTDOC_VERSION: &str = "rustdoc 1.92.0 (ded5c06cf 2025-12-08)";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The target architecture, given by `CARGO_CFG_TARGET_ARCH`."#]
#[allow(dead_code)]
pub static CFG_TARGET_ARCH: &str = "aarch64";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The endianness, given by `CARGO_CFG_TARGET_ENDIAN`."#]
#[allow(dead_code)]
pub static CFG_ENDIAN: &str = "little";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The toolchain-environment, given by `CARGO_CFG_TARGET_ENV`."#]
#[allow(dead_code)]
pub static CFG_ENV: &str = "";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The OS-family, given by `CARGO_CFG_TARGET_FAMILY`."#]
#[allow(dead_code)]
pub static CFG_FAMILY: &str = "unix";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The operating system, given by `CARGO_CFG_TARGET_OS`."#]
#[allow(dead_code)]
pub static CFG_OS: &str = "macos";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The pointer width, given by `CARGO_CFG_TARGET_POINTER_WIDTH`."#]
#[allow(dead_code)]
pub static CFG_POINTER_WIDTH: &str = "64";
#[allow(clippy::needless_raw_string_hashes)]
#[doc=r#"The override-variables that were used during compilation."#]
#[allow(dead_code)]
pub static OVERRIDE_VARIABLES_USED: [&str; 0] = [];
//
// EVERYTHING ABOVE THIS POINT WAS AUTO-GENERATED DURING COMPILATION. DO NOT MODIFY.
//
#[doc(hidden)]
pub mod __private17 {
    #[doc(hidden)]
    pub use crate::private::*;
}
#[doc(hidden)]
pub mod __private228 {
    #[doc(hidden)]
    pub use crate::private::*;
}
use serde_core::__private228 as serde_core_private;
#[doc(hidden)]
pub mod __private228 {
    #[doc(hidden)]
    pub use crate::private::*;
}
// src/smoother.rs

use crate::types::VehiclePosition;
use std::collections::{HashMap, VecDeque};

/// Temporal smoother for vehicle position using a sliding window
pub struct LanePositionSmoother {
    history: VecDeque<VehiclePosition>,
    window_size: usize,
}

impl LanePositionSmoother {
    /// Create a new smoother with specified window size
    ///
    /// # Arguments
    /// * `window_size` - Number of frames to use for smoothing (e.g., 10 frames)
    pub fn new(window_size: usize) -> Self {
        Self {
            history: VecDeque::with_capacity(window_size),
            window_size,
        }
    }

    /// Smooth the current position using temporal window
    ///
    /// Uses different strategies for different components:
    /// - Lane index: Mode (most common value)
    /// - Lateral offset: Median (resistant to outliers)
    /// - Confidence: Average
    pub fn smooth(&mut self, position: VehiclePosition) -> VehiclePosition {
        self.history.push_back(position);

        // Maintain window size
        if self.history.len() > self.window_size {
            self.history.pop_front();
        }

        // Need at least 3 frames for meaningful smoothing
        if self.history.len() < 3 {
            return position;
        }

        VehiclePosition {
            lane_index: self.smooth_lane_index(),
            lateral_offset: self.smooth_lateral_offset(),
            confidence: self.smooth_confidence(),
            timestamp: position.timestamp, // Keep current timestamp
        }
    }

    /// Get the most common lane index (mode)
    fn smooth_lane_index(&self) -> i32 {
        let mut counts: HashMap<i32, usize> = HashMap::new();

        for pos in &self.history {
            *counts.entry(pos.lane_index).or_insert(0) += 1;
        }

        counts
            .into_iter()
            .max_by_key(|(_, count)| *count)
            .map(|(lane, _)| lane)
            .unwrap_or(-1)
    }

    /// Get median lateral offset (resistant to outliers)
    fn smooth_lateral_offset(&self) -> f32 {
        let mut offsets: Vec<f32> = self.history.iter().map(|p| p.lateral_offset).collect();
        offsets.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
        offsets[offsets.len() / 2]
    }

    /// Get average confidence
    fn smooth_confidence(&self) -> f32 {
        let sum: f32 = self.history.iter().map(|p| p.confidence).sum();
        sum / self.history.len() as f32
    }

    /// Reset the smoother (e.g., when video changes)
    pub fn reset(&mut self) {
        self.history.clear();
    }

    /// Get the number of frames currently in the history
    pub fn history_size(&self) -> usize {
        self.history.len()
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_smoother_mode_for_lane_index() {
        let mut smoother = LanePositionSmoother::new(5);

        // Feed noisy lane detections: [1, 1, 2, 1, 1]
        let positions = vec![
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.0,
            },
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.033,
            },
            VehiclePosition {
                lane_index: 2, // noise
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.066,
            },
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.099,
            },
            VehiclePosition {
                lane_index: 1,
                lateral_offset: 0.0,
                confidence: 0.8,
                timestamp: 0.132,
            },
        ];

        for pos in positions {
            smoother.smooth(pos);
        }

        // Last smoothed position should have lane_index = 1 (mode)
        let last_pos = positions.last().unwrap();
        let smoothed = smoother.smooth(*last_pos);
        assert_eq!(smoothed.lane_index, 1);
    }

    #[test]
    fn test_smoother_median_for_offset() {
        let mut smoother = LanePositionSmoother::new(5);

        // Feed offsets with outlier: [-0.1, -0.05, 0.0, 0.05, 2.0 (outlier)]
        let offsets = vec![-0.1, -0.05, 0.0, 0.05, 2.0];

        for (i, offset) in offsets.iter().enumerate() {
            let pos = VehiclePosition {
                lane_index: 1,
                lateral_offset: *offset,
                confidence: 0.8,
                timestamp: i as f64 * 0.033,
            };
            smoother.smooth(pos);
        }

        let last_pos = VehiclePosition {
            lane_index: 1,
            lateral_offset: 2.0,
            confidence: 0.8,
            timestamp: 0.165,
        };
        let smoothed = smoother.smooth(last_pos);

        // Median should be 0.0 (middle value), not affected by 2.0 outlier
        assert_eq!(smoothed.lateral_offset, 0.0);
    }
}
// src/frame_buffer.rs

use crate::types::{Frame, LaneChangeEvent};
use base64::{engine::general_purpose::STANDARD, Engine as _};
use serde::{Deserialize, Serialize};
use std::collections::VecDeque;
use std::path::Path;
use tracing::{error, info};

/// Buffer to capture frames during a lane change event with pre-buffering
pub struct LaneChangeFrameBuffer {
    frames: Vec<Frame>,
    max_frames: usize,
    is_capturing: bool,
    capture_start_frame_id: Option<u64>,
    /// Pre-buffer: keeps last N frames before lane change starts
    pre_buffer: VecDeque<Frame>,
    pre_buffer_size: usize,
}

impl LaneChangeFrameBuffer {
    pub fn new(max_frames: usize) -> Self {
        // Pre-buffer holds frames BEFORE lane change starts (e.g., 20 frames)
        let pre_buffer_size = 20;

        Self {
            frames: Vec::with_capacity(max_frames),
            max_frames,
            is_capturing: false,
            capture_start_frame_id: None,
            pre_buffer: VecDeque::with_capacity(pre_buffer_size),
            pre_buffer_size,
        }
    }

    /// Add frame to pre-buffer (called continuously while in CENTERED state)
    pub fn add_to_pre_buffer(&mut self, frame: Frame) {
        self.pre_buffer.push_back(frame);
        if self.pre_buffer.len() > self.pre_buffer_size {
            self.pre_buffer.pop_front();
        }
    }

    pub fn start_capture(&mut self, frame_id: u64) {
        self.frames.clear();
        self.is_capturing = true;
        self.capture_start_frame_id = Some(frame_id);

        // Transfer pre-buffer frames to main buffer
        let pre_buffer_count = self.pre_buffer.len();
        for frame in self.pre_buffer.drain(..) {
            if self.frames.len() < self.max_frames {
                self.frames.push(frame);
            }
        }

        info!(
            " Started capturing at frame {} (included {} pre-buffered frames)",
            frame_id, pre_buffer_count
        );
    }

    pub fn add_frame(&mut self, frame: Frame) {
        if self.is_capturing && self.frames.len() < self.max_frames {
            self.frames.push(frame);
        }
    }

    pub fn stop_capture(&mut self) -> Vec<Frame> {
        self.is_capturing = false;
        self.capture_start_frame_id = None;
        let frames = std::mem::take(&mut self.frames);
        info!(" Stopped capturing. Total frames: {}", frames.len());
        frames
    }

    pub fn is_capturing(&self) -> bool {
        self.is_capturing
    }

    pub fn frame_count(&self) -> usize {
        self.frames.len()
    }

    pub fn cancel_capture(&mut self) {
        self.frames.clear();
        self.is_capturing = false;
        self.capture_start_frame_id = None;
    }

    pub fn pre_buffer_count(&self) -> usize {
        self.pre_buffer.len()
    }
}

// ============================================================================
// ENHANCED API STRUCTURES WITH DETECTION METADATA
// ============================================================================

/// Detection quality metadata to help AI make better decisions
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DetectionMetadata {
    /// Confidence of the lane change detection (0.0-1.0)
    pub detection_confidence: f32,
    /// Maximum lateral offset reached during maneuver (normalized, 0.0-1.0)
    pub max_offset_normalized: f32,
    /// Average lane detection confidence across frames (0.0-1.0)
    pub avg_lane_confidence: f32,
    /// Percentage of frames where both lanes were detected (0.0-1.0)
    pub both_lanes_ratio: f32,
    /// Video resolution (e.g., "1280x720")
    pub video_resolution: String,
    /// Frames per second
    pub fps: f32,
    /// Country/region for traffic rules (e.g., "PE" for Peru)
    pub region: String,
    /// Average lane width in pixels during the maneuver
    pub avg_lane_width_px: Option<f32>,
}

/// Enhanced payload for the legality analysis API
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LaneChangeLegalityRequest {
    pub event_id: String,
    pub direction: String,
    pub start_frame_id: u64,
    pub end_frame_id: u64,
    pub video_timestamp_ms: f64,
    pub duration_ms: Option<f64>,
    pub source_id: String,
    pub frames: Vec<FrameData>,
    /// NEW: Detection quality metadata
    pub detection_metadata: DetectionMetadata,
}

/// Enhanced frame data with per-frame metadata
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct FrameData {
    pub frame_index: usize,
    pub timestamp_ms: f64,
    pub width: usize,
    pub height: usize,
    pub base64_image: String,
    /// NEW: Lane detection confidence for this frame (if available)
    #[serde(skip_serializing_if = "Option::is_none")]
    pub lane_confidence: Option<f32>,
    /// NEW: Lateral offset as percentage of lane width (if available)
    #[serde(skip_serializing_if = "Option::is_none")]
    pub offset_percentage: Option<f32>,
}

/// Response from the legality API
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LaneChangeLegalityResponse {
    pub event_id: String,
    pub status: String,
    pub message: String,
}

// ============================================================================
// HELPER FUNCTIONS
// ============================================================================

/// Extract key frames emphasizing CONTEXT and PROGRESSION
pub fn extract_key_frames_for_lane_change(frames: &[Frame], count: usize) -> Vec<&Frame> {
    if frames.is_empty() || count == 0 {
        return vec![];
    }

    if frames.len() <= count {
        return frames.iter().collect();
    }

    let mut selected_indices = Vec::with_capacity(count);

    // Strategy: Include frames from BEFORE, DURING, and AFTER the maneuver
    // This gives the AI context about what was "normal" before the change

    match count {
        5 => {
            // Frame 0: Start (should be from pre-buffer, BEFORE maneuver)
            // Frame 1: Early (25%)
            // Frame 2: Middle (50%)
            // Frame 3: Late (75%)
            // Frame 4: End (100%)
            selected_indices.push(0);
            selected_indices.push(frames.len() / 4);
            selected_indices.push(frames.len() / 2);
            selected_indices.push((frames.len() * 3) / 4);
            selected_indices.push(frames.len() - 1);
        }
        7 => {
            // More granular: every ~16%
            selected_indices.push(0); // 0%
            selected_indices.push(frames.len() / 6); // 16%
            selected_indices.push(frames.len() / 3); // 33%
            selected_indices.push(frames.len() / 2); // 50%
            selected_indices.push((frames.len() * 2) / 3); // 66%
            selected_indices.push((frames.len() * 5) / 6); // 83%
            selected_indices.push(frames.len() - 1); // 100%
        }
        _ => {
            // Evenly distributed
            let step = (frames.len() - 1) as f32 / (count - 1) as f32;
            for i in 0..count {
                let index = (i as f32 * step).round() as usize;
                selected_indices.push(index.min(frames.len() - 1));
            }
        }
    }

    selected_indices.into_iter().map(|i| &frames[i]).collect()
}

/// Convert frame to base64 JPEG with quality optimization
pub fn frame_to_base64(frame: &Frame) -> Result<String, anyhow::Error> {
    use image::{codecs::jpeg::JpegEncoder, ImageBuffer, Rgb};
    use std::io::Cursor;

    let img: ImageBuffer<Rgb<u8>, Vec<u8>> =
        ImageBuffer::from_raw(frame.width as u32, frame.height as u32, frame.data.clone())
            .ok_or_else(|| anyhow::anyhow!("Failed to create image buffer"))?;

    let mut buffer = Cursor::new(Vec::new());

    // Use explicit JPEG encoder with quality setting
    let mut encoder = JpegEncoder::new_with_quality(&mut buffer, 85);
    encoder.encode(
        img.as_raw(),
        img.width(),
        img.height(),
        image::ExtendedColorType::Rgb8,
    )?;

    Ok(STANDARD.encode(buffer.into_inner()))
}

/// Build the API request payload with enhanced metadata
pub fn build_legality_request(
    event: &LaneChangeEvent,
    captured_frames: &[Frame],
    num_frames_to_send: usize,
) -> Result<LaneChangeLegalityRequest, anyhow::Error> {
    let key_frames = extract_key_frames_for_lane_change(captured_frames, num_frames_to_send);

    if key_frames.is_empty() {
        anyhow::bail!("No frames to send");
    }

    let mut frame_data_list = Vec::with_capacity(key_frames.len());

    // Log which frames were selected
    let selected_indices: Vec<usize> = key_frames
        .iter()
        .filter_map(|kf| captured_frames.iter().position(|f| std::ptr::eq(*kf, f)))
        .collect();

    info!(
        " Selected {} frames from {} total: indices {:?}",
        key_frames.len(),
        captured_frames.len(),
        selected_indices
    );

    // Process each frame
    for (i, frame) in key_frames.iter().enumerate() {
        let base64_image = frame_to_base64(frame)?;

        let lane_confidence = None;
        let offset_percentage = None;

        frame_data_list.push(FrameData {
            frame_index: i,
            timestamp_ms: frame.timestamp_ms,
            width: frame.width,
            height: frame.height,
            base64_image,
            lane_confidence,
            offset_percentage,
        });
    }

    // Calculate video metadata
    let video_resolution = format!(
        "{}x{}",
        key_frames.first().unwrap().width,
        key_frames.first().unwrap().height
    );

    // Calculate FPS from frame timestamps
    let fps = if key_frames.len() >= 2 {
        let time_span =
            key_frames.last().unwrap().timestamp_ms - key_frames.first().unwrap().timestamp_ms;
        if time_span > 0.0 {
            ((key_frames.len() - 1) as f64 / (time_span / 1000.0)) as f32
        } else {
            25.0
        }
    } else {
        25.0
    };

    let max_offset_normalized = event
        .metadata
        .get("max_offset_normalized")
        .and_then(|v| v.as_f64())
        .map(|v| v as f32)
        .unwrap_or(0.5);

    let both_lanes_ratio = event
        .metadata
        .get("both_lanes_ratio")
        .and_then(|v| v.as_f64())
        .map(|v| v as f32)
        .unwrap_or(0.7);

    let avg_lane_confidence = event
        .metadata
        .get("avg_lane_confidence")
        .and_then(|v| v.as_f64())
        .map(|v| v as f32)
        .unwrap_or(0.6);

    let avg_lane_width_px = event
        .metadata
        .get("avg_lane_width_px")
        .and_then(|v| v.as_f64())
        .map(|v| v as f32);

    let metadata = DetectionMetadata {
        detection_confidence: event.confidence,
        max_offset_normalized,
        avg_lane_confidence,
        both_lanes_ratio,
        video_resolution,
        fps,
        region: "PE".to_string(),
        avg_lane_width_px,
    };

    info!(
        " Detection quality: conf={:.1}%, max_offset={:.1}%, lanes={:.0}%",
        metadata.detection_confidence * 100.0,
        metadata.max_offset_normalized * 100.0,
        metadata.both_lanes_ratio * 100.0
    );

    Ok(LaneChangeLegalityRequest {
        event_id: event.event_id.clone(),
        direction: event.direction_name().to_string(),
        start_frame_id: event.start_frame_id,
        end_frame_id: event.end_frame_id,
        video_timestamp_ms: event.video_timestamp_ms,
        duration_ms: event.duration_ms,
        source_id: event.source_id.clone(),
        frames: frame_data_list,
        detection_metadata: metadata,
    })
}

/// Send the request to the legality analysis API
pub async fn send_to_legality_api(
    request: &LaneChangeLegalityRequest,
    api_url: &str,
) -> Result<LaneChangeLegalityResponse, anyhow::Error> {
    let client = reqwest::Client::builder()
        .timeout(std::time::Duration::from_secs(60))
        .build()?;

    info!(
        " Sending event {} to legality API at {}",
        request.event_id, api_url
    );

    let response = client.post(api_url).json(request).send().await;

    match response {
        Ok(resp) => {
            let status = resp.status();

            if !status.is_success() {
                let body = resp.text().await.unwrap_or_default();
                anyhow::bail!("API error {}: {}", status, body);
            }

            let result = resp.json::<LaneChangeLegalityResponse>().await?;

            info!(
                " API response for {}: {} - {}",
                result.event_id, result.status, result.message
            );

            Ok(result)
        }
        Err(e) => {
            error!(" Failed to connect to API: {}", e);
            anyhow::bail!("Failed to connect to API: {}", e)
        }
    }
}

/// Print the request payload to console with enhanced metadata
pub fn print_legality_request(request: &LaneChangeLegalityRequest) {
    println!("\n============================================================");
    println!(" LANE CHANGE LEGALITY CHECK REQUEST");
    println!("============================================================");
    println!("Event ID: {}", request.event_id);
    println!("Direction: {}", request.direction);
    println!(
        "Frames: {} -> {}",
        request.start_frame_id, request.end_frame_id
    );
    println!("Timestamp: {:.2}s", request.video_timestamp_ms / 1000.0);
    if let Some(duration) = request.duration_ms {
        println!("Duration: {:.0}ms", duration);
    }
    println!("Source: {}", request.source_id);

    println!("\n Detection Quality:");
    println!(
        "   Confidence:       {:.0}%",
        request.detection_metadata.detection_confidence * 100.0
    );
    println!(
        "   Max offset:       {:.0}%",
        request.detection_metadata.max_offset_normalized * 100.0
    );
    println!(
        "   Lane confidence:  {:.0}%",
        request.detection_metadata.avg_lane_confidence * 100.0
    );
    println!(
        "   Both lanes ratio: {:.0}%",
        request.detection_metadata.both_lanes_ratio * 100.0
    );
    println!(
        "   Resolution:       {}",
        request.detection_metadata.video_resolution
    );
    println!(
        "   FPS:              {:.1}",
        request.detection_metadata.fps
    );
    if let Some(width) = request.detection_metadata.avg_lane_width_px {
        println!("   Avg lane width:   {:.0}px", width);
    }

    println!("\n Frames for analysis: {}", request.frames.len());
    for frame_data in &request.frames {
        print!(
            "  Frame {}: {}x{} @ {:.2}s | base64: {} chars",
            frame_data.frame_index,
            frame_data.width,
            frame_data.height,
            frame_data.timestamp_ms / 1000.0,
            frame_data.base64_image.len()
        );
        if let Some(conf) = frame_data.lane_confidence {
            print!(" | lane_conf: {:.0}%", conf * 100.0);
        }
        if let Some(offset) = frame_data.offset_percentage {
            print!(" | offset: {:.0}%", offset * 100.0);
        }
        println!();
    }
    println!("============================================================\n");
}

/// Save the request to a JSON file
pub fn save_legality_request_to_file(
    request: &LaneChangeLegalityRequest,
    output_dir: &str,
) -> Result<std::path::PathBuf, anyhow::Error> {
    let dir = Path::new(output_dir).join("legality_requests");
    std::fs::create_dir_all(&dir)?;

    let filename = format!("{}_legality_request.json", request.event_id);
    let filepath = dir.join(&filename);

    let json = serde_json::to_string_pretty(request)?;
    std::fs::write(&filepath, json)?;

    info!(" Saved legality request to: {}", filepath.display());
    Ok(filepath)
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_extract_key_frames_for_lane_change() {
        let frames: Vec<Frame> = (0..10)
            .map(|i| Frame {
                data: vec![],
                width: 1280,
                height: 720,
                timestamp_ms: i as f64 * 100.0,
            })
            .collect();
        let key_frames = extract_key_frames_for_lane_change(&frames, 5);
        assert_eq!(key_frames.len(), 5);

        assert_eq!(key_frames[0].timestamp_ms, 0.0);
        assert_eq!(key_frames[4].timestamp_ms, 900.0);
    }
}
// src/types.rs

use serde::{Deserialize, Serialize};
use std::collections::HashMap;

// ============================================================================
// Configuration Structs
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Config {
    pub model: ModelConfig,
    pub inference: InferenceConfig,
    pub detection: DetectionConfig,
    pub video: VideoConfig,
    pub logging: LoggingConfig,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelConfig {
    pub path: String,
    pub input_width: usize,
    pub input_height: usize,
    pub num_anchors: usize,
    pub num_lanes: usize,
    pub griding_num: usize,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct InferenceConfig {
    pub use_tensorrt: bool,
    pub use_fp16: bool,
    pub enable_engine_cache: bool,
    pub engine_cache_path: String,
    pub num_threads: usize,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DetectionConfig {
    pub confidence_threshold: f32,
    pub min_points_per_lane: usize,
    pub smoother_window_size: usize,
    pub calibration_frames: usize,
    pub debounce_frames: u32,
    pub confirm_frames: u32,
    pub min_lane_confidence: f32,
    pub min_position_confidence: f32,
    #[serde(default = "default_drift_threshold")]
    pub drift_threshold: f32,
    #[serde(default = "default_crossing_threshold")]
    pub crossing_threshold: f32,
    #[serde(default = "default_cooldown_frames")]
    pub cooldown_frames: u32,
    #[serde(default = "default_min_duration")]
    pub min_lane_change_duration_ms: f64,
    #[serde(default = "default_max_duration")]
    pub max_lane_change_duration_ms: f64,
    #[serde(default = "default_skip_initial")]
    pub skip_initial_frames: u64,
    #[serde(default = "default_require_both_lanes")]
    pub require_both_lanes: bool,
}

fn default_drift_threshold() -> f32 {
    0.30
}
fn default_crossing_threshold() -> f32 {
    0.55
}
fn default_cooldown_frames() -> u32 {
    90
}
fn default_min_duration() -> f64 {
    1500.0
}
fn default_max_duration() -> f64 {
    5000.0
}
fn default_skip_initial() -> u64 {
    150
}
fn default_require_both_lanes() -> bool {
    true
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct VideoConfig {
    pub input_dir: String,
    pub output_dir: String,
    pub source_width: usize,
    pub source_height: usize,
    pub target_fps: u32,
    pub save_annotated: bool,
    pub save_events_only: bool,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LoggingConfig {
    pub level: String,
}

impl Config {
    pub fn load(path: &str) -> anyhow::Result<Self> {
        let contents = std::fs::read_to_string(path)?;
        let config: Config = serde_yaml::from_str(&contents)?;
        Ok(config)
    }
}

// ============================================================================
// Frame Type
// ============================================================================

#[derive(Debug, Clone)]
pub struct Frame {
    pub data: Vec<u8>,
    pub width: usize,
    pub height: usize,
    pub timestamp_ms: f64,
}

// ============================================================================
// Lane Detection Types
// ============================================================================

#[derive(Debug, Clone)]
pub struct DetectedLane {
    pub points: Vec<(f32, f32)>,
    pub confidence: f32,
}

// ============================================================================
// Analysis Types
// ============================================================================

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub enum LaneChangeState {
    Centered,
    Drifting,
    Crossing,
    Completed,
}

impl LaneChangeState {
    pub fn as_str(&self) -> &'static str {
        match self {
            LaneChangeState::Centered => "CENTERED",
            LaneChangeState::Drifting => "DRIFTING",
            LaneChangeState::Crossing => "CROSSING",
            LaneChangeState::Completed => "COMPLETED",
        }
    }
}

impl std::fmt::Display for LaneChangeState {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", self.as_str())
    }
}

#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub struct Point {
    pub x: f32,
    pub y: f32,
}

impl Point {
    pub fn new(x: f32, y: f32) -> Self {
        Self { x, y }
    }

    pub fn distance_to(&self, other: &Point) -> f32 {
        ((self.x - other.x).powi(2) + (self.y - other.y).powi(2)).sqrt()
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum LanePosition {
    LeftFar,
    LeftNear,
    RightNear,
    RightFar,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct Lane {
    pub lane_id: usize,
    pub points: Vec<Point>,
    pub confidence: f32,
    pub position: Option<LanePosition>,
}

impl Lane {
    pub fn from_detected(lane_id: usize, detected: &DetectedLane) -> Self {
        Self {
            lane_id,
            points: detected
                .points
                .iter()
                .map(|p| Point::new(p.0, p.1))
                .collect(),
            confidence: detected.confidence,
            position: None,
        }
    }

    pub fn get_x_at_y(&self, target_y: f32) -> Option<f32> {
        if self.points.len() < 2 {
            return None;
        }

        let mut sorted_points = self.points.clone();
        sorted_points.sort_by(|a, b| a.y.partial_cmp(&b.y).unwrap_or(std::cmp::Ordering::Equal));

        for i in 0..sorted_points.len() - 1 {
            let p1 = &sorted_points[i];
            let p2 = &sorted_points[i + 1];

            if p1.y <= target_y && target_y <= p2.y {
                if (p2.y - p1.y).abs() < 1e-6 {
                    return Some(p1.x);
                }
                let ratio = (target_y - p1.y) / (p2.y - p1.y);
                return Some(p1.x + ratio * (p2.x - p1.x));
            }
        }
        None
    }

    pub fn avg_x(&self) -> f32 {
        if self.points.is_empty() {
            return 0.0;
        }
        self.points.iter().map(|p| p.x).sum::<f32>() / self.points.len() as f32
    }

    pub fn bottom_point(&self) -> Option<&Point> {
        self.points
            .iter()
            .max_by(|a, b| a.y.partial_cmp(&b.y).unwrap_or(std::cmp::Ordering::Equal))
    }
}

// ============================================================================
// Vehicle State
// ============================================================================

#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub struct VehicleState {
    pub lateral_offset: f32,
    pub lane_width: Option<f32>,
    pub heading_offset: f32,
    pub frame_id: u64,
    pub timestamp_ms: f64,
    pub raw_offset: f32,
    pub detection_confidence: f32,
    pub both_lanes_detected: bool,
}

impl VehicleState {
    pub fn invalid() -> Self {
        Self {
            lateral_offset: 0.0,
            lane_width: None,
            heading_offset: 0.0,
            frame_id: 0,
            timestamp_ms: 0.0,
            raw_offset: 0.0,
            detection_confidence: 0.0,
            both_lanes_detected: false,
        }
    }

    pub fn normalized_offset(&self) -> Option<f32> {
        match self.lane_width {
            Some(width) if width > 1.0 => Some(self.lateral_offset / width),
            _ => None,
        }
    }

    pub fn is_valid(&self) -> bool {
        self.lane_width.map_or(false, |w| w > 50.0)
    }
}

// ============================================================================
// Direction
// ============================================================================

#[derive(Debug, Clone, Copy, PartialEq, Eq, Serialize, Deserialize)]
pub enum Direction {
    Left = -1,
    Unknown = 0,
    Right = 1,
}

impl Direction {
    pub fn from_offset(offset: f32) -> Self {
        if offset > 0.0 {
            Direction::Right
        } else if offset < 0.0 {
            Direction::Left
        } else {
            Direction::Unknown
        }
    }

    pub fn as_str(&self) -> &'static str {
        match self {
            Direction::Left => "LEFT",
            Direction::Right => "RIGHT",
            Direction::Unknown => "UNKNOWN",
        }
    }

    pub fn as_i32(&self) -> i32 {
        match self {
            Direction::Left => -1,
            Direction::Right => 1,
            Direction::Unknown => 0,
        }
    }
}

impl std::fmt::Display for Direction {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        write!(f, "{}", self.as_str())
    }
}

// ============================================================================
// Evidence Paths
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct EvidencePaths {
    pub start_image_path: String,
    pub end_image_path: String,
}

// ============================================================================
// Lane Change Event
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LaneChangeEvent {
    pub event_id: String,
    pub timestamp: String,
    pub video_timestamp_ms: f64,
    pub start_frame_id: u64,
    pub end_frame_id: u64,
    pub direction: Direction,
    pub confidence: f32,
    pub duration_ms: Option<f64>,
    pub source_id: String,
    pub evidence_images: Option<EvidencePaths>,
    pub metadata: HashMap<String, serde_json::Value>,
    #[serde(skip_serializing_if = "Option::is_none")]
    pub legality: Option<LegalityInfo>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LegalityInfo {
    pub is_legal: bool,
    pub lane_line_type: String,
    pub confidence: f32,
    pub analysis_details: Option<String>,
}

impl LaneChangeEvent {
    pub fn new(
        video_timestamp_ms: f64,
        start_frame_id: u64,
        end_frame_id: u64,
        direction: Direction,
        confidence: f32,
    ) -> Self {
        Self {
            event_id: uuid::Uuid::new_v4().to_string(),
            timestamp: chrono::Utc::now().to_rfc3339(),
            video_timestamp_ms,
            start_frame_id,
            end_frame_id,
            direction,
            confidence,
            duration_ms: None,
            source_id: String::new(),
            evidence_images: None,
            metadata: HashMap::new(),
            legality: None,
        }
    }

    pub fn direction_name(&self) -> &'static str {
        self.direction.as_str()
    }

    pub fn to_json(&self) -> serde_json::Value {
        serde_json::json!({
            "event_id": self.event_id,
            "type": "lane_change",
            "direction": self.direction_name(),
            "timestamp_ms": self.video_timestamp_ms,
            "frames": {
                "start": self.start_frame_id,
                "end": self.end_frame_id
            },
            "evidence": self.evidence_images,
            "duration_ms": self.duration_ms,
            "source_id": self.source_id,
            "metadata": self.metadata,
            "legality": self.legality,
        })
    }
}

// ============================================================================
// Lane Change Config
// ============================================================================

#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LaneChangeConfig {
    pub drift_threshold: f32,
    pub crossing_threshold: f32,
    pub min_frames_confirm: u32,
    pub cooldown_frames: u32,
    pub smoothing_alpha: f32,
    pub reference_y_ratio: f32,
    pub hysteresis_factor: f32,
    pub min_duration_ms: f64,
    pub max_duration_ms: f64,
    pub skip_initial_frames: u64,
    pub require_both_lanes: bool,
}

impl Default for LaneChangeConfig {
    fn default() -> Self {
        Self {
            drift_threshold: 0.30,
            crossing_threshold: 0.55,
            min_frames_confirm: 12,
            cooldown_frames: 90,
            smoothing_alpha: 0.3,
            reference_y_ratio: 0.8,
            hysteresis_factor: 0.5,
            min_duration_ms: 1500.0,
            max_duration_ms: 5000.0,
            skip_initial_frames: 150,
            require_both_lanes: true,
        }
    }
}

impl LaneChangeConfig {
    pub fn from_detection_config(detection: &DetectionConfig) -> Self {
        Self {
            drift_threshold: detection.drift_threshold,
            crossing_threshold: detection.crossing_threshold,
            min_frames_confirm: detection.confirm_frames,
            cooldown_frames: detection.cooldown_frames,
            smoothing_alpha: 0.3,
            reference_y_ratio: 0.8,
            hysteresis_factor: 0.5,
            min_duration_ms: detection.min_lane_change_duration_ms,
            max_duration_ms: detection.max_lane_change_duration_ms,
            skip_initial_frames: detection.skip_initial_frames,
            require_both_lanes: detection.require_both_lanes,
        }
    }
}
// src/video_processor.rs

use crate::types::{Config, DetectedLane, VehicleState};
use anyhow::Result;
use opencv::{
    core::{self, Mat, Vector},
    imgcodecs, imgproc,
    prelude::*,
    videoio::{self, VideoCapture, VideoCaptureTraitConst, VideoWriter},
};
use std::path::{Path, PathBuf};
use tracing::info;
use walkdir::WalkDir;

pub struct VideoProcessor {
    config: Config,
}

impl VideoProcessor {
    pub fn new(config: Config) -> Self {
        Self { config }
    }

    pub fn find_video_files(&self) -> Result<Vec<PathBuf>> {
        let mut videos = Vec::new();
        let video_extensions = vec!["mp4", "avi", "mov", "mkv", "MP4", "AVI", "MOV", "MKV"];

        for entry in WalkDir::new(&self.config.video.input_dir)
            .follow_links(true)
            .into_iter()
            .filter_map(|e| e.ok())
        {
            let path = entry.path();
            if let Some(ext) = path.extension() {
                if video_extensions.contains(&ext.to_str().unwrap_or("")) {
                    videos.push(path.to_path_buf());
                }
            }
        }
        info!("Found {} video files", videos.len());
        Ok(videos)
    }

    pub fn open_video(&self, path: &Path) -> Result<VideoReader> {
        info!("Opening video: {}", path.display());
        let cap = VideoCapture::from_file(path.to_str().unwrap(), videoio::CAP_ANY)?;

        if !cap.is_opened()? {
            anyhow::bail!("Failed to open video file");
        }

        let fps = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FPS)?;
        let total_frames = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FRAME_COUNT)? as i32;
        let width = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FRAME_WIDTH)? as i32;
        let height = VideoCaptureTraitConst::get(&cap, videoio::CAP_PROP_FRAME_HEIGHT)? as i32;

        Ok(VideoReader {
            cap,
            fps,
            total_frames,
            current_frame: 0,
            width,
            height,
        })
    }

    pub fn create_writer(
        &self,
        input_path: &Path,
        width: i32,
        height: i32,
        fps: f64,
    ) -> Result<Option<VideoWriter>> {
        if !self.config.video.save_annotated {
            return Ok(None);
        }
        std::fs::create_dir_all(&self.config.video.output_dir)?;
        let input_name = input_path.file_stem().unwrap().to_str().unwrap();
        let output_path = PathBuf::from(&self.config.video.output_dir)
            .join(format!("{}_annotated.mp4", input_name));

        let fourcc = VideoWriter::fourcc('m', 'p', '4', 'v')?;
        let writer = VideoWriter::new(
            output_path.to_str().unwrap(),
            fourcc,
            fps,
            core::Size::new(width, height),
            true,
        )?;
        Ok(Some(writer))
    }

    /// Save a specific frame as an image file
    pub fn save_frame_to_disk(
        &self,
        frame: &crate::types::Frame,
        filename: &str,
    ) -> Result<PathBuf> {
        let output_dir = Path::new(&self.config.video.output_dir).join("evidence");
        std::fs::create_dir_all(&output_dir)?;

        let file_path = output_dir.join(filename);

        // Frame data is RGB, OpenCV needs BGR
        let mat = Mat::from_slice(&frame.data)?;
        let mat = mat.reshape(3, frame.height as i32)?;

        let mut bgr_mat = Mat::default();
        imgproc::cvt_color(&mat, &mut bgr_mat, imgproc::COLOR_RGB2BGR, 0)?;

        // Use imgcodecs::imwrite
        let params = Vector::new();
        imgcodecs::imwrite(file_path.to_str().unwrap(), &bgr_mat, &params)?;

        Ok(file_path)
    }
}

pub struct VideoReader {
    pub cap: VideoCapture,
    pub fps: f64,
    pub total_frames: i32,
    pub current_frame: i32,
    pub width: i32,
    pub height: i32,
}

impl VideoReader {
    pub fn read_frame(&mut self) -> Result<Option<crate::types::Frame>> {
        use opencv::videoio::VideoCaptureTrait;
        let mut mat = Mat::default();
        if !VideoCaptureTrait::read(&mut self.cap, &mut mat)? || mat.empty() {
            return Ok(None);
        }
        self.current_frame += 1;
        let timestamp_ms = (self.current_frame as f64 / self.fps) * 1000.0;

        let mut rgb_mat = Mat::default();
        imgproc::cvt_color(&mat, &mut rgb_mat, imgproc::COLOR_BGR2RGB, 0)?;
        let data = rgb_mat.data_bytes()?.to_vec();

        Ok(Some(crate::types::Frame {
            data,
            width: self.width as usize,
            height: self.height as usize,
            timestamp_ms,
        }))
    }

    pub fn progress(&self) -> f32 {
        if self.total_frames == 0 {
            return 0.0;
        }
        (self.current_frame as f32 / self.total_frames as f32) * 100.0
    }
}

pub fn draw_lanes_with_state(
    frame: &[u8],
    width: i32,
    height: i32,
    lanes: &[DetectedLane],
    state: &str,
    vehicle_state: Option<&VehicleState>,
) -> Result<Mat> {
    let mat = Mat::from_slice(frame)?;
    let mat = mat.reshape(3, height)?;
    let mut bgr_mat = Mat::default();
    imgproc::cvt_color(&mat, &mut bgr_mat, imgproc::COLOR_RGB2BGR, 0)?;
    let mut output = bgr_mat.try_clone()?;

    let colors = vec![
        core::Scalar::new(0.0, 0.0, 255.0, 0.0),
        core::Scalar::new(0.0, 255.0, 0.0, 0.0),
        core::Scalar::new(255.0, 0.0, 0.0, 0.0),
        core::Scalar::new(0.0, 255.0, 255.0, 0.0),
    ];

    for (i, lane) in lanes.iter().enumerate() {
        let color = colors[i % colors.len()];
        for point in &lane.points {
            let pt = core::Point::new(point.0 as i32, point.1 as i32);
            imgproc::circle(&mut output, pt, 3, color, -1, imgproc::LINE_8, 0)?;
        }
    }

    let vehicle_x = width / 2;
    let vehicle_y = (height as f32 * 0.85) as i32;
    imgproc::circle(
        &mut output,
        core::Point::new(vehicle_x, vehicle_y),
        10,
        core::Scalar::new(0.0, 255.0, 255.0, 0.0),
        -1,
        imgproc::LINE_8,
        0,
    )?;

    imgproc::put_text(
        &mut output,
        &format!("State: {}", state),
        core::Point::new(15, 32),
        imgproc::FONT_HERSHEY_SIMPLEX,
        0.8,
        core::Scalar::new(0.0, 255.0, 0.0, 0.0),
        2,
        imgproc::LINE_8,
        false,
    )?;

    if let Some(vs) = vehicle_state {
        if vs.is_valid() {
            let normalized = vs.normalized_offset().unwrap_or(0.0);
            let info = format!(
                "Offset: {:.1}px ({:+.1}%)",
                vs.lateral_offset,
                normalized * 100.0
            );
            imgproc::put_text(
                &mut output,
                &info,
                core::Point::new(200, 32),
                imgproc::FONT_HERSHEY_SIMPLEX,
                0.5,
                core::Scalar::new(255.0, 255.0, 255.0, 0.0),
                1,
                imgproc::LINE_8,
                false,
            )?;
        }
    }

    Ok(output)
}
// src/analysis/state_machine.rs
//
// LANE CHANGE DETECTION v2.3
//
// Features:
// - Kalman filter for position smoothing
// - EWMA adaptive baseline (STICKY - slow adaptation)
// - Early baseline freeze when potential lane change detected
// - 8 detection paths including VELOCITY SPIKE for zigzags
// - Tracks max offset during pending phase
//

use super::boundary_detector::CrossingType;
use super::curve_detector::CurveDetector;
use super::velocity_tracker::LateralVelocityTracker;
use crate::types::{Direction, LaneChangeConfig, LaneChangeEvent, LaneChangeState, VehicleState};
use std::collections::VecDeque;
use tracing::{debug, info, warn};

// ============================================================================
// CONSTANTS
// ============================================================================

const MIN_VELOCITY_FAST: f32 = 120.0;
const MIN_VELOCITY_MEDIUM: f32 = 60.0;
const MIN_VELOCITY_SLOW: f32 = 20.0;
const TLC_WARNING_THRESHOLD: f64 = 1.5;
const ANALYSIS_WINDOW_MS: f64 = 4000.0;

const DEVIATION_DRIFT_START: f32 = 0.20;
const DEVIATION_CROSSING: f32 = 0.30;
const DEVIATION_LANE_CENTER: f32 = 0.50;
const DEVIATION_SIGNIFICANT: f32 = 0.40;

const HYSTERESIS_EXIT: f32 = 0.6;
const DIRECTION_CONSISTENCY_THRESHOLD: f32 = 0.65;
const POST_CHANGE_GRACE_FRAMES: u32 = 90;

// Kalman filter
const KALMAN_PROCESS_NOISE: f32 = 0.001;
const KALMAN_MEASUREMENT_NOISE: f32 = 0.01;

//  STICKY EWMA baseline - much slower adaptation!
const EWMA_ALPHA_STABLE: f32 = 0.003; // Was 0.02  6x slower
const EWMA_ALPHA_ADAPTING: f32 = 0.015; // Was 0.08  5x slower
const EWMA_MIN_SAMPLES: u32 = 30;
const STABILITY_VARIANCE_THRESHOLD: f32 = 0.005;
const INSTABILITY_VARIANCE_THRESHOLD: f32 = 0.05;

const CURVE_COMPENSATION_FACTOR: f32 = 1.15;
const MAX_DRIFTING_MS: f64 = 8000.0;

//  Velocity spike detection thresholds
const VELOCITY_SPIKE_THRESHOLD: f32 = 180.0; // Very high velocity
const POSITION_CHANGE_THRESHOLD: f32 = 0.15; // 15% position swing

// ============================================================================
// KALMAN FILTER
// ============================================================================

#[derive(Clone)]
struct SimpleKalmanFilter {
    x: f32,
    p: f32,
    q: f32,
    r: f32,
    initialized: bool,
}

impl SimpleKalmanFilter {
    fn new() -> Self {
        Self {
            x: 0.0,
            p: 1.0,
            q: KALMAN_PROCESS_NOISE,
            r: KALMAN_MEASUREMENT_NOISE,
            initialized: false,
        }
    }

    fn update(&mut self, measurement: f32) -> f32 {
        if !self.initialized {
            self.x = measurement;
            self.p = self.r;
            self.initialized = true;
            return measurement;
        }
        let p_pred = self.p + self.q;
        let k = p_pred / (p_pred + self.r);
        self.x = self.x + k * (measurement - self.x);
        self.p = (1.0 - k) * p_pred;
        self.x
    }

    fn reset(&mut self) {
        self.x = 0.0;
        self.p = 1.0;
        self.initialized = false;
    }
}

// ============================================================================
// ADAPTIVE BASELINE (STICKY)
// ============================================================================

#[derive(Clone)]
struct AdaptiveBaseline {
    value: f32,
    variance: f32,
    sample_count: u32,
    is_valid: bool,
    recent_samples: VecDeque<f32>,
    is_adapting: bool,
    stable_frames: u32,
    is_frozen: bool,
    frozen_value: f32,
}

impl AdaptiveBaseline {
    fn new() -> Self {
        Self {
            value: 0.0,
            variance: 1.0,
            sample_count: 0,
            is_valid: false,
            recent_samples: VecDeque::with_capacity(30),
            is_adapting: true,
            stable_frames: 0,
            is_frozen: false,
            frozen_value: 0.0,
        }
    }

    fn freeze(&mut self) {
        if !self.is_frozen {
            self.is_frozen = true;
            self.frozen_value = self.value;
            info!(" Baseline frozen at {:.1}%", self.frozen_value * 100.0);
        }
    }

    fn unfreeze(&mut self) {
        if self.is_frozen {
            self.is_frozen = false;
            debug!(" Baseline unfrozen");
        }
    }

    fn effective_value(&self) -> f32 {
        if self.is_frozen {
            self.frozen_value
        } else {
            self.value
        }
    }

    fn update(&mut self, measurement: f32) -> f32 {
        self.sample_count += 1;

        self.recent_samples.push_back(measurement);
        if self.recent_samples.len() > 30 {
            self.recent_samples.pop_front();
        }

        if self.recent_samples.len() >= 10 {
            let samples: Vec<f32> = self.recent_samples.iter().copied().collect();
            let mean: f32 = samples.iter().sum::<f32>() / samples.len() as f32;
            self.variance =
                samples.iter().map(|x| (x - mean).powi(2)).sum::<f32>() / samples.len() as f32;
        }

        if self.is_frozen {
            return self.frozen_value;
        }

        let deviation_from_baseline = (measurement - self.value).abs();

        if self.variance < STABILITY_VARIANCE_THRESHOLD {
            self.stable_frames += 1;
            if self.stable_frames > 30 {
                self.is_adapting = false;
            }
        } else {
            self.stable_frames = 0;
            if deviation_from_baseline > 0.15 {
                self.is_adapting = true;
            }
        }

        let alpha = if self.is_adapting || !self.is_valid {
            EWMA_ALPHA_ADAPTING
        } else {
            EWMA_ALPHA_STABLE
        };

        if self.sample_count == 1 {
            self.value = measurement;
        } else {
            self.value = alpha * measurement + (1.0 - alpha) * self.value;
        }

        if self.sample_count >= EWMA_MIN_SAMPLES && self.variance < INSTABILITY_VARIANCE_THRESHOLD {
            self.is_valid = true;
        }

        self.value
    }

    fn reset(&mut self) {
        self.value = 0.0;
        self.variance = 1.0;
        self.sample_count = 0;
        self.is_valid = false;
        self.recent_samples.clear();
        self.is_adapting = true;
        self.stable_frames = 0;
        self.is_frozen = false;
        self.frozen_value = 0.0;
    }
}

// ============================================================================
// DATA STRUCTURES
// ============================================================================

#[derive(Clone, Copy, Debug)]
struct OffsetSample {
    normalized_offset: f32,
    deviation: f32,
    timestamp_ms: f64,
    lateral_velocity: f32,
    direction: Direction,
}

#[derive(Debug, Default)]
struct WindowMetrics {
    total_displacement: f32,
    max_deviation: f32,
    avg_velocity: f32,
    peak_velocity: f32,
    direction_consistency: f32,
    time_span_ms: f64,
    tlc_estimate: Option<f64>,
    is_intentional_change: bool,
    is_sustained_movement: bool,
}

#[derive(Debug, Clone, Copy, PartialEq)]
enum DetectionPath {
    BoundaryCrossing,
    HighVelocity,
    MediumDeviation,
    GradualChange,
    LargeDeviation,
    TLCBased,
    CumulativeDisplacement,
    VelocitySpike, //  NEW: For zigzags with high velocity but low baseline deviation
}

// ============================================================================
// MAIN STATE MACHINE
// ============================================================================

pub struct LaneChangeStateMachine {
    config: LaneChangeConfig,
    source_id: String,

    state: LaneChangeState,
    frames_in_state: u32,
    pending_state: Option<LaneChangeState>,
    pending_frames: u32,

    change_direction: Direction,
    change_start_frame: Option<u64>,
    change_start_time: Option<f64>,
    change_detection_path: Option<DetectionPath>,
    max_offset_in_change: f32,

    cooldown_remaining: u32,
    total_frames_processed: u64,
    post_lane_change_grace: u32,

    position_filter: SimpleKalmanFilter,
    adaptive_baseline: AdaptiveBaseline,

    offset_history: Vec<f32>,
    velocity_history: VecDeque<f32>,
    offset_samples: VecDeque<OffsetSample>,
    direction_samples: VecDeque<Direction>,
    recent_deviations: Vec<f32>,

    stable_deviation_frames: u32,
    last_deviation: f32,

    peak_deviation_in_window: f32,
    peak_velocity_in_window: f32,
    peak_direction: Direction,

    curve_detector: CurveDetector,
    velocity_tracker: LateralVelocityTracker,

    is_in_curve: bool,
    curve_compensation_factor: f32,

    pending_change_direction: Direction,
    pending_max_offset: f32,
}

impl LaneChangeStateMachine {
    pub fn new(config: LaneChangeConfig) -> Self {
        Self {
            config,
            source_id: String::new(),
            state: LaneChangeState::Centered,
            frames_in_state: 0,
            pending_state: None,
            pending_frames: 0,
            change_direction: Direction::Unknown,
            change_start_frame: None,
            change_start_time: None,
            change_detection_path: None,
            max_offset_in_change: 0.0,
            cooldown_remaining: 0,
            total_frames_processed: 0,
            post_lane_change_grace: 0,
            position_filter: SimpleKalmanFilter::new(),
            adaptive_baseline: AdaptiveBaseline::new(),
            offset_history: Vec::with_capacity(60),
            velocity_history: VecDeque::with_capacity(30),
            offset_samples: VecDeque::with_capacity(150),
            direction_samples: VecDeque::with_capacity(30),
            recent_deviations: Vec::with_capacity(30),
            stable_deviation_frames: 0,
            last_deviation: 0.0,
            peak_deviation_in_window: 0.0,
            peak_velocity_in_window: 0.0,
            peak_direction: Direction::Unknown,
            curve_detector: CurveDetector::new(),
            velocity_tracker: LateralVelocityTracker::new(),
            is_in_curve: false,
            curve_compensation_factor: 1.0,
            pending_change_direction: Direction::Unknown,
            pending_max_offset: 0.0,
        }
    }

    pub fn current_state(&self) -> &str {
        self.state.as_str()
    }

    pub fn update_curve_detector(&mut self, lanes: &[crate::types::Lane]) -> bool {
        self.is_in_curve = self.curve_detector.is_in_curve(lanes);
        self.curve_compensation_factor = if self.is_in_curve {
            CURVE_COMPENSATION_FACTOR
        } else {
            1.0
        };
        self.is_in_curve
    }

    pub fn update(
        &mut self,
        vehicle_state: &VehicleState,
        frame_id: u64,
        timestamp_ms: f64,
        crossing_type: CrossingType,
    ) -> Option<LaneChangeEvent> {
        self.total_frames_processed += 1;

        if self.total_frames_processed < self.config.skip_initial_frames {
            return None;
        }

        if self.cooldown_remaining > 0 {
            self.cooldown_remaining -= 1;
            if self.cooldown_remaining == 0 {
                self.state = LaneChangeState::Centered;
                self.frames_in_state = 0;
            }
            return None;
        }

        if self.post_lane_change_grace > 0 {
            self.post_lane_change_grace -= 1;
        }

        // Timeout handling
        if self.state == LaneChangeState::Drifting {
            if let Some(start_time) = self.change_start_time {
                let elapsed = timestamp_ms - start_time;

                if elapsed > MAX_DRIFTING_MS {
                    if self.max_offset_in_change >= self.config.crossing_threshold {
                        info!(
                            " Long DRIFTING ({:.0}ms) with good offset ({:.1}%) - auto-completing",
                            elapsed,
                            self.max_offset_in_change * 100.0
                        );
                        return self.force_complete(frame_id, timestamp_ms);
                    }
                }

                if elapsed > self.config.max_duration_ms {
                    if self.max_offset_in_change >= self.config.crossing_threshold {
                        info!(" Timeout but good offset - completing");
                        return self.force_complete(frame_id, timestamp_ms);
                    }
                    warn!(
                        " Timeout after {:.0}ms with max={:.1}%",
                        elapsed,
                        self.max_offset_in_change * 100.0
                    );
                    self.adaptive_baseline.unfreeze();
                    self.reset_lane_change();
                    self.cooldown_remaining = 30;
                    return None;
                }
            }
        }

        if self.state == LaneChangeState::Crossing {
            if let Some(start_time) = self.change_start_time {
                let elapsed = timestamp_ms - start_time;
                if elapsed > self.config.max_duration_ms {
                    info!(" Timeout in CROSSING - completing anyway");
                    return self.force_complete(frame_id, timestamp_ms);
                }
            }
        }

        if !vehicle_state.is_valid() {
            return None;
        }

        let lane_width = vehicle_state.lane_width.unwrap();
        let raw_offset = vehicle_state.lateral_offset / lane_width;
        let normalized_offset = self.position_filter.update(raw_offset);

        let lateral_velocity = self
            .velocity_tracker
            .get_velocity(vehicle_state.lateral_offset, timestamp_ms);

        self.velocity_history.push_back(lateral_velocity);
        if self.velocity_history.len() > 30 {
            self.velocity_history.pop_front();
        }

        self.offset_history.push(normalized_offset);
        if self.offset_history.len() > 60 {
            self.offset_history.remove(0);
        }

        if self.post_lane_change_grace > 0 {
            self.adaptive_baseline.update(normalized_offset);
            return None;
        }

        self.adaptive_baseline.update(normalized_offset);

        if !self.adaptive_baseline.is_valid {
            if self.adaptive_baseline.sample_count % 30 == 0 {
                debug!(
                    "Baseline forming: {:.1}%",
                    self.adaptive_baseline.value * 100.0
                );
            }
            return None;
        }

        if self.adaptive_baseline.sample_count == EWMA_MIN_SAMPLES {
            info!(
                " Adaptive baseline ready: {:.1}% at frame {} ({:.1}s)",
                self.adaptive_baseline.value * 100.0,
                frame_id,
                timestamp_ms / 1000.0
            );
        }

        let baseline = self.adaptive_baseline.effective_value();
        let signed_deviation = normalized_offset - baseline;
        let deviation = signed_deviation.abs();
        let current_direction = Direction::from_offset(signed_deviation);

        // Track max offset during pending and active phases
        if self.pending_state == Some(LaneChangeState::Drifting)
            || self.state == LaneChangeState::Drifting
            || self.state == LaneChangeState::Crossing
        {
            if deviation > self.max_offset_in_change {
                self.max_offset_in_change = deviation;
            }
            if deviation > self.pending_max_offset {
                self.pending_max_offset = deviation;
            }
        }

        self.recent_deviations.push(deviation);
        if self.recent_deviations.len() > 30 {
            self.recent_deviations.remove(0);
        }

        let sample = OffsetSample {
            normalized_offset,
            deviation,
            timestamp_ms,
            lateral_velocity,
            direction: current_direction,
        };
        self.offset_samples.push_back(sample);

        while let Some(oldest) = self.offset_samples.front() {
            if timestamp_ms - oldest.timestamp_ms > ANALYSIS_WINDOW_MS {
                self.offset_samples.pop_front();
            } else {
                break;
            }
        }

        self.direction_samples.push_back(current_direction);
        if self.direction_samples.len() > 30 {
            self.direction_samples.pop_front();
        }

        if deviation > self.peak_deviation_in_window {
            self.peak_deviation_in_window = deviation;
            self.peak_direction = current_direction;
        }
        if lateral_velocity.abs() > self.peak_velocity_in_window {
            self.peak_velocity_in_window = lateral_velocity.abs();
        }

        let window_metrics = self.calculate_window_metrics(timestamp_ms, lane_width);

        let target_state = self.determine_target_state(
            deviation,
            crossing_type,
            lateral_velocity,
            current_direction,
            &window_metrics,
        );

        //  Debug logging for zigzag investigation (around 202s = frame ~6060)
        if frame_id >= 6000 && frame_id <= 6150 {
            info!(
                " F{}: pos={:.1}%, base={:.1}%, dev={:.1}%, vel={:.1}px/s, swing={:.1}%",
                frame_id,
                normalized_offset * 100.0,
                baseline * 100.0,
                deviation * 100.0,
                lateral_velocity,
                self.get_recent_position_change() * 100.0
            );
        }

        debug!(
            "F{}: off={:.1}%, base={:.1}%{}, dev={:.1}%, max={:.1}%, state={:?}{:?}",
            frame_id,
            normalized_offset * 100.0,
            baseline * 100.0,
            if self.adaptive_baseline.is_frozen {
                ""
            } else {
                ""
            },
            deviation * 100.0,
            self.max_offset_in_change * 100.0,
            self.state,
            target_state
        );

        self.check_transition(
            target_state,
            current_direction,
            frame_id,
            timestamp_ms,
            deviation,
        )
    }

    fn force_complete(&mut self, frame_id: u64, timestamp_ms: f64) -> Option<LaneChangeEvent> {
        let start_frame = self.change_start_frame.unwrap_or(frame_id);
        let start_time = self.change_start_time.unwrap_or(timestamp_ms);
        let duration_ms = Some(timestamp_ms - start_time);
        let confidence = self.calculate_confidence(duration_ms);

        let mut event = LaneChangeEvent::new(
            start_time,
            start_frame,
            frame_id,
            self.change_direction,
            confidence,
        );
        event.duration_ms = duration_ms;
        event.source_id = self.source_id.clone();

        info!(
            " FORCE CONFIRMED: {} at {:.2}s, dur={:.0}ms, max={:.1}%, path={:?}",
            event.direction_name(),
            start_time / 1000.0,
            duration_ms.unwrap_or(0.0),
            self.max_offset_in_change * 100.0,
            self.change_detection_path
        );

        self.adaptive_baseline.reset();
        self.position_filter.reset();
        self.post_lane_change_grace = POST_CHANGE_GRACE_FRAMES;
        self.offset_samples.clear();
        self.cooldown_remaining = self.config.cooldown_frames;

        info!(" Baseline reset - will adapt to new position");
        self.reset_lane_change();

        Some(event)
    }

    ///  Get the total position change over recent frames (ignoring baseline)
    /// Used for detecting zigzags where baseline has adapted
    fn get_recent_position_change(&self) -> f32 {
        if self.offset_history.len() < 10 {
            return 0.0;
        }

        let recent = &self.offset_history[self.offset_history.len() - 10..];
        let first = recent[0];
        let last = recent[recent.len() - 1];

        // Also check max swing (for zigzags that return to center)
        let max = recent.iter().fold(f32::MIN, |a, &b| a.max(b));
        let min = recent.iter().fold(f32::MAX, |a, &b| a.min(b));
        let swing = max - min;

        // Return the larger of: end-to-end change or total swing
        (last - first).abs().max(swing)
    }

    fn calculate_window_metrics(&self, _current_time_ms: f64, lane_width: f32) -> WindowMetrics {
        let mut metrics = WindowMetrics::default();

        if self.offset_samples.len() < 10 {
            return metrics;
        }

        let first = self.offset_samples.front().unwrap();
        let last = self.offset_samples.back().unwrap();

        metrics.time_span_ms = last.timestamp_ms - first.timestamp_ms;
        if metrics.time_span_ms < 300.0 {
            return metrics;
        }

        metrics.total_displacement = (last.deviation - first.deviation).abs();
        metrics.max_deviation = self
            .offset_samples
            .iter()
            .map(|s| s.deviation)
            .fold(0.0f32, |a, b| a.max(b));

        let velocities: Vec<f32> = self
            .offset_samples
            .iter()
            .map(|s| s.lateral_velocity)
            .collect();
        metrics.avg_velocity = velocities.iter().sum::<f32>() / velocities.len() as f32;
        metrics.peak_velocity = velocities
            .iter()
            .map(|v| v.abs())
            .fold(0.0f32, |a, b| a.max(b));

        if !self.direction_samples.is_empty() {
            let target_dir = self.peak_direction;
            let consistent = self
                .direction_samples
                .iter()
                .filter(|&&d| d == target_dir)
                .count();
            metrics.direction_consistency = consistent as f32 / self.direction_samples.len() as f32;
        }

        if metrics.avg_velocity.abs() > 5.0 {
            let distance_to_boundary = (0.5 - last.deviation.abs()) * lane_width;
            if distance_to_boundary > 0.0 {
                metrics.tlc_estimate =
                    Some((distance_to_boundary / metrics.avg_velocity.abs()) as f64);
            }
        }

        metrics.is_sustained_movement = metrics.direction_consistency
            >= DIRECTION_CONSISTENCY_THRESHOLD
            && metrics.time_span_ms >= 1000.0;
        metrics.is_intentional_change = metrics.max_deviation >= DEVIATION_DRIFT_START
            && metrics.is_sustained_movement
            && (metrics.avg_velocity.abs() > MIN_VELOCITY_SLOW || metrics.time_span_ms >= 2000.0);

        metrics
    }

    fn determine_target_state(
        &mut self,
        deviation: f32,
        crossing_type: CrossingType,
        lateral_velocity: f32,
        current_direction: Direction,
        metrics: &WindowMetrics,
    ) -> LaneChangeState {
        let drift_threshold = self.config.drift_threshold * self.curve_compensation_factor;
        let crossing_threshold = self.config.crossing_threshold * self.curve_compensation_factor;

        let vel_fast = MIN_VELOCITY_FAST * self.curve_compensation_factor;
        let vel_medium = MIN_VELOCITY_MEDIUM * self.curve_compensation_factor;

        match self.state {
            LaneChangeState::Centered => {
                // PATH 1: BOUNDARY CROSSING
                if crossing_type != CrossingType::None && lateral_velocity.abs() > vel_fast {
                    if self.is_deviation_sustained(drift_threshold * 0.9) {
                        self.change_detection_path = Some(DetectionPath::BoundaryCrossing);
                        info!(
                            " [BOUNDARY] {:?}, vel={:.1}px/s",
                            crossing_type, lateral_velocity
                        );
                        return LaneChangeState::Drifting;
                    }
                }

                // PATH 2: HIGH VELOCITY + DEVIATION
                if lateral_velocity.abs() > vel_fast && deviation >= drift_threshold {
                    if self.is_velocity_sustained(vel_medium) {
                        self.change_detection_path = Some(DetectionPath::HighVelocity);
                        info!(
                            " [HIGH-VEL] vel={:.1}px/s, dev={:.1}%",
                            lateral_velocity,
                            deviation * 100.0
                        );
                        return LaneChangeState::Drifting;
                    }
                }

                //  PATH 8: VELOCITY SPIKE (for zigzags where baseline has adapted)
                // High velocity movement should trigger even if baseline deviation is low
                if lateral_velocity.abs() > VELOCITY_SPIKE_THRESHOLD {
                    if self.is_velocity_sustained(vel_fast) {
                        let position_change = self.get_recent_position_change();
                        if position_change >= POSITION_CHANGE_THRESHOLD {
                            self.change_detection_path = Some(DetectionPath::VelocitySpike);
                            info!(
                                " [VELOCITY-SPIKE] vel={:.1}px/s, pos_change={:.1}%, dev={:.1}%",
                                lateral_velocity,
                                position_change * 100.0,
                                deviation * 100.0
                            );
                            return LaneChangeState::Drifting;
                        }
                    }
                }

                // PATH 3: TLC-BASED
                if let Some(tlc) = metrics.tlc_estimate {
                    if tlc < TLC_WARNING_THRESHOLD
                        && deviation >= drift_threshold
                        && metrics.is_sustained_movement
                    {
                        self.change_detection_path = Some(DetectionPath::TLCBased);
                        info!(" [TLC] TLC={:.2}s, dev={:.1}%", tlc, deviation * 100.0);
                        return LaneChangeState::Drifting;
                    }
                }

                // PATH 4: MEDIUM SPEED + HIGH DEVIATION
                if deviation >= drift_threshold + 0.10 && lateral_velocity.abs() > vel_medium {
                    if self.is_deviation_sustained(drift_threshold) {
                        self.change_detection_path = Some(DetectionPath::MediumDeviation);
                        info!(
                            " [MEDIUM] dev={:.1}%, vel={:.1}px/s",
                            deviation * 100.0,
                            lateral_velocity
                        );
                        return LaneChangeState::Drifting;
                    }
                }

                // PATH 5: GRADUAL CHANGE
                if metrics.is_intentional_change && metrics.max_deviation >= DEVIATION_SIGNIFICANT {
                    if self.is_deviation_sustained_long(DEVIATION_DRIFT_START) {
                        self.change_detection_path = Some(DetectionPath::GradualChange);
                        info!(
                            " [GRADUAL] max={:.1}%, span={:.1}s",
                            metrics.max_deviation * 100.0,
                            metrics.time_span_ms / 1000.0
                        );
                        return LaneChangeState::Drifting;
                    }
                }

                // PATH 6: LARGE DEVIATION
                if deviation >= DEVIATION_LANE_CENTER {
                    if self.is_deviation_sustained(drift_threshold) {
                        self.change_detection_path = Some(DetectionPath::LargeDeviation);
                        info!(" [LARGE] dev={:.1}%", deviation * 100.0);
                        return LaneChangeState::Drifting;
                    }
                }

                // PATH 7: CUMULATIVE
                if metrics.max_deviation >= DEVIATION_SIGNIFICANT
                    && metrics.direction_consistency >= DIRECTION_CONSISTENCY_THRESHOLD
                    && metrics.time_span_ms >= 2500.0
                    && !self.is_in_curve
                {
                    self.change_detection_path = Some(DetectionPath::CumulativeDisplacement);
                    info!(
                        " [CUMULATIVE] max={:.1}%, span={:.1}s",
                        metrics.max_deviation * 100.0,
                        metrics.time_span_ms / 1000.0
                    );
                    return LaneChangeState::Drifting;
                }

                LaneChangeState::Centered
            }

            LaneChangeState::Drifting => {
                // Check for crossing threshold
                if deviation >= crossing_threshold {
                    return LaneChangeState::Crossing;
                }

                // Also check max_offset
                if self.max_offset_in_change >= crossing_threshold {
                    return LaneChangeState::Crossing;
                }

                // Check if we should complete based on sustained high deviation
                if self.frames_in_state > 30 && self.max_offset_in_change >= drift_threshold + 0.08
                {
                    if self.is_deviation_stable() {
                        info!(
                            " DRIFTING complete: stabilized with max={:.1}%",
                            self.max_offset_in_change * 100.0
                        );
                        return LaneChangeState::Completed;
                    }
                }

                // Cancellation check - only if max offset is very low
                let cancel_threshold = drift_threshold * 0.5;
                if deviation < cancel_threshold && self.max_offset_in_change < drift_threshold {
                    warn!(
                        " Cancelled: max={:.1}% < drift={:.1}%",
                        self.max_offset_in_change * 100.0,
                        drift_threshold * 100.0
                    );
                    return LaneChangeState::Centered;
                }

                LaneChangeState::Drifting
            }

            LaneChangeState::Crossing => {
                let deviation_change = (deviation - self.last_deviation).abs();
                if deviation_change < 0.03 {
                    self.stable_deviation_frames += 1;
                } else {
                    self.stable_deviation_frames = 0;
                }
                self.last_deviation = deviation;

                if self.is_deviation_stable() && deviation < 0.35 {
                    info!(" Completing: stabilized at {:.1}%", deviation * 100.0);
                    return LaneChangeState::Completed;
                }

                let return_threshold = self.config.drift_threshold * HYSTERESIS_EXIT;
                if deviation < return_threshold {
                    info!(" Completing: returned to center");
                    return LaneChangeState::Completed;
                }

                if self.stable_deviation_frames >= 30 && deviation < 0.45 {
                    info!(
                        " Completing: stable for {} frames",
                        self.stable_deviation_frames
                    );
                    return LaneChangeState::Completed;
                }

                if self.max_offset_in_change >= self.config.crossing_threshold
                    && current_direction != self.change_direction
                    && current_direction != Direction::Unknown
                {
                    let reversal_count = self
                        .direction_samples
                        .iter()
                        .rev()
                        .take(10)
                        .filter(|&&d| d != self.change_direction && d != Direction::Unknown)
                        .count();
                    if reversal_count >= 7 {
                        info!(" Completing: direction reversed");
                        return LaneChangeState::Completed;
                    }
                }

                LaneChangeState::Crossing
            }

            LaneChangeState::Completed => LaneChangeState::Centered,
        }
    }

    fn is_deviation_sustained(&self, threshold: f32) -> bool {
        if self.offset_history.len() < 8 {
            return false;
        }
        let baseline = self.adaptive_baseline.effective_value();
        self.offset_history
            .iter()
            .rev()
            .take(6)
            .filter(|o| (*o - baseline).abs() >= threshold)
            .count()
            >= 5
    }

    fn is_deviation_sustained_long(&self, threshold: f32) -> bool {
        if self.offset_history.len() < 20 {
            return false;
        }
        let baseline = self.adaptive_baseline.effective_value();
        self.offset_history
            .iter()
            .rev()
            .take(15)
            .filter(|o| (*o - baseline).abs() >= threshold)
            .count()
            >= 12
    }

    fn is_velocity_sustained(&self, threshold: f32) -> bool {
        if self.velocity_history.len() < 5 {
            return false;
        }
        self.velocity_history
            .iter()
            .rev()
            .take(5)
            .filter(|v| v.abs() >= threshold)
            .count()
            >= 4
    }

    fn is_deviation_stable(&self) -> bool {
        if self.recent_deviations.len() < 15 {
            return false;
        }
        let recent = &self.recent_deviations[self.recent_deviations.len() - 15..];
        let max = recent.iter().fold(f32::MIN, |a, &b| a.max(b));
        let min = recent.iter().fold(f32::MAX, |a, &b| a.min(b));
        if max - min > 0.08 {
            return false;
        }
        recent
            .windows(2)
            .filter(|w| (w[1] - w[0]).abs() > 0.03)
            .count()
            <= 2
    }

    fn reset_lane_change(&mut self) {
        self.state = LaneChangeState::Centered;
        self.frames_in_state = 0;
        self.pending_state = None;
        self.pending_frames = 0;
        self.change_direction = Direction::Unknown;
        self.change_start_frame = None;
        self.change_start_time = None;
        self.change_detection_path = None;
        self.max_offset_in_change = 0.0;
        self.stable_deviation_frames = 0;
        self.last_deviation = 0.0;
        self.recent_deviations.clear();
        self.peak_deviation_in_window = 0.0;
        self.peak_velocity_in_window = 0.0;
        self.peak_direction = Direction::Unknown;
        self.pending_change_direction = Direction::Unknown;
        self.pending_max_offset = 0.0;
    }

    fn check_transition(
        &mut self,
        target_state: LaneChangeState,
        direction: Direction,
        frame_id: u64,
        timestamp_ms: f64,
        current_deviation: f32,
    ) -> Option<LaneChangeEvent> {
        if target_state == self.state {
            self.pending_state = None;
            self.pending_frames = 0;
            self.frames_in_state += 1;
            return None;
        }

        // Freeze baseline immediately when we first detect potential lane change
        if target_state == LaneChangeState::Drifting && self.state == LaneChangeState::Centered {
            if self.pending_state != Some(LaneChangeState::Drifting) {
                self.adaptive_baseline.freeze();
                self.pending_change_direction = direction;
                self.pending_max_offset = current_deviation;
                info!(
                    " Early freeze: baseline at {:.1}%, initial dev={:.1}%",
                    self.adaptive_baseline.effective_value() * 100.0,
                    current_deviation * 100.0
                );
            }
        }

        if self.pending_state == Some(target_state) {
            self.pending_frames += 1;
        } else {
            self.pending_state = Some(target_state);
            self.pending_frames = 1;
        }

        // Unfreeze if we're NOT going to transition after all
        if target_state != LaneChangeState::Drifting
            && self.adaptive_baseline.is_frozen
            && self.state == LaneChangeState::Centered
            && self.pending_frames < self.config.min_frames_confirm
        {
            self.adaptive_baseline.unfreeze();
            self.pending_max_offset = 0.0;
        }

        if self.pending_frames < self.config.min_frames_confirm {
            return None;
        }

        self.execute_transition(target_state, direction, frame_id, timestamp_ms)
    }

    fn execute_transition(
        &mut self,
        target_state: LaneChangeState,
        direction: Direction,
        frame_id: u64,
        timestamp_ms: f64,
    ) -> Option<LaneChangeEvent> {
        let from_state = self.state;

        info!(
            "State: {:?}  {:?} at frame {} ({:.2}s)",
            from_state,
            target_state,
            frame_id,
            timestamp_ms / 1000.0
        );

        if target_state == LaneChangeState::Drifting && from_state == LaneChangeState::Centered {
            self.change_direction = if self.pending_change_direction != Direction::Unknown {
                self.pending_change_direction
            } else {
                direction
            };
            self.change_start_frame = Some(frame_id);
            self.change_start_time = Some(timestamp_ms);
            self.max_offset_in_change = self.pending_max_offset;
            self.stable_deviation_frames = 0;
            self.last_deviation = 0.0;

            if !self.adaptive_baseline.is_frozen {
                self.adaptive_baseline.freeze();
            }

            info!(
                " Lane change started: {} at {:.2}s via {:?} (max so far: {:.1}%)",
                self.change_direction.as_str(),
                timestamp_ms / 1000.0,
                self.change_detection_path,
                self.max_offset_in_change * 100.0
            );
        }

        if target_state == LaneChangeState::Centered && from_state == LaneChangeState::Drifting {
            info!(" Cancelled");
            self.adaptive_baseline.unfreeze();
            self.reset_lane_change();
            self.cooldown_remaining = 30;
            return None;
        }

        let duration_ms = if target_state == LaneChangeState::Completed {
            self.change_start_time.map(|start| timestamp_ms - start)
        } else {
            None
        };

        self.state = target_state;
        self.frames_in_state = 0;
        self.pending_state = None;
        self.pending_frames = 0;

        if target_state == LaneChangeState::Completed {
            if let Some(dur) = duration_ms {
                if dur < self.config.min_duration_ms
                    && self.max_offset_in_change < DEVIATION_SIGNIFICANT
                {
                    warn!(" Rejected: short + low dev");
                    self.adaptive_baseline.unfreeze();
                    self.reset_lane_change();
                    self.cooldown_remaining = 60;
                    return None;
                }
            }

            let min_offset_for_valid = self.config.drift_threshold + 0.05;
            if self.max_offset_in_change < min_offset_for_valid {
                warn!(
                    " Rejected: max={:.1}% < {:.1}%",
                    self.max_offset_in_change * 100.0,
                    min_offset_for_valid * 100.0
                );
                self.adaptive_baseline.unfreeze();
                self.reset_lane_change();
                self.cooldown_remaining = 60;
                return None;
            }

            self.cooldown_remaining = self.config.cooldown_frames;

            let start_frame = self.change_start_frame.unwrap_or(frame_id);
            let start_time = self.change_start_time.unwrap_or(timestamp_ms);
            let confidence = self.calculate_confidence(duration_ms);

            let mut event = LaneChangeEvent::new(
                start_time,
                start_frame,
                frame_id,
                self.change_direction,
                confidence,
            );
            event.duration_ms = duration_ms;
            event.source_id = self.source_id.clone();

            info!(
                " CONFIRMED: {} at {:.2}s, dur={:.0}ms, max={:.1}%, path={:?}",
                event.direction_name(),
                start_time / 1000.0,
                duration_ms.unwrap_or(0.0),
                self.max_offset_in_change * 100.0,
                self.change_detection_path
            );

            self.adaptive_baseline.reset();
            self.position_filter.reset();
            self.post_lane_change_grace = POST_CHANGE_GRACE_FRAMES;
            self.offset_samples.clear();

            info!(" Baseline reset - will adapt to new position");
            self.reset_lane_change();

            return Some(event);
        }

        None
    }

    fn calculate_confidence(&self, duration_ms: Option<f64>) -> f32 {
        let mut confidence: f32 = 0.5;
        if self.max_offset_in_change > 0.60 {
            confidence += 0.25;
        } else if self.max_offset_in_change > 0.50 {
            confidence += 0.20;
        } else if self.max_offset_in_change > 0.40 {
            confidence += 0.15;
        } else {
            confidence += 0.05;
        }

        if let Some(dur) = duration_ms {
            if dur > 1000.0 && dur < 6000.0 {
                confidence += 0.15;
            } else if dur > 500.0 && dur < 10000.0 {
                confidence += 0.10;
            } else {
                confidence += 0.05;
            }
        }

        if let Some(path) = &self.change_detection_path {
            match path {
                DetectionPath::BoundaryCrossing | DetectionPath::TLCBased => confidence += 0.05,
                DetectionPath::HighVelocity | DetectionPath::VelocitySpike => confidence += 0.03,
                _ => {}
            }
        }
        confidence.min(0.95)
    }

    pub fn reset(&mut self) {
        self.reset_lane_change();
        self.adaptive_baseline.unfreeze();
        self.cooldown_remaining = 0;
        self.total_frames_processed = 0;
        self.post_lane_change_grace = 0;
        self.position_filter.reset();
        self.adaptive_baseline.reset();
        self.offset_history.clear();
        self.velocity_history.clear();
        self.curve_detector.reset();
        self.velocity_tracker.reset();
        self.offset_samples.clear();
        self.direction_samples.clear();
        self.is_in_curve = false;
        self.curve_compensation_factor = 1.0;
    }

    pub fn set_source_id(&mut self, source_id: String) {
        self.source_id = source_id;
    }
}
// src/analysis/curve_detector.rs

use crate::types::Lane;
use std::collections::VecDeque;
use tracing::debug;

pub struct CurveDetector {
    lane_angle_history: VecDeque<f32>,
    history_size: usize,
    curve_threshold: f32,
}

impl CurveDetector {
    pub fn new() -> Self {
        Self {
            lane_angle_history: VecDeque::with_capacity(30),
            history_size: 30,
            curve_threshold: 5.0, // degrees
        }
    }

    pub fn is_in_curve(&mut self, lanes: &[Lane]) -> bool {
        let angle = self.calculate_lane_angle(lanes);

        self.lane_angle_history.push_back(angle);
        if self.lane_angle_history.len() > self.history_size {
            self.lane_angle_history.pop_front();
        }

        if self.lane_angle_history.len() < 10 {
            return false;
        }

        // Calculate average absolute angle
        let avg_angle: f32 = self.lane_angle_history.iter().map(|a| a.abs()).sum::<f32>()
            / self.lane_angle_history.len() as f32;

        let is_curve = avg_angle > self.curve_threshold;

        if is_curve {
            debug!(
                " Curve detected: avg angle = {:.1} (threshold: {:.1})",
                avg_angle, self.curve_threshold
            );
        }

        is_curve
    }

    fn calculate_lane_angle(&self, lanes: &[Lane]) -> f32 {
        // Find the most confident lane with enough points
        let best_lane = lanes.iter().filter(|l| l.points.len() >= 5).max_by(|a, b| {
            a.confidence
                .partial_cmp(&b.confidence)
                .unwrap_or(std::cmp::Ordering::Equal)
        });

        if let Some(lane) = best_lane {
            // Calculate angle between bottom and top points
            if lane.points.len() >= 2 {
                let bottom = &lane.points[0];
                let top = &lane.points[lane.points.len() - 1];

                let dx = top.x - bottom.x;
                let dy = top.y - bottom.y;

                if dy.abs() > 10.0 {
                    // Prevent division by near-zero
                    let angle_rad = (dx / dy).atan();
                    let angle_deg = angle_rad.to_degrees();
                    return angle_deg;
                }
            }
        }

        0.0 // No curve detected
    }

    pub fn reset(&mut self) {
        self.lane_angle_history.clear();
    }
}
// src/analysis/position_estimator.rs

use crate::types::{Lane, VehicleState};
use std::collections::VecDeque;
use tracing::debug;

pub struct PositionEstimator {
    pub reference_y_ratio: f32,
    pub min_lane_width: f32,
    pub max_lane_width: f32,
    pub default_lane_width: f32,
    lane_width_history: VecDeque<f32>,
    offset_history: VecDeque<f32>,
    history_size: usize,
    last_valid_width: Option<f32>,
}

impl PositionEstimator {
    pub fn new(reference_y_ratio: f32) -> Self {
        Self {
            reference_y_ratio,
            min_lane_width: 100.0,
            max_lane_width: 900.0,
            default_lane_width: 550.0,
            lane_width_history: VecDeque::with_capacity(15),
            offset_history: VecDeque::with_capacity(15),
            history_size: 15,
            last_valid_width: None,
        }
    }

    fn get_stable_lane_width(&mut self, measured: f32) -> f32 {
        if measured >= self.min_lane_width && measured <= self.max_lane_width {
            self.lane_width_history.push_back(measured);
            if self.lane_width_history.len() > self.history_size {
                self.lane_width_history.pop_front();
            }
            self.last_valid_width = Some(measured);
        }

        if self.lane_width_history.len() < 3 {
            return self.last_valid_width.unwrap_or(self.default_lane_width);
        }

        let mut sorted: Vec<f32> = self.lane_width_history.iter().copied().collect();
        sorted.sort_by(|a, b| a.partial_cmp(b).unwrap_or(std::cmp::Ordering::Equal));
        sorted[sorted.len() / 2]
    }

    fn update_offset_history(&mut self, offset: f32) {
        self.offset_history.push_back(offset);
        if self.offset_history.len() > self.history_size {
            self.offset_history.pop_front();
        }
    }

    pub fn estimate(
        &mut self,
        lanes: &[Lane],
        frame_width: u32,
        frame_height: u32,
    ) -> VehicleState {
        let vehicle_x = frame_width as f32 / 2.0;
        let reference_y = frame_height as f32 * self.reference_y_ratio;

        let confident_lanes: Vec<&Lane> = lanes
            .iter()
            .filter(|l| l.confidence > 0.2 && l.points.len() >= 3)
            .collect();

        let left_lane = self.find_ego_lane(&confident_lanes, vehicle_x, true);
        let right_lane = self.find_ego_lane(&confident_lanes, vehicle_x, false);

        let left_x = left_lane.and_then(|l| l.get_x_at_y(reference_y));
        let right_x = right_lane.and_then(|l| l.get_x_at_y(reference_y));

        let both_lanes_detected = left_x.is_some() && right_x.is_some();

        let detection_confidence = match (&left_lane, &right_lane) {
            (Some(l), Some(r)) => (l.confidence + r.confidence) / 2.0,
            (Some(l), None) => l.confidence * 0.6,
            (None, Some(r)) => r.confidence * 0.6,
            (None, None) => 0.0,
        };

        let mut lane_width: Option<f32> = None;
        let mut lateral_offset = 0.0f32;
        let mut raw_offset = 0.0f32;

        match (left_x, right_x) {
            (Some(lx), Some(rx)) => {
                let measured_width = rx - lx;
                let stable_width = self.get_stable_lane_width(measured_width);
                lane_width = Some(stable_width);

                let lane_center = (lx + rx) / 2.0;
                raw_offset = vehicle_x - lane_center;
                lateral_offset = raw_offset;

                self.update_offset_history(lateral_offset);
            }
            (Some(lx), None) => {
                let stable_width = self.get_stable_lane_width(self.default_lane_width);
                let estimated_center = lx + (stable_width / 2.0);
                raw_offset = vehicle_x - estimated_center;
                lateral_offset = raw_offset;
                lane_width = Some(stable_width);
                self.update_offset_history(lateral_offset);
            }
            (None, Some(rx)) => {
                let stable_width = self.get_stable_lane_width(self.default_lane_width);
                let estimated_center = rx - (stable_width / 2.0);
                raw_offset = vehicle_x - estimated_center;
                lateral_offset = raw_offset;
                lane_width = Some(stable_width);
                self.update_offset_history(lateral_offset);
            }
            (None, None) => {
                if let Some(width) = self.last_valid_width {
                    lane_width = Some(width);
                }
                if let Some(&last_offset) = self.offset_history.back() {
                    lateral_offset = last_offset;
                }
            }
        }

        VehicleState {
            lateral_offset,
            lane_width,
            heading_offset: 0.0,
            frame_id: 0,
            timestamp_ms: 0.0,
            raw_offset,
            detection_confidence,
            both_lanes_detected,
        }
    }

    fn find_ego_lane<'a>(
        &self,
        lanes: &[&'a Lane],
        vehicle_x: f32,
        is_left: bool,
    ) -> Option<&'a Lane> {
        let mut candidates: Vec<(&Lane, f32)> = Vec::new();

        for lane in lanes {
            if lane.points.len() < 2 {
                continue;
            }

            if let Some(p) = lane.bottom_point() {
                if is_left && p.x < vehicle_x {
                    candidates.push((lane, vehicle_x - p.x));
                } else if !is_left && p.x > vehicle_x {
                    candidates.push((lane, p.x - vehicle_x));
                }
            }
        }

        candidates.sort_by(|a, b| a.1.partial_cmp(&b.1).unwrap_or(std::cmp::Ordering::Equal));
        candidates.first().map(|(lane, _)| *lane)
    }

    pub fn reset(&mut self) {
        self.lane_width_history.clear();
        self.offset_history.clear();
        self.last_valid_width = None;
    }
}

pub struct PositionSmoother {
    alpha: f32,
    smoothed_offset: Option<f32>,
    smoothed_width: Option<f32>,
}

impl PositionSmoother {
    pub fn new(alpha: f32) -> Self {
        Self {
            alpha: alpha.clamp(0.1, 0.5),
            smoothed_offset: None,
            smoothed_width: None,
        }
    }

    pub fn smooth(&mut self, state: VehicleState) -> VehicleState {
        let smoothed_offset = match self.smoothed_offset {
            None => {
                self.smoothed_offset = Some(state.lateral_offset);
                state.lateral_offset
            }
            Some(prev) => {
                let new_val = self.alpha * state.lateral_offset + (1.0 - self.alpha) * prev;
                self.smoothed_offset = Some(new_val);
                new_val
            }
        };

        let smoothed_width = if let Some(width) = state.lane_width {
            match self.smoothed_width {
                None => {
                    self.smoothed_width = Some(width);
                    Some(width)
                }
                Some(prev) => {
                    let new_val = 0.1 * width + 0.9 * prev;
                    self.smoothed_width = Some(new_val);
                    Some(new_val)
                }
            }
        } else {
            self.smoothed_width
        };

        VehicleState {
            lateral_offset: smoothed_offset,
            lane_width: smoothed_width,
            heading_offset: state.heading_offset,
            frame_id: state.frame_id,
            timestamp_ms: state.timestamp_ms,
            raw_offset: state.raw_offset,
            detection_confidence: state.detection_confidence,
            both_lanes_detected: state.both_lanes_detected,
        }
    }

    pub fn reset(&mut self) {
        self.smoothed_offset = None;
        self.smoothed_width = None;
    }
}
// src/analysis/mod.rs

mod boundary_detector;
mod curve_detector;
mod lane_analyzer;
mod position_estimator;
mod state_machine;
mod velocity_tracker;

pub use lane_analyzer::LaneChangeAnalyzer;
// src/analysis/boundary_detector.rs

use std::collections::VecDeque;
use tracing::debug;

#[derive(Debug, Clone, Copy, PartialEq, Eq)]
pub enum CrossingType {
    None,
    CrossedLeft,
    CrossedRight,
}

pub struct LaneBoundaryCrossingDetector {
    left_lane_x_history: VecDeque<f32>,
    right_lane_x_history: VecDeque<f32>,
    vehicle_x_history: VecDeque<f32>,
    history_size: usize,
    crossing_margin: f32,
}

impl LaneBoundaryCrossingDetector {
    pub fn new() -> Self {
        Self {
            left_lane_x_history: VecDeque::with_capacity(15),
            right_lane_x_history: VecDeque::with_capacity(15),
            vehicle_x_history: VecDeque::with_capacity(15),
            history_size: 15,
            crossing_margin: 20.0, // pixels - margin for noise tolerance
        }
    }

    pub fn detect_crossing(
        &mut self,
        left_x: Option<f32>,
        right_x: Option<f32>,
        vehicle_x: f32,
    ) -> CrossingType {
        // Need history to detect crossing
        if self.left_lane_x_history.is_empty() {
            self.update_history(left_x, right_x, vehicle_x);
            return CrossingType::None;
        }

        match (left_x, right_x) {
            (Some(lx), Some(rx)) => {
                // Get previous positions
                let prev_left = self.left_lane_x_history.back().copied();
                let prev_right = self.right_lane_x_history.back().copied();
                let prev_vehicle = self.vehicle_x_history.back().copied();

                if let (Some(prev_lx), Some(prev_rx), Some(prev_vx)) =
                    (prev_left, prev_right, prev_vehicle)
                {
                    // Check if vehicle WAS inside lane boundaries
                    let was_inside = prev_vx > (prev_lx + self.crossing_margin)
                        && prev_vx < (prev_rx - self.crossing_margin);

                    // Check if vehicle IS STILL inside lane boundaries
                    let is_inside = vehicle_x > (lx + self.crossing_margin)
                        && vehicle_x < (rx - self.crossing_margin);

                    // Crossing detected if vehicle went from inside to outside
                    if was_inside && !is_inside {
                        let crossing_type = if vehicle_x <= lx + self.crossing_margin {
                            CrossingType::CrossedLeft
                        } else if vehicle_x >= rx - self.crossing_margin {
                            CrossingType::CrossedRight
                        } else {
                            CrossingType::None
                        };

                        if crossing_type != CrossingType::None {
                            debug!(
                                " Boundary crossing detected: {:?} | Vehicle: {:.1} | Left: {:.1} | Right: {:.1}",
                                crossing_type, vehicle_x, lx, rx
                            );
                        }

                        self.update_history(left_x, right_x, vehicle_x);
                        return crossing_type;
                    }
                }

                self.update_history(left_x, right_x, vehicle_x);
                CrossingType::None
            }
            _ => {
                // Can't detect crossing without both lane boundaries
                self.update_history(left_x, right_x, vehicle_x);
                CrossingType::None
            }
        }
    }

    fn update_history(&mut self, left_x: Option<f32>, right_x: Option<f32>, vehicle_x: f32) {
        if let Some(lx) = left_x {
            self.left_lane_x_history.push_back(lx);
            if self.left_lane_x_history.len() > self.history_size {
                self.left_lane_x_history.pop_front();
            }
        }

        if let Some(rx) = right_x {
            self.right_lane_x_history.push_back(rx);
            if self.right_lane_x_history.len() > self.history_size {
                self.right_lane_x_history.pop_front();
            }
        }

        self.vehicle_x_history.push_back(vehicle_x);
        if self.vehicle_x_history.len() > self.history_size {
            self.vehicle_x_history.pop_front();
        }
    }

    pub fn reset(&mut self) {
        self.left_lane_x_history.clear();
        self.right_lane_x_history.clear();
        self.vehicle_x_history.clear();
    }
}
// src/analysis/velocity_tracker.rs

use std::collections::VecDeque;

pub struct LateralVelocityTracker {
    offset_history: VecDeque<(f32, f64)>, // (offset_px, timestamp_ms)
    history_size: usize,
}

impl LateralVelocityTracker {
    pub fn new() -> Self {
        Self {
            offset_history: VecDeque::with_capacity(20),
            history_size: 20,
        }
    }

    pub fn get_velocity(&mut self, offset_px: f32, timestamp_ms: f64) -> f32 {
        self.offset_history.push_back((offset_px, timestamp_ms));

        if self.offset_history.len() > self.history_size {
            self.offset_history.pop_front();
        }

        if self.offset_history.len() < 5 {
            return 0.0;
        }

        // Calculate velocity over the entire history window
        let first = self.offset_history.front().unwrap();
        let last = self.offset_history.back().unwrap();

        let delta_offset = last.0 - first.0;
        let delta_time = (last.1 - first.1) / 1000.0; // Convert to seconds

        if delta_time > 0.01 {
            // Avoid division by near-zero
            let velocity = delta_offset / delta_time as f32; // pixels per second
            velocity
        } else {
            0.0
        }
    }

    #[allow(dead_code)]
    pub fn is_moving_laterally(&self, min_velocity_px_per_sec: f32) -> bool {
        if self.offset_history.len() < 5 {
            return false;
        }

        let first = self.offset_history.front().unwrap();
        let last = self.offset_history.back().unwrap();

        let delta_offset = (last.0 - first.0).abs();
        let delta_time = (last.1 - first.1) / 1000.0;

        if delta_time > 0.01 {
            let velocity = delta_offset / delta_time as f32;
            velocity > min_velocity_px_per_sec
        } else {
            false
        }
    }

    pub fn reset(&mut self) {
        self.offset_history.clear();
    }
}
// src/analysis/lane_analyzer.rs

use crate::analysis::boundary_detector::{CrossingType, LaneBoundaryCrossingDetector};
use crate::analysis::position_estimator::{PositionEstimator, PositionSmoother};
use crate::analysis::state_machine::LaneChangeStateMachine;
use crate::types::{Lane, LaneChangeConfig, LaneChangeEvent, VehicleState};

pub struct LaneChangeAnalyzer {
    position_estimator: PositionEstimator,
    smoother: PositionSmoother,
    state_machine: LaneChangeStateMachine,
    boundary_detector: LaneBoundaryCrossingDetector,
    config: LaneChangeConfig,
    last_state: Option<VehicleState>,
    frame_count: u64,
    valid_estimates: u64,
}

impl LaneChangeAnalyzer {
    pub fn new(config: LaneChangeConfig) -> Self {
        let position_estimator = PositionEstimator::new(config.reference_y_ratio);
        let smoother = PositionSmoother::new(config.smoothing_alpha);
        let state_machine = LaneChangeStateMachine::new(config.clone());
        let boundary_detector = LaneBoundaryCrossingDetector::new();

        Self {
            position_estimator,
            smoother,
            state_machine,
            boundary_detector,
            config,
            last_state: None,
            frame_count: 0,
            valid_estimates: 0,
        }
    }

    pub fn analyze(
        &mut self,
        lanes: &[Lane],
        frame_width: u32,
        frame_height: u32,
        frame_id: u64,
        timestamp_ms: f64,
    ) -> Option<LaneChangeEvent> {
        self.frame_count += 1;

        // Update curve detector with current lanes
        let _is_in_curve = self.state_machine.update_curve_detector(lanes);

        // Get raw position estimate
        let mut raw_state = self
            .position_estimator
            .estimate(lanes, frame_width, frame_height);
        raw_state.frame_id = frame_id;
        raw_state.timestamp_ms = timestamp_ms;

        // Apply smoothing
        let smoothed_state = self.smoother.smooth(raw_state);

        if smoothed_state.is_valid() {
            self.valid_estimates += 1;
        }

        // Detect lane boundary crossing
        let (left_x, right_x) = self.get_lane_boundaries(lanes, frame_height);
        let vehicle_x = frame_width as f32 / 2.0;

        let crossing_type = self
            .boundary_detector
            .detect_crossing(left_x, right_x, vehicle_x);

        self.last_state = Some(smoothed_state);

        // Update state machine with crossing info
        self.state_machine
            .update(&smoothed_state, frame_id, timestamp_ms, crossing_type)
    }

    fn get_lane_boundaries(&self, lanes: &[Lane], frame_height: u32) -> (Option<f32>, Option<f32>) {
        let reference_y = frame_height as f32 * self.config.reference_y_ratio;

        // Find left and right ego lanes
        let mut left_x = None;
        let mut right_x = None;

        let vehicle_x = 640.0; // Approximate center, adjust if needed

        for lane in lanes {
            if let Some(x) = lane.get_x_at_y(reference_y) {
                if x < vehicle_x && (left_x.is_none() || x > left_x.unwrap()) {
                    left_x = Some(x);
                } else if x > vehicle_x && (right_x.is_none() || x < right_x.unwrap()) {
                    right_x = Some(x);
                }
            }
        }

        (left_x, right_x)
    }

    pub fn current_state(&self) -> &str {
        self.state_machine.current_state()
    }

    pub fn last_vehicle_state(&self) -> Option<&VehicleState> {
        self.last_state.as_ref()
    }

    pub fn reset(&mut self) {
        self.state_machine.reset();
        self.smoother.reset();
        self.position_estimator.reset();
        self.boundary_detector.reset();
        self.last_state = None;
        self.frame_count = 0;
        self.valid_estimates = 0;
    }

    pub fn set_source_id(&mut self, source_id: String) {
        self.state_machine.set_source_id(source_id);
    }

    pub fn config(&self) -> &LaneChangeConfig {
        &self.config
    }

    pub fn get_stats(&self) -> (u64, u64, f32) {
        let valid_ratio = if self.frame_count > 0 {
            self.valid_estimates as f32 / self.frame_count as f32
        } else {
            0.0
        };
        (self.frame_count, self.valid_estimates, valid_ratio)
    }
}
use crate::types::Config;
use anyhow::Result;
use std::fs;

impl Config {
    pub fn load(path: &str) -> Result<Self> {
        let contents = fs::read_to_string(path)?;
        let config: Config = serde_yaml::from_str(&contents)?;
        Ok(config)
    }
}
// src/lane_detection.rs

use crate::types::{Config, DetectedLane};
use anyhow::Result;
use tracing::debug;

pub struct LaneDetectionResult {
    pub lanes: Vec<DetectedLane>,
    pub timestamp_ms: f64,
}

/// Softmax along first axis
fn softmax_axis0(data: &[f32], dim0: usize, dim1: usize, dim2: usize) -> Vec<f32> {
    let mut result = vec![0.0f32; data.len()];

    for j in 0..dim1 {
        for k in 0..dim2 {
            // Find max for numerical stability
            let mut max_val = f32::NEG_INFINITY;
            for i in 0..dim0 {
                let idx = i * (dim1 * dim2) + j * dim2 + k;
                if data[idx] > max_val {
                    max_val = data[idx];
                }
            }

            // Compute exp and sum
            let mut sum = 0.0f32;
            for i in 0..dim0 {
                let idx = i * (dim1 * dim2) + j * dim2 + k;
                let exp_val = (data[idx] - max_val).exp();
                result[idx] = exp_val;
                sum += exp_val;
            }

            // Normalize
            for i in 0..dim0 {
                let idx = i * (dim1 * dim2) + j * dim2 + k;
                result[idx] /= sum;
            }
        }
    }

    result
}

pub fn parse_lanes(
    output: &[f32],
    frame_width: f32,
    frame_height: f32,
    config: &Config,
    timestamp_ms: f64,
) -> Result<LaneDetectionResult> {
    let griding_num = config.model.griding_num; // 200
    let num_anchors = config.model.num_anchors; // 72
    let num_lanes = config.model.num_lanes; // 4

    // Expected size for loc_row tensor [200, 72, 4]
    let loc_row_size = griding_num * num_anchors * num_lanes;

    if output.len() < loc_row_size {
        anyhow::bail!(
            "Output size mismatch: expected {}, got {}",
            loc_row_size,
            output.len()
        );
    }

    // Constants matching Python
    const ROW_ANCHOR_START: f32 = 160.0;
    const ROW_ANCHOR_END: f32 = 710.0;
    const ORIGINAL_HEIGHT: f32 = 720.0;

    // Apply softmax along grid dimension (like Python)
    let loc_row_prob = softmax_axis0(output, griding_num, num_anchors, num_lanes);

    let mut lanes = Vec::new();

    for lane_idx in 0..num_lanes {
        let mut points: Vec<(f32, f32)> = Vec::new();
        let mut total_confidence = 0.0;
        let mut valid_points = 0;

        for anchor_idx in 0..num_anchors {
            // Find argmax along grid dimension (after softmax)
            let mut max_prob = f32::NEG_INFINITY;
            let mut max_grid_idx = 0;

            for grid_idx in 0..griding_num {
                let idx = grid_idx * (num_anchors * num_lanes) + anchor_idx * num_lanes + lane_idx;
                let prob = loc_row_prob[idx];
                if prob > max_prob {
                    max_prob = prob;
                    max_grid_idx = grid_idx;
                }
            }

            // Skip grid_idx == 0 (no lane class) - matches Python
            if max_grid_idx == 0 {
                continue;
            }

            // Only include points with reasonable confidence
            if max_prob < 0.1 {
                continue;
            }

            // Calculate X coordinate - matches Python exactly
            // Python: x_norm = (grid_idx - 1) / (num_grid_cells - 1)
            let x_norm = (max_grid_idx as f32 - 1.0) / (griding_num as f32 - 1.0);
            let x = x_norm * frame_width;

            // Calculate Y coordinate - matches Python exactly
            // Python: np.linspace(160, 710, 72)
            let y_norm = ROW_ANCHOR_START
                + (ROW_ANCHOR_END - ROW_ANCHOR_START)
                    * (anchor_idx as f32 / (num_anchors as f32 - 1.0));
            let y = (y_norm / ORIGINAL_HEIGHT) * frame_height;

            points.push((x, y));
            total_confidence += max_prob;
            valid_points += 1;
        }

        // Require minimum points per lane
        if points.len() >= config.detection.min_points_per_lane {
            let avg_confidence = if valid_points > 0 {
                total_confidence / valid_points as f32
            } else {
                0.0
            };

            // Sort points by Y (bottom to top for consistency)
            points.sort_by(|a, b| b.1.partial_cmp(&a.1).unwrap_or(std::cmp::Ordering::Equal));

            lanes.push(DetectedLane {
                points,
                confidence: avg_confidence,
            });
        }
    }

    debug!("Detected {} lanes", lanes.len());

    Ok(LaneDetectionResult {
        lanes,
        timestamp_ms,
    })
}
// src/main.rs

mod analysis;
mod frame_buffer;
mod inference;
mod lane_detection;
mod preprocessing;
mod types;
mod video_processor;

use analysis::LaneChangeAnalyzer;
use anyhow::Result;
use frame_buffer::{
    build_legality_request, print_legality_request, save_legality_request_to_file,
    send_to_legality_api, LaneChangeFrameBuffer,
};
use std::path::Path;
use tracing::{debug, error, info, warn};
use types::{DetectedLane, Frame, Lane, LaneChangeConfig, LaneChangeEvent};

/// Configuration for legality analysis
struct LegalityAnalysisConfig {
    /// Number of frames to extract and send for analysis
    num_frames_to_analyze: usize,
    /// Maximum frames to buffer during lane change
    max_buffer_frames: usize,
    /// Whether to save the request payload to a file
    save_to_file: bool,
    /// Whether to print the request to console
    print_to_console: bool,
    /// Whether to send to the API
    send_to_api: bool,
    /// API URL for legality analysis
    api_url: String,
}

impl Default for LegalityAnalysisConfig {
    fn default() -> Self {
        Self {
            num_frames_to_analyze: 7,
            max_buffer_frames: 90,
            save_to_file: false,
            print_to_console: true,
            send_to_api: true,
            api_url: "http://localhost:3000/api/analyze".to_string(),
        }
    }
}

#[tokio::main]
async fn main() -> Result<()> {
    tracing_subscriber::fmt()
        .with_env_filter("overtake_detection=info,ort=warn")
        .init();

    info!(" Lane Change Detection System Starting");

    let config = types::Config::load("config.yaml")?;
    info!(" Configuration loaded");

    // Log key detection parameters
    info!(
        "Detection thresholds: drift={:.2}, crossing={:.2}, confirm_frames={}",
        config.detection.drift_threshold,
        config.detection.crossing_threshold,
        config.detection.confirm_frames
    );

    let mut inference_engine = inference::InferenceEngine::new(config.clone())?;
    info!(" Inference engine ready");

    let video_processor = video_processor::VideoProcessor::new(config.clone());

    let video_files = video_processor.find_video_files()?;

    if video_files.is_empty() {
        error!("No video files found in {}", config.video.input_dir);
        return Ok(());
    }

    info!("Found {} video file(s) to process", video_files.len());

    // Legality analysis configuration
    let legality_config = LegalityAnalysisConfig {
        num_frames_to_analyze: 5,
        max_buffer_frames: 90,
        save_to_file: false,
        print_to_console: true,
        send_to_api: true,
        api_url: std::env::var("LEGALITY_API_URL")
            .unwrap_or_else(|_| "http://localhost:3000/api/analyze".to_string()),
    };

    info!(" Legality API URL: {}", legality_config.api_url);

    for (idx, video_path) in video_files.iter().enumerate() {
        info!("\n========================================");
        info!(
            "Processing video {}/{}: {}",
            idx + 1,
            video_files.len(),
            video_path.display()
        );
        info!("========================================\n");

        match process_video(
            video_path,
            &mut inference_engine,
            &video_processor,
            &config,
            &legality_config,
        )
        .await
        {
            Ok(stats) => {
                info!("\n Video processed successfully!");
                info!("  Total frames: {}", stats.total_frames);
                info!(
                    "  Valid position frames: {} ({:.1}%)",
                    stats.frames_with_position,
                    100.0 * stats.frames_with_position as f64 / stats.total_frames as f64
                );
                info!("  Lane changes detected: {}", stats.lane_changes_detected);
                info!("  Events sent to API: {}", stats.events_sent_to_api);
            }
            Err(e) => {
                error!("Failed to process video: {}", e);
            }
        }
    }

    Ok(())
}

struct ProcessingStats {
    total_frames: u64,
    frames_with_position: u64,
    lane_changes_detected: usize,
    events_sent_to_api: usize,
    duration_secs: f64,
    avg_fps: f64,
}

async fn process_video(
    video_path: &Path,
    inference_engine: &mut inference::InferenceEngine,
    video_processor: &video_processor::VideoProcessor,
    config: &types::Config,
    legality_config: &LegalityAnalysisConfig,
) -> Result<ProcessingStats> {
    use std::time::Instant;

    let start_time = Instant::now();

    let mut reader = video_processor.open_video(video_path)?;

    let mut writer =
        video_processor.create_writer(video_path, reader.width, reader.height, reader.fps)?;

    // *** USE CONFIG VALUES INSTEAD OF HARDCODED ***
    let lane_change_config = LaneChangeConfig::from_detection_config(&config.detection);

    info!(
        "Lane change config: drift={:.2}, crossing={:.2}, confirm={}, cooldown={}, hysteresis={:.2}",
        lane_change_config.drift_threshold,
        lane_change_config.crossing_threshold,
        lane_change_config.min_frames_confirm,
        lane_change_config.cooldown_frames,
        lane_change_config.hysteresis_factor
    );

    let mut analyzer = LaneChangeAnalyzer::new(lane_change_config);
    analyzer.set_source_id(video_path.to_string_lossy().to_string());

    let mut lane_changes: Vec<LaneChangeEvent> = Vec::new();
    let mut frame_count: u64 = 0;
    let mut frames_with_valid_position: u64 = 0;
    let mut events_sent_to_api: usize = 0;

    let mut cached_start_frame: Option<Frame> = None;
    let mut previous_state = "CENTERED".to_string();

    // Frame buffer for capturing lane change frames
    let mut frame_buffer = LaneChangeFrameBuffer::new(legality_config.max_buffer_frames);

    // Confidence threshold from config
    let lane_confidence_threshold = config.detection.min_lane_confidence;

    // En la funcin process_video, reemplaza todo el loop while:

    while let Some(frame) = reader.read_frame()? {
        frame_count += 1;
        let timestamp_ms = frame.timestamp_ms;

        if frame_count % 50 == 0 {
            info!(
            "Progress: {:.1}% ({}/{}) | State: {} | Lane changes: {} | Buffered: {} | Pre-buffered: {}",
            reader.progress(),
            reader.current_frame,
            reader.total_frames,
            analyzer.current_state(),
            lane_changes.len(),
            frame_buffer.frame_count(),
            frame_buffer.pre_buffer_count()
        );
        }

        match process_frame(
            &frame,
            inference_engine,
            config,
            config.detection.min_lane_confidence,
        )
        .await
        {
            Ok(detected_lanes) => {
                let analysis_lanes: Vec<Lane> = detected_lanes
                    .iter()
                    .enumerate()
                    .map(|(i, dl)| Lane::from_detected(i, dl))
                    .collect();

                //  IMPORTANTE: Agregar al pre-buffer ANTES de analizar (usa previous_state)
                if previous_state == "CENTERED" {
                    frame_buffer.add_to_pre_buffer(frame.clone());
                }

                // Check if lane change completed
                if let Some(mut event) = analyzer.analyze(
                    &analysis_lanes,
                    frame.width as u32,
                    frame.height as u32,
                    frame_count,
                    timestamp_ms,
                ) {
                    info!(
                        " LANE CHANGE DETECTED: {} at {:.2}s (frame {})",
                        event.direction_name(),
                        event.video_timestamp_ms / 1000.0,
                        event.end_frame_id
                    );

                    // Get captured frames (includes pre-buffer)
                    let captured_frames = frame_buffer.stop_capture();

                    info!(
                        " Captured {} frames total (includes pre-buffer context)",
                        captured_frames.len()
                    );

                    // Build and send legality request
                    if !captured_frames.is_empty() {
                        match build_legality_request(
                            &event,
                            &captured_frames,
                            legality_config.num_frames_to_analyze,
                        ) {
                            Ok(request) => {
                                if legality_config.print_to_console {
                                    print_legality_request(&request);
                                }

                                if legality_config.save_to_file {
                                    if let Err(e) = save_legality_request_to_file(
                                        &request,
                                        &config.video.output_dir,
                                    ) {
                                        warn!("Failed to save legality request: {}", e);
                                    }
                                }

                                if legality_config.send_to_api {
                                    match send_to_legality_api(&request, &legality_config.api_url)
                                        .await
                                    {
                                        Ok(response) => {
                                            info!(
                                                " Event {} sent to API: {} - {}",
                                                response.event_id,
                                                response.status,
                                                response.message
                                            );
                                            events_sent_to_api += 1;
                                        }
                                        Err(e) => {
                                            error!(" Failed to send event to API: {}", e);
                                        }
                                    }
                                }
                            }
                            Err(e) => {
                                warn!("Failed to build legality request: {}", e);
                            }
                        }
                    } else {
                        warn!("No frames captured for lane change event");
                    }

                    // Save evidence images (use first captured frame as start)
                    let video_stem = video_path.file_stem().unwrap().to_str().unwrap();
                    let start_filename =
                        format!("{}_event_{}_start.jpg", video_stem, event.event_id);
                    let end_filename = format!("{}_event_{}_end.jpg", video_stem, event.event_id);

                    let mut start_path_str = String::new();
                    let mut end_path_str = String::new();

                    // Use first captured frame (from pre-buffer) as start
                    if !captured_frames.is_empty() {
                        if let Ok(path) =
                            video_processor.save_frame_to_disk(&captured_frames[0], &start_filename)
                        {
                            start_path_str = path.to_string_lossy().to_string();
                        }
                    }

                    if let Ok(path) = video_processor.save_frame_to_disk(&frame, &end_filename) {
                        end_path_str = path.to_string_lossy().to_string();
                    }

                    event.evidence_images = Some(types::EvidencePaths {
                        start_image_path: start_path_str,
                        end_image_path: end_path_str,
                    });

                    lane_changes.push(event);
                }

                //  Obtener current_state DESPUS del anlisis
                let current_state = analyzer.current_state().to_string();

                // Start capturing when CENTERED -> DRIFTING
                if previous_state == "CENTERED" && current_state == "DRIFTING" {
                    frame_buffer.start_capture(frame_count);
                    debug!(
                        " Started capturing at frame {} (with pre-buffer)",
                        frame_count
                    );
                }

                // Continue capturing during lane change
                if frame_buffer.is_capturing() {
                    frame_buffer.add_frame(frame.clone());
                }

                // Cancel if returned to CENTERED without completing
                if current_state == "CENTERED" && frame_buffer.is_capturing() {
                    frame_buffer.cancel_capture();
                    debug!(" Lane change cancelled");
                }

                //  Actualizar previous_state al final
                previous_state = current_state;

                if frame_count % 50 == 0 {
                    if let Some(vs) = analyzer.last_vehicle_state() {
                        if vs.is_valid() {
                            let normalized = vs.normalized_offset().unwrap_or(0.0);
                            let width = vs.lane_width.unwrap_or(0.0);
                            if normalized.abs() > 0.1 {
                                info!(
                                "Frame {}: State={} | Offset: {:.1}px ({:.1}%) | Width: {:.0}px",
                                frame_count,
                                analyzer.current_state(),
                                vs.lateral_offset,
                                normalized * 100.0,
                                width
                            );
                            }
                        }
                    }
                }

                if analyzer
                    .last_vehicle_state()
                    .map_or(false, |s| s.is_valid())
                {
                    frames_with_valid_position += 1;
                }

                if let Some(ref mut w) = writer {
                    if let Ok(annotated) = video_processor::draw_lanes_with_state(
                        &frame.data,
                        reader.width,
                        reader.height,
                        &detected_lanes,
                        analyzer.current_state(),
                        analyzer.last_vehicle_state(),
                    ) {
                        use opencv::videoio::VideoWriterTrait;
                        w.write(&annotated)?;
                    }
                }
            }
            Err(e) => error!("Frame {} failed: {}", frame_count, e),
        }
    }

    let duration = start_time.elapsed();
    let avg_fps = frame_count as f64 / duration.as_secs_f64();

    info!("\n Final Report:");
    info!("  Total Lane Changes: {}", lane_changes.len());
    info!("  Events Sent to API: {}", events_sent_to_api);
    info!("  Processing Speed: {:.1} FPS", avg_fps);

    for (i, event) in lane_changes.iter().enumerate() {
        info!(
            "  {}. {} at {:.2}s (confidence: {:.2})",
            i + 1,
            event.direction_name(),
            event.video_timestamp_ms / 1000.0,
            event.confidence
        );
    }

    save_results(video_path, &lane_changes, config)?;

    Ok(ProcessingStats {
        total_frames: frame_count,
        frames_with_position: frames_with_valid_position,
        lane_changes_detected: lane_changes.len(),
        events_sent_to_api,
        duration_secs: duration.as_secs_f64(),
        avg_fps,
    })
}

async fn process_frame(
    frame: &Frame,
    inference_engine: &mut inference::InferenceEngine,
    config: &types::Config,
    confidence_threshold: f32,
) -> Result<Vec<DetectedLane>> {
    let preprocessed = preprocessing::preprocess(
        &frame.data,
        frame.width,
        frame.height,
        config.model.input_width,
        config.model.input_height,
    )?;

    let output = inference_engine.infer(&preprocessed)?;

    let lane_detection = lane_detection::parse_lanes(
        &output,
        frame.width as f32,
        frame.height as f32,
        config,
        frame.timestamp_ms,
    )?;

    // Use config threshold instead of hardcoded
    let high_confidence_lanes: Vec<DetectedLane> = lane_detection
        .lanes
        .into_iter()
        .filter(|lane| {
            lane.confidence > confidence_threshold
                && lane.points.len() >= config.detection.min_points_per_lane
        })
        .collect();

    Ok(high_confidence_lanes)
}

fn save_results(
    video_path: &Path,
    lane_changes: &[LaneChangeEvent],
    config: &types::Config,
) -> Result<()> {
    use std::fs::File;
    use std::io::Write;

    std::fs::create_dir_all(&config.video.output_dir)?;
    let video_name = video_path.file_stem().unwrap().to_str().unwrap();
    let jsonl_path =
        Path::new(&config.video.output_dir).join(format!("{}_lane_changes.jsonl", video_name));

    let mut file = File::create(&jsonl_path)?;
    for event in lane_changes {
        let json_line = serde_json::to_string(&event.to_json())?;
        writeln!(file, "{}", json_line)?;
    }
    info!(" Saved to: {}", jsonl_path.display());
    Ok(())
}
// src/preprocessing.rs

use anyhow::Result;

/// Preprocess raw RGB image for model input
pub fn preprocess(
    src: &[u8],
    src_width: usize,
    src_height: usize,
    dst_width: usize,
    dst_height: usize,
) -> Result<Vec<f32>> {
    // Resize
    let resized = resize_bilinear(src, src_width, src_height, dst_width, dst_height);

    // Normalize and convert HWC -> CHW
    const MEAN: [f32; 3] = [0.485, 0.456, 0.406];
    const STD: [f32; 3] = [0.229, 0.224, 0.225];

    let mut output = vec![0.0f32; 3 * dst_height * dst_width];

    for c in 0..3 {
        for h in 0..dst_height {
            for w in 0..dst_width {
                let hwc_idx = (h * dst_width + w) * 3 + c;
                let chw_idx = c * dst_height * dst_width + h * dst_width + w;

                let pixel = resized[hwc_idx] as f32 / 255.0;
                output[chw_idx] = (pixel - MEAN[c]) / STD[c];
            }
        }
    }

    Ok(output)
}

/// Bilinear image resize
fn resize_bilinear(src: &[u8], src_w: usize, src_h: usize, dst_w: usize, dst_h: usize) -> Vec<u8> {
    let mut dst = vec![0u8; dst_h * dst_w * 3];

    let x_ratio = src_w as f32 / dst_w as f32;
    let y_ratio = src_h as f32 / dst_h as f32;

    for dy in 0..dst_h {
        for dx in 0..dst_w {
            let sx = dx as f32 * x_ratio;
            let sy = dy as f32 * y_ratio;

            let sx0 = sx.floor() as usize;
            let sy0 = sy.floor() as usize;
            let sx1 = (sx0 + 1).min(src_w - 1);
            let sy1 = (sy0 + 1).min(src_h - 1);

            let fx = sx - sx0 as f32;
            let fy = sy - sy0 as f32;

            for c in 0..3 {
                let p00 = src[(sy0 * src_w + sx0) * 3 + c] as f32;
                let p10 = src[(sy0 * src_w + sx1) * 3 + c] as f32;
                let p01 = src[(sy1 * src_w + sx0) * 3 + c] as f32;
                let p11 = src[(sy1 * src_w + sx1) * 3 + c] as f32;

                let val = p00 * (1.0 - fx) * (1.0 - fy)
                    + p10 * fx * (1.0 - fy)
                    + p01 * (1.0 - fx) * fy
                    + p11 * fx * fy;

                dst[(dy * dst_w + dx) * 3 + c] = val.round() as u8;
            }
        }
    }

    dst
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_preprocess() {
        let src = vec![128u8; 640 * 480 * 3];
        let result = preprocess(&src, 640, 480, 1600, 320);
        assert!(result.is_ok());
        assert_eq!(result.unwrap().len(), 3 * 320 * 1600);
    }

    #[test]
    fn test_resize() {
        let src = vec![255u8; 100 * 100 * 3];
        let dst = resize_bilinear(&src, 100, 100, 50, 50);
        assert_eq!(dst.len(), 50 * 50 * 3);
    }
}
use opencv::{core, imgproc, prelude::*};

pub fn visualize_lanes(frame: &Mat, lanes: &[Lane], position: &VehiclePosition) -> Result<Mat> {
    let mut debug_frame = frame.clone();

    // Draw detected lanes with different colors
    let colors = [
        core::Scalar::new(255.0, 0.0, 0.0, 0.0),   // Blue - Lane 0
        core::Scalar::new(0.0, 255.0, 0.0, 0.0),   // Green - Lane 1
        core::Scalar::new(0.0, 0.0, 255.0, 0.0),   // Red - Lane 2
        core::Scalar::new(255.0, 255.0, 0.0, 0.0), // Cyan - Lane 3
    ];

    for (i, lane) in lanes.iter().enumerate() {
        // Draw lane points
        for window in lane.points.windows(2) {
            let p1 = core::Point::new(window[0].x as i32, window[0].y as i32);
            let p2 = core::Point::new(window[1].x as i32, window[1].y as i32);
            imgproc::line(
                &mut debug_frame,
                p1,
                p2,
                colors[i % 4],
                3,
                imgproc::LINE_8,
                0,
            )?;
        }

        // Draw lane ID
        if let Some(first_point) = lane.points.first() {
            imgproc::put_text(
                &mut debug_frame,
                &format!("L{} ({:.2})", i, lane.confidence),
                core::Point::new(first_point.x as i32, first_point.y as i32 - 10),
                imgproc::FONT_HERSHEY_SIMPLEX,
                0.6,
                colors[i % 4],
                2,
                imgproc::LINE_8,
                false,
            )?;
        }
    }

    // Draw vehicle position indicator
    let vehicle_x = frame.cols() / 2;
    let vehicle_y = (frame.rows() as f32 * 0.85) as i32;

    imgproc::circle(
        &mut debug_frame,
        core::Point::new(vehicle_x, vehicle_y),
        10,
        core::Scalar::new(0.0, 255.0, 255.0, 0.0), // Yellow
        -1,
        imgproc::LINE_8,
        0,
    )?;

    // Draw current lane info
    let info = format!(
        "Lane: {} | Offset: {:.2} | Conf: {:.2}",
        position.lane_index, position.lateral_offset, position.confidence
    );
    imgproc::put_text(
        &mut debug_frame,
        &info,
        core::Point::new(10, 30),
        imgproc::FONT_HERSHEY_SIMPLEX,
        0.8,
        core::Scalar::new(0.0, 255.0, 0.0, 0.0),
        2,
        imgproc::LINE_8,
        false,
    )?;

    Ok(debug_frame)
}
// src/inference.rs

use crate::types::Config;
use anyhow::{Context, Result};
use ort::{
    execution_providers::CUDAExecutionProvider,
    session::{builder::GraphOptimizationLevel, Session},
};
use tracing::{debug, info};

pub struct InferenceEngine {
    session: Session,
    config: Config,
}

impl InferenceEngine {
    pub fn new(config: Config) -> Result<Self> {
        info!("Initializing inference engine");
        info!("Model path: {}", config.model.path);

        let mut session_builder = Session::builder()?;

        // CUDA execution provider
        info!("Enabling CUDA execution provider");
        session_builder =
            session_builder.with_execution_providers([CUDAExecutionProvider::default()
                .with_device_id(0)
                .build()])?;

        info!("Building ONNX Runtime session...");
        let session = session_builder
            .with_optimization_level(GraphOptimizationLevel::Level3)?
            .with_intra_threads(config.inference.num_threads)?
            .with_inter_threads(1)?
            .commit_from_file(&config.model.path)
            .context("Failed to load model")?;

        info!(" Inference engine initialized successfully");

        Ok(Self { session, config })
    }

    pub fn infer(&mut self, input: &[f32]) -> Result<Vec<f32>> {
        debug!("Running inference");

        // Create shape tuple
        let shape = [
            1,
            3,
            self.config.model.input_height,
            self.config.model.input_width,
        ];

        // Create input value from tuple (shape, data)
        let input_value =
            ort::value::Value::from_array((shape.as_slice(), input.to_vec().into_boxed_slice()))?;

        // Run inference
        let outputs = self.session.run(ort::inputs!["input" => input_value])?;

        // Extract output
        let output = &outputs[0];
        let (output_shape, data_slice) = output.try_extract_tensor::<f32>()?;

        // Convert slice to Vec
        let output_data: Vec<f32> = data_slice.to_vec();

        Ok(output_data)
    }
}
=== ./config.yaml ===
# config.yaml
model:
  path: "/home/edartru/InEdge/poc-minsur/models/ufldv2_culane_res34_320x1600.onnx"
  input_width: 1600
  input_height: 320
  num_anchors: 72
  num_lanes: 4
  griding_num: 200

inference:
  use_tensorrt: true
  use_fp16: true
  enable_engine_cache: true
  engine_cache_path: "/home/edartru/InEdge/poc-minsur/cache"
  num_threads: 4

detection:
  confidence_threshold: 0.25
  min_points_per_lane: 3
  smoother_window_size: 10
  calibration_frames: 90
  debounce_frames: 10
  confirm_frames: 12
  min_lane_confidence: 0.25
  min_position_confidence: 0.3
  drift_threshold: 0.30           # Start noticing at 30%
  crossing_threshold: 0.48        # Confirm at 48% (balanced)
  cooldown_frames: 90
  min_lane_change_duration_ms: 1200
  max_lane_change_duration_ms: 8000
  skip_initial_frames: 100
  require_both_lanes: false

overtake:
  lane_change_offset_threshold: 0.6
  debounce_frames: 5
  confirm_frames: 8
  max_window_seconds: 15.0
  min_interval_seconds: 2.0

video:
  input_dir: "/home/edartru/InEdge/poc-minsur/videos/lima"
  output_dir: "/home/edartru/InEdge/poc-minsur/output"
  source_width: 1280
  source_height: 720
  target_fps: 30
  save_annotated: true
  save_events_only: false

logging:
  level: "info"

